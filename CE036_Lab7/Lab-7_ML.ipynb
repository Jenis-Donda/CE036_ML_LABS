{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWBMu_eS0QQF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "RqVbHt0U0mum",
        "outputId": "be11c3e6-13e0-4e5b-d847-268386dd6b91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79cf21bb-2d07-4b18-b847-54b6dbe8056e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-79cf21bb-2d07-4b18-b847-54b6dbe8056e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BuyComputer.csv to BuyComputer.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  EstimatedSalary  Purchased\n",
              "0   19            19000          0\n",
              "1   35            20000          0\n",
              "2   26            43000          0\n",
              "3   27            57000          0\n",
              "4   19            76000          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0309426d-b530-4d81-aa9d-5eb731c8de08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0309426d-b530-4d81-aa9d-5eb731c8de08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0309426d-b530-4d81-aa9d-5eb731c8de08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0309426d-b530-4d81-aa9d-5eb731c8de08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(io.BytesIO(uploaded['BuyComputer.csv']))\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Aya3h_O70yRL",
        "outputId": "dffa1395-44f5-4234-985c-691a2a63872a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  EstimatedSalary  Purchased\n",
              "0     19            19000          0\n",
              "1     35            20000          0\n",
              "2     26            43000          0\n",
              "3     27            57000          0\n",
              "4     19            76000          0\n",
              "..   ...              ...        ...\n",
              "395   46            41000          1\n",
              "396   51            23000          1\n",
              "397   50            20000          1\n",
              "398   36            33000          0\n",
              "399   49            36000          1\n",
              "\n",
              "[400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc98765c-3818-4fdf-960d-d61c58bb60a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>46</td>\n",
              "      <td>41000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>51</td>\n",
              "      <td>23000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>50</td>\n",
              "      <td>20000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>36</td>\n",
              "      <td>33000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>49</td>\n",
              "      <td>36000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc98765c-3818-4fdf-960d-d61c58bb60a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc98765c-3818-4fdf-960d-d61c58bb60a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc98765c-3818-4fdf-960d-d61c58bb60a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8WUANVP1cy0"
      },
      "source": [
        "# Declare label as last column in the source file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au9edz251fJ_"
      },
      "outputs": [],
      "source": [
        "#Declaring X as all columns excluding last\n",
        "X = data.iloc[:,:-1].values\n",
        "\n",
        "#Declare label as last column in the source file\n",
        "Y = data.iloc[:,-1].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mHxqdcw2RRJ",
        "outputId": "e3d06a3f-d5d8-415e-8d32-66f98d113022"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    19,  19000],\n",
              "       [    35,  20000],\n",
              "       [    26,  43000],\n",
              "       [    27,  57000],\n",
              "       [    19,  76000],\n",
              "       [    27,  58000],\n",
              "       [    27,  84000],\n",
              "       [    32, 150000],\n",
              "       [    25,  33000],\n",
              "       [    35,  65000],\n",
              "       [    26,  80000],\n",
              "       [    26,  52000],\n",
              "       [    20,  86000],\n",
              "       [    32,  18000],\n",
              "       [    18,  82000],\n",
              "       [    29,  80000],\n",
              "       [    47,  25000],\n",
              "       [    45,  26000],\n",
              "       [    46,  28000],\n",
              "       [    48,  29000],\n",
              "       [    45,  22000],\n",
              "       [    47,  49000],\n",
              "       [    48,  41000],\n",
              "       [    45,  22000],\n",
              "       [    46,  23000],\n",
              "       [    47,  20000],\n",
              "       [    49,  28000],\n",
              "       [    47,  30000],\n",
              "       [    29,  43000],\n",
              "       [    31,  18000],\n",
              "       [    31,  74000],\n",
              "       [    27, 137000],\n",
              "       [    21,  16000],\n",
              "       [    28,  44000],\n",
              "       [    27,  90000],\n",
              "       [    35,  27000],\n",
              "       [    33,  28000],\n",
              "       [    30,  49000],\n",
              "       [    26,  72000],\n",
              "       [    27,  31000],\n",
              "       [    27,  17000],\n",
              "       [    33,  51000],\n",
              "       [    35, 108000],\n",
              "       [    30,  15000],\n",
              "       [    28,  84000],\n",
              "       [    23,  20000],\n",
              "       [    25,  79000],\n",
              "       [    27,  54000],\n",
              "       [    30, 135000],\n",
              "       [    31,  89000],\n",
              "       [    24,  32000],\n",
              "       [    18,  44000],\n",
              "       [    29,  83000],\n",
              "       [    35,  23000],\n",
              "       [    27,  58000],\n",
              "       [    24,  55000],\n",
              "       [    23,  48000],\n",
              "       [    28,  79000],\n",
              "       [    22,  18000],\n",
              "       [    32, 117000],\n",
              "       [    27,  20000],\n",
              "       [    25,  87000],\n",
              "       [    23,  66000],\n",
              "       [    32, 120000],\n",
              "       [    59,  83000],\n",
              "       [    24,  58000],\n",
              "       [    24,  19000],\n",
              "       [    23,  82000],\n",
              "       [    22,  63000],\n",
              "       [    31,  68000],\n",
              "       [    25,  80000],\n",
              "       [    24,  27000],\n",
              "       [    20,  23000],\n",
              "       [    33, 113000],\n",
              "       [    32,  18000],\n",
              "       [    34, 112000],\n",
              "       [    18,  52000],\n",
              "       [    22,  27000],\n",
              "       [    28,  87000],\n",
              "       [    26,  17000],\n",
              "       [    30,  80000],\n",
              "       [    39,  42000],\n",
              "       [    20,  49000],\n",
              "       [    35,  88000],\n",
              "       [    30,  62000],\n",
              "       [    31, 118000],\n",
              "       [    24,  55000],\n",
              "       [    28,  85000],\n",
              "       [    26,  81000],\n",
              "       [    35,  50000],\n",
              "       [    22,  81000],\n",
              "       [    30, 116000],\n",
              "       [    26,  15000],\n",
              "       [    29,  28000],\n",
              "       [    29,  83000],\n",
              "       [    35,  44000],\n",
              "       [    35,  25000],\n",
              "       [    28, 123000],\n",
              "       [    35,  73000],\n",
              "       [    28,  37000],\n",
              "       [    27,  88000],\n",
              "       [    28,  59000],\n",
              "       [    32,  86000],\n",
              "       [    33, 149000],\n",
              "       [    19,  21000],\n",
              "       [    21,  72000],\n",
              "       [    26,  35000],\n",
              "       [    27,  89000],\n",
              "       [    26,  86000],\n",
              "       [    38,  80000],\n",
              "       [    39,  71000],\n",
              "       [    37,  71000],\n",
              "       [    38,  61000],\n",
              "       [    37,  55000],\n",
              "       [    42,  80000],\n",
              "       [    40,  57000],\n",
              "       [    35,  75000],\n",
              "       [    36,  52000],\n",
              "       [    40,  59000],\n",
              "       [    41,  59000],\n",
              "       [    36,  75000],\n",
              "       [    37,  72000],\n",
              "       [    40,  75000],\n",
              "       [    35,  53000],\n",
              "       [    41,  51000],\n",
              "       [    39,  61000],\n",
              "       [    42,  65000],\n",
              "       [    26,  32000],\n",
              "       [    30,  17000],\n",
              "       [    26,  84000],\n",
              "       [    31,  58000],\n",
              "       [    33,  31000],\n",
              "       [    30,  87000],\n",
              "       [    21,  68000],\n",
              "       [    28,  55000],\n",
              "       [    23,  63000],\n",
              "       [    20,  82000],\n",
              "       [    30, 107000],\n",
              "       [    28,  59000],\n",
              "       [    19,  25000],\n",
              "       [    19,  85000],\n",
              "       [    18,  68000],\n",
              "       [    35,  59000],\n",
              "       [    30,  89000],\n",
              "       [    34,  25000],\n",
              "       [    24,  89000],\n",
              "       [    27,  96000],\n",
              "       [    41,  30000],\n",
              "       [    29,  61000],\n",
              "       [    20,  74000],\n",
              "       [    26,  15000],\n",
              "       [    41,  45000],\n",
              "       [    31,  76000],\n",
              "       [    36,  50000],\n",
              "       [    40,  47000],\n",
              "       [    31,  15000],\n",
              "       [    46,  59000],\n",
              "       [    29,  75000],\n",
              "       [    26,  30000],\n",
              "       [    32, 135000],\n",
              "       [    32, 100000],\n",
              "       [    25,  90000],\n",
              "       [    37,  33000],\n",
              "       [    35,  38000],\n",
              "       [    33,  69000],\n",
              "       [    18,  86000],\n",
              "       [    22,  55000],\n",
              "       [    35,  71000],\n",
              "       [    29, 148000],\n",
              "       [    29,  47000],\n",
              "       [    21,  88000],\n",
              "       [    34, 115000],\n",
              "       [    26, 118000],\n",
              "       [    34,  43000],\n",
              "       [    34,  72000],\n",
              "       [    23,  28000],\n",
              "       [    35,  47000],\n",
              "       [    25,  22000],\n",
              "       [    24,  23000],\n",
              "       [    31,  34000],\n",
              "       [    26,  16000],\n",
              "       [    31,  71000],\n",
              "       [    32, 117000],\n",
              "       [    33,  43000],\n",
              "       [    33,  60000],\n",
              "       [    31,  66000],\n",
              "       [    20,  82000],\n",
              "       [    33,  41000],\n",
              "       [    35,  72000],\n",
              "       [    28,  32000],\n",
              "       [    24,  84000],\n",
              "       [    19,  26000],\n",
              "       [    29,  43000],\n",
              "       [    19,  70000],\n",
              "       [    28,  89000],\n",
              "       [    34,  43000],\n",
              "       [    30,  79000],\n",
              "       [    20,  36000],\n",
              "       [    26,  80000],\n",
              "       [    35,  22000],\n",
              "       [    35,  39000],\n",
              "       [    49,  74000],\n",
              "       [    39, 134000],\n",
              "       [    41,  71000],\n",
              "       [    58, 101000],\n",
              "       [    47,  47000],\n",
              "       [    55, 130000],\n",
              "       [    52, 114000],\n",
              "       [    40, 142000],\n",
              "       [    46,  22000],\n",
              "       [    48,  96000],\n",
              "       [    52, 150000],\n",
              "       [    59,  42000],\n",
              "       [    35,  58000],\n",
              "       [    47,  43000],\n",
              "       [    60, 108000],\n",
              "       [    49,  65000],\n",
              "       [    40,  78000],\n",
              "       [    46,  96000],\n",
              "       [    59, 143000],\n",
              "       [    41,  80000],\n",
              "       [    35,  91000],\n",
              "       [    37, 144000],\n",
              "       [    60, 102000],\n",
              "       [    35,  60000],\n",
              "       [    37,  53000],\n",
              "       [    36, 126000],\n",
              "       [    56, 133000],\n",
              "       [    40,  72000],\n",
              "       [    42,  80000],\n",
              "       [    35, 147000],\n",
              "       [    39,  42000],\n",
              "       [    40, 107000],\n",
              "       [    49,  86000],\n",
              "       [    38, 112000],\n",
              "       [    46,  79000],\n",
              "       [    40,  57000],\n",
              "       [    37,  80000],\n",
              "       [    46,  82000],\n",
              "       [    53, 143000],\n",
              "       [    42, 149000],\n",
              "       [    38,  59000],\n",
              "       [    50,  88000],\n",
              "       [    56, 104000],\n",
              "       [    41,  72000],\n",
              "       [    51, 146000],\n",
              "       [    35,  50000],\n",
              "       [    57, 122000],\n",
              "       [    41,  52000],\n",
              "       [    35,  97000],\n",
              "       [    44,  39000],\n",
              "       [    37,  52000],\n",
              "       [    48, 134000],\n",
              "       [    37, 146000],\n",
              "       [    50,  44000],\n",
              "       [    52,  90000],\n",
              "       [    41,  72000],\n",
              "       [    40,  57000],\n",
              "       [    58,  95000],\n",
              "       [    45, 131000],\n",
              "       [    35,  77000],\n",
              "       [    36, 144000],\n",
              "       [    55, 125000],\n",
              "       [    35,  72000],\n",
              "       [    48,  90000],\n",
              "       [    42, 108000],\n",
              "       [    40,  75000],\n",
              "       [    37,  74000],\n",
              "       [    47, 144000],\n",
              "       [    40,  61000],\n",
              "       [    43, 133000],\n",
              "       [    59,  76000],\n",
              "       [    60,  42000],\n",
              "       [    39, 106000],\n",
              "       [    57,  26000],\n",
              "       [    57,  74000],\n",
              "       [    38,  71000],\n",
              "       [    49,  88000],\n",
              "       [    52,  38000],\n",
              "       [    50,  36000],\n",
              "       [    59,  88000],\n",
              "       [    35,  61000],\n",
              "       [    37,  70000],\n",
              "       [    52,  21000],\n",
              "       [    48, 141000],\n",
              "       [    37,  93000],\n",
              "       [    37,  62000],\n",
              "       [    48, 138000],\n",
              "       [    41,  79000],\n",
              "       [    37,  78000],\n",
              "       [    39, 134000],\n",
              "       [    49,  89000],\n",
              "       [    55,  39000],\n",
              "       [    37,  77000],\n",
              "       [    35,  57000],\n",
              "       [    36,  63000],\n",
              "       [    42,  73000],\n",
              "       [    43, 112000],\n",
              "       [    45,  79000],\n",
              "       [    46, 117000],\n",
              "       [    58,  38000],\n",
              "       [    48,  74000],\n",
              "       [    37, 137000],\n",
              "       [    37,  79000],\n",
              "       [    40,  60000],\n",
              "       [    42,  54000],\n",
              "       [    51, 134000],\n",
              "       [    47, 113000],\n",
              "       [    36, 125000],\n",
              "       [    38,  50000],\n",
              "       [    42,  70000],\n",
              "       [    39,  96000],\n",
              "       [    38,  50000],\n",
              "       [    49, 141000],\n",
              "       [    39,  79000],\n",
              "       [    39,  75000],\n",
              "       [    54, 104000],\n",
              "       [    35,  55000],\n",
              "       [    45,  32000],\n",
              "       [    36,  60000],\n",
              "       [    52, 138000],\n",
              "       [    53,  82000],\n",
              "       [    41,  52000],\n",
              "       [    48,  30000],\n",
              "       [    48, 131000],\n",
              "       [    41,  60000],\n",
              "       [    41,  72000],\n",
              "       [    42,  75000],\n",
              "       [    36, 118000],\n",
              "       [    47, 107000],\n",
              "       [    38,  51000],\n",
              "       [    48, 119000],\n",
              "       [    42,  65000],\n",
              "       [    40,  65000],\n",
              "       [    57,  60000],\n",
              "       [    36,  54000],\n",
              "       [    58, 144000],\n",
              "       [    35,  79000],\n",
              "       [    38,  55000],\n",
              "       [    39, 122000],\n",
              "       [    53, 104000],\n",
              "       [    35,  75000],\n",
              "       [    38,  65000],\n",
              "       [    47,  51000],\n",
              "       [    47, 105000],\n",
              "       [    41,  63000],\n",
              "       [    53,  72000],\n",
              "       [    54, 108000],\n",
              "       [    39,  77000],\n",
              "       [    38,  61000],\n",
              "       [    38, 113000],\n",
              "       [    37,  75000],\n",
              "       [    42,  90000],\n",
              "       [    37,  57000],\n",
              "       [    36,  99000],\n",
              "       [    60,  34000],\n",
              "       [    54,  70000],\n",
              "       [    41,  72000],\n",
              "       [    40,  71000],\n",
              "       [    42,  54000],\n",
              "       [    43, 129000],\n",
              "       [    53,  34000],\n",
              "       [    47,  50000],\n",
              "       [    42,  79000],\n",
              "       [    42, 104000],\n",
              "       [    59,  29000],\n",
              "       [    58,  47000],\n",
              "       [    46,  88000],\n",
              "       [    38,  71000],\n",
              "       [    54,  26000],\n",
              "       [    60,  46000],\n",
              "       [    60,  83000],\n",
              "       [    39,  73000],\n",
              "       [    59, 130000],\n",
              "       [    37,  80000],\n",
              "       [    46,  32000],\n",
              "       [    46,  74000],\n",
              "       [    42,  53000],\n",
              "       [    41,  87000],\n",
              "       [    58,  23000],\n",
              "       [    42,  64000],\n",
              "       [    48,  33000],\n",
              "       [    44, 139000],\n",
              "       [    49,  28000],\n",
              "       [    57,  33000],\n",
              "       [    56,  60000],\n",
              "       [    49,  39000],\n",
              "       [    39,  71000],\n",
              "       [    47,  34000],\n",
              "       [    48,  35000],\n",
              "       [    48,  33000],\n",
              "       [    47,  23000],\n",
              "       [    45,  45000],\n",
              "       [    60,  42000],\n",
              "       [    39,  59000],\n",
              "       [    46,  41000],\n",
              "       [    51,  23000],\n",
              "       [    50,  20000],\n",
              "       [    36,  33000],\n",
              "       [    49,  36000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gWGWHET2Sp-"
      },
      "outputs": [],
      "source": [
        "# Splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X,Y ,\n",
        "                                   random_state=36, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ2LkhvM2fNq"
      },
      "outputs": [],
      "source": [
        "from os import XATTR_SIZE_MAX\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-es2TR82y5F",
        "outputId": "50d06168-a3ba-49c3-b062-3c0937e368eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.95591499, -1.03853963],\n",
              "       [ 0.76240994, -0.28464395],\n",
              "       [ 0.47215235,  1.86105915],\n",
              "       [-0.78563054,  0.52724371],\n",
              "       [ 1.92344029,  0.93318754],\n",
              "       [-0.30186789, -1.32849951],\n",
              "       [ 1.53643017,  1.02017551],\n",
              "       [ 2.11694535, -1.00954364],\n",
              "       [-0.20511536,  0.17929186],\n",
              "       [ 0.37539982, -0.42962389],\n",
              "       [ 0.85916247, -1.1255276 ],\n",
              "       [-0.30186789,  0.81720359],\n",
              "       [-1.07588813, -0.31363994],\n",
              "       [-0.9791356 ,  0.29527581],\n",
              "       [-1.17264066,  1.42611934],\n",
              "       [ 0.76240994, -1.3574955 ],\n",
              "       [ 0.18189476,  0.17929186],\n",
              "       [ 0.18189476,  2.12202305],\n",
              "       [-0.88238307, -0.74857975],\n",
              "       [-1.17264066,  0.49824772],\n",
              "       [ 1.82668776, -1.03853963],\n",
              "       [ 1.43967764,  0.38226377],\n",
              "       [-0.78563054,  1.91905113],\n",
              "       [ 0.08514223,  0.23728383],\n",
              "       [-0.0116103 , -0.28464395],\n",
              "       [-0.49537295, -0.80657173],\n",
              "       [-1.17264066, -0.98054766],\n",
              "       [-0.49537295, -0.25564796],\n",
              "       [ 0.85916247,  1.2811394 ],\n",
              "       [-1.17264066,  0.3242718 ],\n",
              "       [-0.0116103 ,  1.2811394 ],\n",
              "       [-1.65640331, -1.53147143],\n",
              "       [ 0.18189476, -0.6325958 ],\n",
              "       [ 0.18189476,  0.17929186],\n",
              "       [ 0.27864729,  0.06330791],\n",
              "       [-0.68887801,  1.42611934],\n",
              "       [ 0.95591499, -0.98054766],\n",
              "       [ 0.85916247,  2.18001502],\n",
              "       [-0.78563054, -0.57460383],\n",
              "       [ 1.34292511,  2.35399095],\n",
              "       [-1.36614572, -1.32849951],\n",
              "       [-0.9791356 , -0.71958377],\n",
              "       [-1.07588813,  0.58523569],\n",
              "       [-0.68887801,  0.15029587],\n",
              "       [-1.17264066, -0.74857975],\n",
              "       [-0.10836283, -0.45861987],\n",
              "       [ 0.08514223,  0.12129988],\n",
              "       [-1.36614572, -0.4006279 ],\n",
              "       [-0.0116103 , -0.54560784],\n",
              "       [ 0.76240994, -1.06753562],\n",
              "       [ 1.92344029, -0.6325958 ],\n",
              "       [ 0.95591499,  0.15029587],\n",
              "       [ 0.08514223, -0.22665197],\n",
              "       [-0.10836283, -1.03853963],\n",
              "       [ 2.02019282,  0.20828785],\n",
              "       [-0.88238307,  0.17929186],\n",
              "       [-0.78563054,  0.3242718 ],\n",
              "       [-0.68887801,  0.58523569],\n",
              "       [ 0.85916247,  1.10716347],\n",
              "       [ 2.02019282,  2.15101903],\n",
              "       [-0.30186789,  0.09230389],\n",
              "       [-0.0116103 , -0.4006279 ],\n",
              "       [ 0.18189476,  0.09230389],\n",
              "       [-0.20511536,  2.18001502],\n",
              "       [ 0.37539982, -0.45861987],\n",
              "       [ 1.43967764, -1.00954364],\n",
              "       [ 0.66565741, -1.3574955 ],\n",
              "       [ 0.27864729, -0.16866   ],\n",
              "       [ 0.76240994, -0.80657173],\n",
              "       [ 0.27864729,  0.3242718 ],\n",
              "       [-0.78563054,  0.58523569],\n",
              "       [-0.59212548,  2.35399095],\n",
              "       [-1.36614572, -1.21251556],\n",
              "       [ 0.85916247,  1.04917149],\n",
              "       [-1.07588813,  1.97704311],\n",
              "       [ 0.95591499,  2.09302706],\n",
              "       [ 0.18189476, -0.25564796],\n",
              "       [ 2.11694535, -0.77757574],\n",
              "       [ 1.72993523,  1.86105915],\n",
              "       [ 1.05266752,  2.09302706],\n",
              "       [ 0.66565741, -0.69058778],\n",
              "       [-0.68887801,  0.06330791],\n",
              "       [-1.9466609 , -0.48761586],\n",
              "       [ 1.24617258,  1.89005514],\n",
              "       [ 2.11694535,  0.41125976],\n",
              "       [ 1.6331827 , -0.8645637 ],\n",
              "       [-1.46289825, -1.41548747],\n",
              "       [-0.30186789, -1.3574955 ],\n",
              "       [ 0.47215235,  1.25214341],\n",
              "       [-1.07588813, -1.09653161],\n",
              "       [-0.9791356 ,  1.57109928],\n",
              "       [-1.17264066, -1.53147143],\n",
              "       [-0.59212548,  0.49824772],\n",
              "       [-0.68887801, -0.31363994],\n",
              "       [ 0.76240994,  0.7882076 ],\n",
              "       [-0.88238307, -0.6325958 ],\n",
              "       [-0.30186789,  0.23728383],\n",
              "       [ 2.11694535,  1.13615946],\n",
              "       [-0.59212548, -1.47347945],\n",
              "       [-0.30186789,  0.09230389],\n",
              "       [ 0.18189476, -0.11066802],\n",
              "       [-0.88238307,  0.41125976],\n",
              "       [-0.20511536,  1.62909125],\n",
              "       [-0.30186789,  0.29527581],\n",
              "       [-0.59212548,  1.39712335],\n",
              "       [ 0.37539982,  0.29527581],\n",
              "       [ 1.34292511, -1.38649149],\n",
              "       [-1.36614572, -1.44448346],\n",
              "       [ 1.92344029, -1.32849951],\n",
              "       [ 0.95591499, -0.80657173],\n",
              "       [ 0.37539982, -0.42962389],\n",
              "       [-0.59212548,  1.91905113],\n",
              "       [ 0.76240994,  0.15029587],\n",
              "       [-0.59212548, -1.47347945],\n",
              "       [-1.9466609 ,  0.49824772],\n",
              "       [-1.84990837, -1.24151155],\n",
              "       [ 1.43967764,  2.15101903],\n",
              "       [ 1.14942005, -1.41548747],\n",
              "       [ 1.6331827 ,  1.77407119],\n",
              "       [ 0.08514223,  0.7882076 ],\n",
              "       [-0.0116103 ,  0.06330791],\n",
              "       [ 0.47215235,  1.7450752 ],\n",
              "       [-0.20511536,  1.65808724],\n",
              "       [ 0.37539982,  0.17929186],\n",
              "       [ 0.85916247, -1.32849951],\n",
              "       [-0.0116103 ,  0.3242718 ],\n",
              "       [ 0.85916247, -1.27050753],\n",
              "       [ 0.76240994,  0.5562397 ],\n",
              "       [-0.0116103 , -0.51661185],\n",
              "       [ 2.02019282,  0.41125976],\n",
              "       [-0.30186789,  0.17929186],\n",
              "       [-1.55965078, -1.21251556],\n",
              "       [ 0.95591499,  1.80306718],\n",
              "       [ 0.18189476, -0.22665197],\n",
              "       [ 0.95591499,  0.61423168],\n",
              "       [-0.39862042, -1.27050753],\n",
              "       [-0.30186789, -1.27050753],\n",
              "       [-0.10836283, -0.34263592],\n",
              "       [-1.17264066, -1.56046741],\n",
              "       [-0.9791356 , -0.4006279 ],\n",
              "       [-0.10836283, -0.48761586],\n",
              "       [-0.30186789, -0.34263592],\n",
              "       [ 1.34292511,  0.61423168],\n",
              "       [-0.88238307, -1.18351957],\n",
              "       [ 0.27864729, -0.25564796],\n",
              "       [ 1.05266752, -0.11066802],\n",
              "       [ 0.27864729, -0.48761586],\n",
              "       [ 0.66565741, -1.24151155],\n",
              "       [ 1.14942005, -0.71958377],\n",
              "       [-1.07588813,  0.44025575],\n",
              "       [ 0.37539982,  0.03431192],\n",
              "       [-1.84990837,  0.03431192],\n",
              "       [ 0.56890488,  2.03503508],\n",
              "       [ 2.11694535, -0.66159179],\n",
              "       [-1.75315584,  0.15029587],\n",
              "       [-0.68887801, -1.56046741],\n",
              "       [-1.75315584,  0.38226377],\n",
              "       [ 0.08514223, -0.77757574],\n",
              "       [-0.9791356 , -0.28464395],\n",
              "       [-0.49537295, -1.09653161],\n",
              "       [ 1.43967764,  1.02017551],\n",
              "       [ 1.14942005, -0.95155167],\n",
              "       [ 1.53643017,  1.13615946],\n",
              "       [-0.10836283,  0.29527581],\n",
              "       [-0.30186789, -0.25564796],\n",
              "       [-0.10836283,  0.15029587],\n",
              "       [-0.9791356 , -0.92255568],\n",
              "       [-1.55965078, -1.47347945],\n",
              "       [-1.84990837,  0.20828785],\n",
              "       [ 1.53643017,  0.03431192],\n",
              "       [-0.30186789, -1.41548747],\n",
              "       [-1.46289825, -0.16866   ],\n",
              "       [-0.68887801, -1.47347945],\n",
              "       [ 1.24617258,  2.238007  ],\n",
              "       [ 1.05266752,  0.15029587],\n",
              "       [-0.0116103 , -0.22665197],\n",
              "       [-1.84990837, -1.44448346],\n",
              "       [-0.39862042,  1.25214341],\n",
              "       [-1.17264066, -1.50247544],\n",
              "       [ 0.66565741,  0.29527581],\n",
              "       [-0.30186789,  1.13615946],\n",
              "       [-1.07588813, -0.34263592],\n",
              "       [ 1.05266752,  0.58523569],\n",
              "       [ 2.02019282, -1.15452358],\n",
              "       [-0.10836283,  0.3242718 ],\n",
              "       [-1.17264066,  0.09230389],\n",
              "       [-1.55965078,  0.35326779],\n",
              "       [ 0.37539982,  1.13615946],\n",
              "       [ 0.85916247, -0.74857975],\n",
              "       [ 0.27864729, -0.28464395],\n",
              "       [-0.59212548,  1.39712335],\n",
              "       [-1.07588813, -0.31363994],\n",
              "       [ 0.18189476, -0.28464395],\n",
              "       [-1.07588813, -1.50247544],\n",
              "       [-0.10836283,  0.06330791],\n",
              "       [-0.78563054, -0.19765598],\n",
              "       [ 0.08514223,  0.29527581],\n",
              "       [ 0.08514223, -0.28464395],\n",
              "       [-0.49537295, -0.51661185],\n",
              "       [-0.30186789, -0.4006279 ],\n",
              "       [-1.07588813, -0.42962389],\n",
              "       [-1.17264066, -1.1255276 ],\n",
              "       [ 0.37539982, -0.11066802],\n",
              "       [-0.88238307, -0.22665197],\n",
              "       [ 0.37539982,  0.12129988],\n",
              "       [ 1.24617258, -1.32849951],\n",
              "       [-1.36614572,  0.44025575],\n",
              "       [ 0.08514223,  0.17929186],\n",
              "       [-0.30186789, -0.54560784],\n",
              "       [ 1.43967764,  0.09230389],\n",
              "       [ 0.27864729, -0.69058778],\n",
              "       [-0.10836283,  0.3242718 ],\n",
              "       [-0.30186789,  0.64322766],\n",
              "       [ 0.27864729,  0.09230389],\n",
              "       [-0.20511536, -0.25564796],\n",
              "       [-0.88238307,  0.41125976],\n",
              "       [ 1.34292511, -0.89355969],\n",
              "       [-0.49537295, -0.74857975],\n",
              "       [-1.07588813,  0.5562397 ],\n",
              "       [ 2.02019282,  0.5562397 ],\n",
              "       [ 0.27864729,  0.09230389],\n",
              "       [-0.30186789, -0.11066802],\n",
              "       [ 1.05266752,  0.5562397 ],\n",
              "       [ 1.72993523, -0.25564796],\n",
              "       [-1.17264066, -0.48761586],\n",
              "       [-1.75315584,  0.38226377],\n",
              "       [ 1.92344029,  2.18001502],\n",
              "       [-0.10836283,  2.238007  ],\n",
              "       [-1.26939319,  0.3242718 ],\n",
              "       [-0.30186789, -0.8645637 ],\n",
              "       [-0.30186789, -0.31363994],\n",
              "       [-1.17264066,  0.44025575],\n",
              "       [ 0.08514223,  0.06330791],\n",
              "       [-0.68887801,  0.20828785],\n",
              "       [-1.55965078, -0.4006279 ],\n",
              "       [ 1.34292511,  1.31013539],\n",
              "       [ 0.18189476, -0.34263592],\n",
              "       [-1.07588813, -1.41548747],\n",
              "       [ 1.05266752, -0.95155167],\n",
              "       [-0.88238307,  2.29599897],\n",
              "       [-0.78563054, -1.56046741],\n",
              "       [-0.10836283, -0.4006279 ],\n",
              "       [ 0.37539982,  1.02017551],\n",
              "       [-0.0116103 , -0.22665197],\n",
              "       [ 0.18189476,  1.10716347],\n",
              "       [ 0.85916247, -1.41548747],\n",
              "       [ 0.27864729,  0.29527581],\n",
              "       [-0.20511536,  1.42611934],\n",
              "       [-0.0116103 ,  0.06330791],\n",
              "       [-0.30186789, -0.71958377],\n",
              "       [ 1.82668776, -1.24151155],\n",
              "       [-0.78563054,  0.29527581],\n",
              "       [-0.10836283,  0.03431192],\n",
              "       [ 0.27864729,  0.52724371],\n",
              "       [ 0.08514223, -0.77757574],\n",
              "       [-1.26939319, -1.3574955 ],\n",
              "       [ 0.85916247, -0.54560784],\n",
              "       [-0.49537295, -1.18351957],\n",
              "       [ 0.76240994, -1.18351957],\n",
              "       [-1.75315584, -0.57460383],\n",
              "       [-1.17264066,  0.35326779],\n",
              "       [-1.17264066, -1.06753562],\n",
              "       [ 0.27864729, -1.1255276 ],\n",
              "       [-0.49537295,  2.32499496],\n",
              "       [ 0.08514223,  1.89005514],\n",
              "       [-0.88238307, -0.74857975],\n",
              "       [ 0.76240994, -1.32849951],\n",
              "       [ 0.95591499, -1.1255276 ],\n",
              "       [ 0.27864729, -0.48761586],\n",
              "       [-0.30186789, -0.22665197],\n",
              "       [-0.10836283,  0.17929186],\n",
              "       [ 0.95591499,  1.89005514],\n",
              "       [-1.9466609 , -0.02368006],\n",
              "       [ 0.85916247, -0.57460383],\n",
              "       [-0.39862042, -0.74857975],\n",
              "       [-0.10836283, -0.19765598],\n",
              "       [-0.10836283,  0.09230389],\n",
              "       [ 0.85916247, -0.6325958 ],\n",
              "       [ 1.72993523,  1.02017551],\n",
              "       [-0.30186789,  0.5562397 ],\n",
              "       [-0.30186789, -0.28464395],\n",
              "       [-0.49537295,  0.00531593],\n",
              "       [ 0.27864729, -0.51661185],\n",
              "       [-1.17264066, -1.56046741],\n",
              "       [-1.65640331,  0.09230389],\n",
              "       [ 0.18189476, -0.34263592],\n",
              "       [ 0.95591499,  2.00603909],\n",
              "       [ 0.85916247, -1.00954364],\n",
              "       [-1.17264066,  0.3242718 ],\n",
              "       [ 2.11694535,  0.96218353],\n",
              "       [-0.78563054,  1.36812736],\n",
              "       [ 1.34292511,  2.00603909],\n",
              "       [ 0.95591499, -1.03853963],\n",
              "       [-0.10836283,  0.23728383],\n",
              "       [-0.78563054,  1.10716347],\n",
              "       [ 1.92344029, -0.89355969],\n",
              "       [ 0.56890488, -0.8645637 ],\n",
              "       [-1.26939319,  0.61423168],\n",
              "       [-0.30186789,  0.12129988],\n",
              "       [-1.65640331, -0.02368006]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikD0Sbcg3frX",
        "outputId": "86523b30-0380-4fff-85ca-f3fe43e88bf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.23439718, -0.20022908],\n",
              "       [ 1.93072379, -0.38448897],\n",
              "       [-0.76893821, -0.41519895],\n",
              "       [-0.48966283, -0.20022908],\n",
              "       [-0.86203001,  0.72107037],\n",
              "       [-1.14130539, -1.24436846],\n",
              "       [ 2.20999917, -0.93726864],\n",
              "       [-1.69985615,  0.29113063],\n",
              "       [ 1.65144841, -1.42862835],\n",
              "       [-0.11729566, -0.78371873],\n",
              "       [-1.32748897, -0.29235903],\n",
              "       [ 0.06888793,  1.98017962],\n",
              "       [ 1.09289765, -1.3364984 ],\n",
              "       [ 0.25507151,  1.88804967],\n",
              "       [-0.21038745, -0.90655866],\n",
              "       [-0.11729566,  0.07616075],\n",
              "       [-1.14130539, -0.53803888],\n",
              "       [-0.02420387, -0.29235903],\n",
              "       [ 2.11690738,  1.76520975],\n",
              "       [-0.02420387, -0.69158879],\n",
              "       [-1.60676435,  0.38326057],\n",
              "       [-0.11729566, -0.59945884],\n",
              "       [ 0.34816331, -0.47661892],\n",
              "       [-0.11729566, -1.06010857],\n",
              "       [-1.04821359,  0.19900068],\n",
              "       [ 0.90671407,  0.29113063],\n",
              "       [-1.04821359, -1.21365848],\n",
              "       [-1.14130539,  0.5061005 ],\n",
              "       [ 0.4412551 , -0.01596919],\n",
              "       [ 0.4412551 , -0.01596919],\n",
              "       [-0.67584642,  0.22971066],\n",
              "       [-0.76893821,  0.35255059],\n",
              "       [-0.58275463, -1.70501818],\n",
              "       [-0.76893821,  0.38326057],\n",
              "       [ 0.53434689, -0.26164904],\n",
              "       [-1.60676435, -1.58217826],\n",
              "       [ 1.09289765,  0.72107037],\n",
              "       [ 0.53434689,  0.22971066],\n",
              "       [-1.14130539, -0.44590893],\n",
              "       [-1.23439718, -0.75300875],\n",
              "       [ 0.16197972, -0.69158879],\n",
              "       [ 0.06888793,  0.1682907 ],\n",
              "       [ 0.53434689,  0.22971066],\n",
              "       [-1.23439718, -1.36720838],\n",
              "       [ 0.90671407,  0.19900068],\n",
              "       [ 0.25507151, -0.04667917],\n",
              "       [-0.02420387,  0.81320031],\n",
              "       [ 0.53434689,  0.53681048],\n",
              "       [ 1.27908124,  0.47539052],\n",
              "       [ 0.53434689,  2.3486994 ],\n",
              "       [ 1.93072379,  1.51952989],\n",
              "       [ 1.18598945,  0.41397055],\n",
              "       [ 0.06888793,  0.62894042],\n",
              "       [-0.76893821,  0.5061005 ],\n",
              "       [ 0.81362227, -1.24436846],\n",
              "       [-0.48966283, -1.18294849],\n",
              "       [ 0.81362227,  1.79591973],\n",
              "       [ 0.25507151,  1.02817019],\n",
              "       [ 1.93072379,  0.04545077],\n",
              "       [ 1.18598945, -1.02939859],\n",
              "       [-0.11729566, -0.04667917],\n",
              "       [-0.30347925,  1.24314006],\n",
              "       [ 1.09289765,  1.42739995],\n",
              "       [ 0.06888793,  2.19514949],\n",
              "       [ 0.34816331,  0.1682907 ],\n",
              "       [ 1.74454021,  1.61165984],\n",
              "       [-0.76893821,  0.44468053],\n",
              "       [ 2.02381559,  0.69036039],\n",
              "       [-1.42058077,  0.47539052],\n",
              "       [-0.02420387, -0.63016882],\n",
              "       [-1.51367256,  0.41397055],\n",
              "       [ 0.99980586, -0.66087881],\n",
              "       [-1.60676435, -1.45933833],\n",
              "       [-1.69985615, -0.87584868],\n",
              "       [-0.39657104,  0.8439103 ],\n",
              "       [-0.11729566,  2.28727944],\n",
              "       [-0.76893821, -1.24436846],\n",
              "       [ 0.16197972,  1.21243008],\n",
              "       [ 2.11690738, -0.93726864],\n",
              "       [-0.02420387, -1.21365848],\n",
              "       [ 1.18598945, -1.36720838],\n",
              "       [ 0.53434689, -0.23093906],\n",
              "       [ 0.90671407,  1.36597999],\n",
              "       [ 0.81362227, -1.55146827],\n",
              "       [ 1.18598945, -1.36720838],\n",
              "       [-1.04821359,  0.44468053],\n",
              "       [-1.23439718,  0.29113063],\n",
              "       [-0.02420387, -0.56874886],\n",
              "       [ 0.25507151,  1.51952989],\n",
              "       [-0.48966283, -0.13880912],\n",
              "       [-1.51367256, -1.12152853],\n",
              "       [ 0.34816331, -0.04667917],\n",
              "       [-0.86203001,  0.53681048],\n",
              "       [-0.11729566, -1.39791837],\n",
              "       [-0.39657104,  1.45810993],\n",
              "       [-1.51367256, -1.52075829],\n",
              "       [ 0.16197972, -0.23093906],\n",
              "       [-0.11729566, -0.69158879],\n",
              "       [-0.21038745,  1.30456002],\n",
              "       [-0.21038745, -0.01596919]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgt9hkf038gR",
        "outputId": "7ef9edba-1b76-4cc2-8a3c-ba7ff14c11f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "#Variabes to calculate sigmoid function\n",
        "y_pred = []\n",
        "len_x = len(X_train[0])\n",
        "w = []\n",
        "b = 0.2\n",
        "print(len_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LL2j3pe7ByI"
      },
      "outputs": [],
      "source": [
        "entries = len(X_train[:,0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_0YceD67P7_",
        "outputId": "bb24e19d-8e76-43d0-8d67-3203705f2840"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Vqv4ouK7SFH"
      },
      "outputs": [],
      "source": [
        "for weights in range(len_x):\n",
        "  w.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF2UitfL7cCn",
        "outputId": "b863ad3b-c3d4-46da-af81-acc944b58590"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZViyyMee7fRn"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return (1/(1+np.exp(-z)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm4tu11X7x4f"
      },
      "outputs": [],
      "source": [
        "def predict(inputs):\n",
        "  z=np.dot(inputs,w)+b\n",
        "  h=sigmoid(z)\n",
        "  for i in range((len(h))):\n",
        "    if(h[i]>=0.5):\n",
        "      h[i]=1\n",
        "    else:\n",
        "      h[i]=0\n",
        "  return h\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s1PF2K38mgP"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize.minpack import shape\n",
        "def loss_func(y,y1):\n",
        "  total_loss=np.sum(-y*np.log(y1)-(1-y)*np.log(1-y1))\n",
        "  m=y.shape[0]\n",
        "  j=total_loss/m\n",
        "  return j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7XMMhLCAGR3"
      },
      "outputs": [],
      "source": [
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "for x in range(len_x):\n",
        "  dw.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-bGRoimALtW",
        "outputId": "762b7944-3f9f-4764-9a56-f1fe2d72b86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round: 0 Weight: [0.02958692 0.01668477] Bias: 0.1800166002687522 loss: 0.728138869381592\n",
            "Round: 1 Weight: [0.05837634 0.03284235] Bias: 0.16052977733672263 loss: 0.7128192882175102\n",
            "Round: 2 Weight: [0.08638905 0.04848866] Bias: 0.14153035705536682 loss: 0.698323504164618\n",
            "Round: 3 Weight: [0.11364679 0.06364015] Bias: 0.12300830699723174 loss: 0.6846083559276838\n",
            "Round: 4 Weight: [0.14017197 0.07831362] Bias: 0.10495289345763967 loss: 0.6716315049965728\n",
            "Round: 5 Weight: [0.16598743 0.09252607] Bias: 0.08735283009614313 loss: 0.6593517304230658\n",
            "Round: 6 Weight: [0.19111621 0.10629448] Bias: 0.07019641580208034 loss: 0.6477291629566146\n",
            "Round: 7 Weight: [0.21558138 0.11963578] Bias: 0.05347166021270745 loss: 0.6367254628621289\n",
            "Round: 8 Weight: [0.23940589 0.13256665] Bias: 0.03716639604690687 loss: 0.6263039469490861\n",
            "Round: 9 Weight: [0.2626124  0.14510349] Bias: 0.021268378024426757 loss: 0.6164296710003092\n",
            "Round: 10 Weight: [0.28522318 0.15726231] Bias: 0.005765368616752357 loss: 0.607069474000315\n",
            "Round: 11 Weight: [0.30726005 0.1690587 ] Bias: -0.009354788771706625 loss: 0.5981919904326936\n",
            "Round: 12 Weight: [0.32874424 0.18050775] Bias: -0.024104108350601054 loss: 0.5897676365435496\n",
            "Round: 13 Weight: [0.3496964  0.19162406] Bias: -0.038494411227113896 loss: 0.5817685759408766\n",
            "Round: 14 Weight: [0.3701365  0.20242167] Bias: -0.052537284358765785 loss: 0.5741686692892768\n",
            "Round: 15 Weight: [0.39008385 0.21291409] Bias: -0.06624404809052467 loss: 0.5669434122205543\n",
            "Round: 16 Weight: [0.40955706 0.22311429] Bias: -0.07962573121560969 loss: 0.5600698649530369\n",
            "Round: 17 Weight: [0.42857404 0.23303465] Bias: -0.09269305255311205 loss: 0.5535265765225196\n",
            "Round: 18 Weight: [0.44715199 0.24268703] Bias: -0.10545640810803644 loss: 0.5472935059914751\n",
            "Round: 19 Weight: [0.4653074  0.25208276] Bias: -0.11792586296232818 loss: 0.5413519425285165\n",
            "Round: 20 Weight: [0.48305609 0.26123263] Bias: -0.1301111471326705 loss: 0.5356844258391521\n",
            "Round: 21 Weight: [0.5004132  0.27014694] Bias: -0.14202165471781594 loss: 0.5302746680797615\n",
            "Round: 22 Weight: [0.51739322 0.27883547] Bias: -0.15366644574186747 loss: 0.525107478095122\n",
            "Round: 23 Weight: [0.53400999 0.28730757] Bias: -0.16505425017826247 loss: 0.5201686885800273\n",
            "Round: 24 Weight: [0.55027674 0.29557209] Bias: -0.17619347371109365 loss: 0.515445086571267\n",
            "Round: 25 Weight: [0.56620613 0.30363749] Bias: -0.18709220485529565 loss: 0.5109243475211923\n",
            "Round: 26 Weight: [0.58181022 0.31151178] Bias: -0.19775822311505054 loss: 0.5065949730822531\n",
            "Round: 27 Weight: [0.59710055 0.3192026 ] Bias: -0.20819900791072532 loss: 0.5024462326377807\n",
            "Round: 28 Weight: [0.61208813 0.3267172 ] Bias: -0.2184217480491532 loss: 0.49846810854301915\n",
            "Round: 29 Weight: [0.62678346 0.33406248] Bias: -0.22843335155061467 loss: 0.49465124498772356\n",
            "Round: 30 Weight: [0.6411966 0.341245 ] Bias: -0.23824045567902877 loss: 0.49098690035391995\n",
            "Round: 31 Weight: [0.65533711 0.348271  ] Bias: -0.24784943705020424 loss: 0.48746690291659417\n",
            "Round: 32 Weight: [0.66921417 0.35514639] Bias: -0.2572664217170844 loss: 0.48408360971859377\n",
            "Round: 33 Weight: [0.68283651 0.36187684] Bias: -0.26649729515127973 loss: 0.4808298684418071\n",
            "Round: 34 Weight: [0.69621249 0.36846771] Bias: -0.2755477120573048 loss: 0.4776989820929981\n",
            "Round: 35 Weight: [0.7093501  0.37492411] Bias: -0.28442310597026826 loss: 0.4746846763231696\n",
            "Round: 36 Weight: [0.72225697 0.38125091] Bias: -0.2931286985996942 loss: 0.47178106920287743\n",
            "Round: 37 Weight: [0.73494039 0.38745274] Bias: -0.30166950889204225 loss: 0.46898264328166256\n",
            "Round: 38 Weight: [0.74740736 0.39353402] Bias: -0.3100503617926346 loss: 0.46628421976702206\n",
            "Round: 39 Weight: [0.75966455 0.39949896] Bias: -0.31827589669437173 loss: 0.46368093466655286\n",
            "Round: 40 Weight: [0.77171835 0.40535156] Bias: -0.3263505755660435 loss: 0.4611682167456897\n",
            "Round: 41 Weight: [0.78357489 0.41109567] Bias: -0.33427869075742755 loss: 0.45874176716248255\n",
            "Round: 42 Weight: [0.79524004 0.41673492] Bias: -0.3420643724818708 loss: 0.45639754064990756\n",
            "Round: 43 Weight: [0.80671941 0.42227281] Bias: -0.3497115959798303 loss: 0.45413172812509384\n",
            "Round: 44 Weight: [0.81801839 0.42771267] Bias: -0.357224188369015 loss: 0.45194074061346695\n",
            "Round: 45 Weight: [0.82914215 0.43305767] Bias: -0.3646058351884395 loss: 0.44982119438406415\n",
            "Round: 46 Weight: [0.84009564 0.43831086] Bias: -0.3718600866449481 loss: 0.447769897200122\n",
            "Round: 47 Weight: [0.85088362 0.44347513] Bias: -0.37899036357167737 loss: 0.4457838355964364\n",
            "Round: 48 Weight: [0.86151065 0.44855328] Bias: -0.38599996310855544 loss: 0.4438601631019354\n",
            "Round: 49 Weight: [0.87198112 0.45354796] Bias: -0.39289206411533634 loss: 0.44199618933238943\n",
            "Round: 50 Weight: [0.88229925 0.45846172] Bias: -0.3996697323278881 loss: 0.44018936988420887\n",
            "Round: 51 Weight: [0.89246908 0.463297  ] Bias: -0.4063359252685236 loss: 0.4384372969658686\n",
            "Round: 52 Weight: [0.90249451 0.46805613] Bias: -0.412893496921116 loss: 0.43673769070867025\n",
            "Round: 53 Weight: [0.91237929 0.47274136] Bias: -0.4193452021816046 loss: 0.43508839110331865\n",
            "Round: 54 Weight: [0.92212702 0.47735483] Bias: -0.42569370109428445 loss: 0.43348735051318615\n",
            "Round: 55 Weight: [0.93174117 0.4818986 ] Bias: -0.43194156288401186 loss: 0.431932626719173\n",
            "Round: 56 Weight: [0.94122509 0.48637465] Bias: -0.4380912697941515 loss: 0.43042237645479076\n",
            "Round: 57 Weight: [0.95058199 0.49078488] Bias: -0.4441452207397587 loss: 0.42895484939349293\n",
            "Round: 58 Weight: [0.95981499 0.49513111] Bias: -0.4501057347851376 loss: 0.4275283825534065\n",
            "Round: 59 Weight: [0.96892708 0.4994151 ] Bias: -0.45597505445455194 loss: 0.42614139508747656\n",
            "Round: 60 Weight: [0.97792113 0.50363852] Bias: -0.46175534888449365 loss: 0.4247923834296573\n",
            "Round: 61 Weight: [0.98679995 0.507803  ] Bias: -0.4674487168255444 loss: 0.4234799167701831\n",
            "Round: 62 Weight: [0.99556621 0.5119101 ] Bias: -0.473057189501496 loss: 0.4222026328351494\n",
            "Round: 63 Weight: [1.00422252 0.51596131] Bias: -0.47858273333303347 loss: 0.4209592339476443\n",
            "Round: 64 Weight: [1.01277138 0.51995807] Bias: -0.48402725253292983 loss: 0.4197484833495097\n",
            "Round: 65 Weight: [1.02121521 0.52390178] Bias: -0.4893925915793571 loss: 0.4185692017644986\n",
            "Round: 66 Weight: [1.02955637 0.52779378] Bias: -0.4946805375735856 loss: 0.41742026418513006\n",
            "Round: 67 Weight: [1.0377971  0.53163535] Bias: -0.49989282248802097 loss: 0.4163005968669614\n",
            "Round: 68 Weight: [1.04593962 0.53542774] Bias: -0.5050311253102207 loss: 0.4152091745152815\n",
            "Round: 69 Weight: [1.05398602 0.53917215] Bias: -0.5100970740882359 loss: 0.41414501765041756\n",
            "Round: 70 Weight: [1.06193838 0.54286973] Bias: -0.5150922478823428 loss: 0.4131071901389274\n",
            "Round: 71 Weight: [1.06979867 0.54652161] Bias: -0.5200181786279549 loss: 0.41209479687894307\n",
            "Round: 72 Weight: [1.07756881 0.55012885] Bias: -0.5248763529142568 loss: 0.41110698162884274\n",
            "Round: 73 Weight: [1.08525068 0.5536925 ] Bias: -0.5296682136828503 loss: 0.4101429249692592\n",
            "Round: 74 Weight: [1.09284607 0.55721357] Bias: -0.5343951618504749 loss: 0.4092018423892006\n",
            "Round: 75 Weight: [1.10035675 0.56069303] Bias: -0.5390585578596456 loss: 0.40828298248776174\n",
            "Round: 76 Weight: [1.1077844  0.56413182] Bias: -0.5436597231608422 loss: 0.4073856252835456\n",
            "Round: 77 Weight: [1.11513068 0.56753084] Bias: -0.5481999416296849 loss: 0.40650908062451085\n",
            "Round: 78 Weight: [1.12239718 0.57089097] Bias: -0.5526804609223493 loss: 0.40565268669150195\n",
            "Round: 79 Weight: [1.12958546 0.57421307] Bias: -0.5571024937722944 loss: 0.40481580858921973\n",
            "Round: 80 Weight: [1.13669703 0.57749795] Bias: -0.5614672192312093 loss: 0.4039978370188501\n",
            "Round: 81 Weight: [1.14373333 0.58074642] Bias: -0.5657757838569333 loss: 0.40319818702699156\n",
            "Round: 82 Weight: [1.1506958  0.58395924] Bias: -0.5700293028509466 loss: 0.40241629682591157\n",
            "Round: 83 Weight: [1.15758582 0.58713716] Bias: -0.574228861147897 loss: 0.4016516266805207\n",
            "Round: 84 Weight: [1.16440473 0.5902809 ] Bias: -0.5783755144594902 loss: 0.40090365785778365\n",
            "Round: 85 Weight: [1.17115382 0.59339117] Bias: -0.5824702902749478 loss: 0.4001718916345927\n",
            "Round: 86 Weight: [1.17783438 0.59646865] Bias: -0.586514188820121 loss: 0.3994558483604069\n",
            "Round: 87 Weight: [1.18444763 0.59951399] Bias: -0.5905081839772339 loss: 0.39875506657122384\n",
            "Round: 88 Weight: [1.19099478 0.60252784] Bias: -0.5944532241671283 loss: 0.398069102151687\n",
            "Round: 89 Weight: [1.19747699 0.60551082] Bias: -0.5983502331957801 loss: 0.39739752754235536\n",
            "Round: 90 Weight: [1.2038954  0.60846352] Bias: -0.6022001110667664 loss: 0.39673993098936466\n",
            "Round: 91 Weight: [1.21025112 0.61138653] Bias: -0.6060037347612739 loss: 0.39609591583390125\n",
            "Round: 92 Weight: [1.21654522 0.61428043] Bias: -0.6097619589871536 loss: 0.39546509983908007\n",
            "Round: 93 Weight: [1.22277875 0.61714576] Bias: -0.6134756168984524 loss: 0.394847114551988\n",
            "Round: 94 Weight: [1.22895275 0.61998306] Bias: -0.6171455207867759 loss: 0.394241604698794\n",
            "Round: 95 Weight: [1.2350682  0.62279285] Bias: -0.620772462745765 loss: 0.3936482276109757\n",
            "Round: 96 Weight: [1.24112607 0.62557563] Bias: -0.6243572153099086 loss: 0.39306665268083485\n",
            "Round: 97 Weight: [1.24712732 0.6283319 ] Bias: -0.6279005320688453 loss: 0.3924965608445972\n",
            "Round: 98 Weight: [1.25307287 0.63106213] Bias: -0.6314031482582548 loss: 0.3919376440915005\n",
            "Round: 99 Weight: [1.25896362 0.6337668 ] Bias: -0.6348657813283792 loss: 0.39138960499738024\n",
            "Round: 100 Weight: [1.26480045 0.63644635] Bias: -0.638289131491165 loss: 0.3908521562813569\n",
            "Round: 101 Weight: [1.27058421 0.63910123] Bias: -0.6416738822469654 loss: 0.39032502038431666\n",
            "Round: 102 Weight: [1.27631575 0.64173186] Bias: -0.6450207008916977 loss: 0.389807929067963\n",
            "Round: 103 Weight: [1.28199588 0.64433866] Bias: -0.6483302390053023 loss: 0.3893006230332897\n",
            "Round: 104 Weight: [1.2876254  0.64692204] Bias: -0.6516031329223133 loss: 0.3888028515574025\n",
            "Round: 105 Weight: [1.29320508 0.64948239] Bias: -0.6548400041853072 loss: 0.388314372147677\n",
            "Round: 106 Weight: [1.2987357 0.6520201] Bias: -0.6580414599819597 loss: 0.3878349502123091\n",
            "Round: 107 Weight: [1.30421799 0.65453554] Bias: -0.6612080935664061 loss: 0.38736435874636765\n",
            "Round: 108 Weight: [1.30965268 0.65702909] Bias: -0.6643404846655663 loss: 0.3869023780325139\n",
            "Round: 109 Weight: [1.31504048 0.65950109] Bias: -0.6674391998710643 loss: 0.386448795355606\n",
            "Round: 110 Weight: [1.32038208 0.66195191] Bias: -0.6705047930173414 loss: 0.3860034047304468\n",
            "Round: 111 Weight: [1.32567817 0.66438186] Bias: -0.6735378055465353 loss: 0.38556600664198676\n",
            "Round: 112 Weight: [1.3309294 0.6667913] Bias: -0.676538766860667 loss: 0.3851364077973253\n",
            "Round: 113 Weight: [1.33613643 0.66918054] Bias: -0.6795081946616576 loss: 0.38471442088889823\n",
            "Round: 114 Weight: [1.34129989 0.67154989] Bias: -0.6824465952796654 loss: 0.38429986436827446\n",
            "Round: 115 Weight: [1.3464204  0.67389966] Bias: -0.6853544639902197 loss: 0.38389256223001467\n",
            "Round: 116 Weight: [1.35149857 0.67623016] Bias: -0.6882322853205954 loss: 0.3834923438050803\n",
            "Round: 117 Weight: [1.35653499 0.67854167] Bias: -0.6910805333458628 loss: 0.38309904356331015\n",
            "Round: 118 Weight: [1.36153025 0.68083448] Bias: -0.6938996719750188 loss: 0.3827125009245055\n",
            "Round: 119 Weight: [1.36648491 0.68310888] Bias: -0.6966901552275914 loss: 0.38233256007769617\n",
            "Round: 120 Weight: [1.37139953 0.68536513] Bias: -0.6994524275010915 loss: 0.3819590698081791\n",
            "Round: 121 Weight: [1.37627467 0.68760351] Bias: -0.702186923829668 loss: 0.3815918833319476\n",
            "Round: 122 Weight: [1.38111085 0.68982427] Bias: -0.7048940701343058 loss: 0.3812308581371476\n",
            "Round: 123 Weight: [1.3859086  0.69202766] Bias: -0.707574283464895 loss: 0.38087585583221956\n",
            "Round: 124 Weight: [1.39066843 0.69421394] Bias: -0.7102279722344792 loss: 0.38052674200040176\n",
            "Round: 125 Weight: [1.39539084 0.69638335] Bias: -0.7128555364459831 loss: 0.3801833860602897\n",
            "Round: 126 Weight: [1.40007634 0.69853613] Bias: -0.7154573679117022 loss: 0.3798456611321617\n",
            "Round: 127 Weight: [1.40472539 0.70067251] Bias: -0.7180338504658279 loss: 0.37951344390979735\n",
            "Round: 128 Weight: [1.40933848 0.70279272] Bias: -0.7205853601702674 loss: 0.3791866145375292\n",
            "Round: 129 Weight: [1.41391608 0.70489698] Bias: -0.7231122655140089 loss: 0.3788650564922824\n",
            "Round: 130 Weight: [1.41845862 0.7069855 ] Bias: -0.7256149276062693 loss: 0.37854865647036995\n",
            "Round: 131 Weight: [1.42296657 0.70905851] Bias: -0.7280937003636546 loss: 0.37823730427882346\n",
            "Round: 132 Weight: [1.42744037 0.71111622] Bias: -0.7305489306915499 loss: 0.3779308927310504\n",
            "Round: 133 Weight: [1.43188043 0.71315881] Bias: -0.7329809586599503 loss: 0.37762931754661955\n",
            "Round: 134 Weight: [1.43628718 0.71518651] Bias: -0.7353901176739325 loss: 0.37733247725498786\n",
            "Round: 135 Weight: [1.44066104 0.71719949] Bias: -0.7377767346389604 loss: 0.3770402731029898\n",
            "Round: 136 Weight: [1.44500241 0.71919796] Bias: -0.7401411301212093 loss: 0.3767526089659206\n",
            "Round: 137 Weight: [1.44931169 0.7211821 ] Bias: -0.7424836185030844 loss: 0.3764693912620521\n",
            "Round: 138 Weight: [1.45358927 0.7231521 ] Bias: -0.7448045081341055 loss: 0.37619052887043036\n",
            "Round: 139 Weight: [1.45783553 0.72510813] Bias: -0.7471041014773188 loss: 0.3759159330518087\n",
            "Round: 140 Weight: [1.46205086 0.72705037] Bias: -0.7493826952513937 loss: 0.37564551737257934\n",
            "Round: 141 Weight: [1.46623562 0.728979  ] Bias: -0.7516405805685534 loss: 0.37537919763157257\n",
            "Round: 142 Weight: [1.47039018 0.73089419] Bias: -0.7538780430684842 loss: 0.37511689178959967\n",
            "Round: 143 Weight: [1.47451489 0.7327961 ] Bias: -0.7560953630483607 loss: 0.3748585199016201\n",
            "Round: 144 Weight: [1.4786101 0.7346849] Bias: -0.7582928155891211 loss: 0.37460400405142275\n",
            "Round: 145 Weight: [1.48267616 0.73656074] Bias: -0.7604706706781194 loss: 0.37435326828871085\n",
            "Round: 146 Weight: [1.48671341 0.73842378] Bias: -0.7626291933282763 loss: 0.37410623856849184\n",
            "Round: 147 Weight: [1.49072217 0.74027418] Bias: -0.7647686436938488 loss: 0.3738628426926733\n",
            "Round: 148 Weight: [1.49470278 0.74211209] Bias: -0.7668892771829293 loss: 0.37362301025377265\n",
            "Round: 149 Weight: [1.49865556 0.74393765] Bias: -0.7689913445667849 loss: 0.3733866725806538\n",
            "Round: 150 Weight: [1.50258082 0.74575102] Bias: -0.77107509208614 loss: 0.3731537626862044\n",
            "Round: 151 Weight: [1.50647887 0.74755233] Bias: -0.773140761554505 loss: 0.37292421521687735\n",
            "Round: 152 Weight: [1.51035003 0.74934173] Bias: -0.7751885904586456 loss: 0.37269796640401553\n",
            "Round: 153 Weight: [1.51419458 0.75111934] Bias: -0.7772188120562883 loss: 0.3724749540168919\n",
            "Round: 154 Weight: [1.51801282 0.75288531] Bias: -0.7792316554711489 loss: 0.37225511731739186\n",
            "Round: 155 Weight: [1.52180505 0.75463978] Bias: -0.7812273457853741 loss: 0.3720383970162734\n",
            "Round: 156 Weight: [1.52557154 0.75638286] Bias: -0.7832061041294757 loss: 0.3718247352309418\n",
            "Round: 157 Weight: [1.52931259 0.75811468] Bias: -0.7851681477698398 loss: 0.37161407544467756\n",
            "Round: 158 Weight: [1.53302846 0.75983539] Bias: -0.7871136901938878 loss: 0.37140636246726083\n",
            "Round: 159 Weight: [1.53671943 0.76154508] Bias: -0.7890429411929623 loss: 0.3712015423969374\n",
            "Round: 160 Weight: [1.54038576 0.76324389] Bias: -0.7909561069430107 loss: 0.37099956258367217\n",
            "Round: 161 Weight: [1.54402772 0.76493194] Bias: -0.7928533900831354 loss: 0.3708003715936419\n",
            "Round: 162 Weight: [1.54764556 0.76660935] Bias: -0.7947349897920764 loss: 0.37060391917491764\n",
            "Round: 163 Weight: [1.55123955 0.76827622] Bias: -0.796601101862691 loss: 0.3704101562242915\n",
            "Round: 164 Weight: [1.55480993 0.76993267] Bias: -0.7984519187744924 loss: 0.3702190347552036\n",
            "Round: 165 Weight: [1.55835695 0.77157881] Bias: -0.8002876297643065 loss: 0.37003050786672775\n",
            "Round: 166 Weight: [1.56188084 0.77321475] Bias: -0.8021084208951044 loss: 0.3698445297135742\n",
            "Round: 167 Weight: [1.56538186 0.7748406 ] Bias: -0.8039144751230669 loss: 0.3696610554770728\n",
            "Round: 168 Weight: [1.56886024 0.77645647] Bias: -0.8057059723629334 loss: 0.3694800413370986\n",
            "Round: 169 Weight: [1.5723162  0.77806245] Bias: -0.8074830895516875 loss: 0.3693014444449045\n",
            "Round: 170 Weight: [1.57574998 0.77965865] Bias: -0.8092460007106289 loss: 0.3691252228968278\n",
            "Round: 171 Weight: [1.5791618  0.78124518] Bias: -0.8109948770058808 loss: 0.36895133570883804\n",
            "Round: 172 Weight: [1.58255188 0.78282212] Bias: -0.8127298868073769 loss: 0.3687797427918946\n",
            "Round: 173 Weight: [1.58592044 0.78438957] Bias: -0.8144511957463759 loss: 0.36861040492808533\n",
            "Round: 174 Weight: [1.5892677  0.78594764] Bias: -0.8161589667715445 loss: 0.36844328374751656\n",
            "Round: 175 Weight: [1.59259387 0.78749642] Bias: -0.8178533602036522 loss: 0.36827834170592855\n",
            "Round: 176 Weight: [1.59589915 0.78903599] Bias: -0.8195345337889172 loss: 0.3681155420630086\n",
            "Round: 177 Weight: [1.59918376 0.79056645] Bias: -0.8212026427510442 loss: 0.3679548488613783\n",
            "Round: 178 Weight: [1.60244789 0.79208789] Bias: -0.8228578398419902 loss: 0.36779622690622904\n",
            "Round: 179 Weight: [1.60569174 0.79360039] Bias: -0.824500275391496 loss: 0.3676396417455851\n",
            "Round: 180 Weight: [1.60891552 0.79510405] Bias: -0.8261300973554176 loss: 0.3674850596511689\n",
            "Round: 181 Weight: [1.6121194  0.79659895] Bias: -0.8277474513628938 loss: 0.36733244759985056\n",
            "Round: 182 Weight: [1.6153036  0.79808518] Bias: -0.8293524807623802 loss: 0.36718177325565854\n",
            "Round: 183 Weight: [1.61846829 0.79956281] Bias: -0.8309453266665839 loss: 0.3670330049523333\n",
            "Round: 184 Weight: [1.62161366 0.80103192] Bias: -0.8325261279963291 loss: 0.3668861116764042\n",
            "Round: 185 Weight: [1.62473989 0.80249261] Bias: -0.8340950215233826 loss: 0.36674106305077286\n",
            "Round: 186 Weight: [1.62784717 0.80394494] Bias: -0.8356521419122699 loss: 0.36659782931878354\n",
            "Round: 187 Weight: [1.63093567 0.805389  ] Bias: -0.8371976217611087 loss: 0.3664563813287655\n",
            "Round: 188 Weight: [1.63400557 0.80682487] Bias: -0.838731591641487 loss: 0.3663166905190307\n",
            "Round: 189 Weight: [1.63705703 0.80825261] Bias: -0.8402541801374127 loss: 0.3661787289033112\n",
            "Round: 190 Weight: [1.64009024 0.8096723 ] Bias: -0.8417655138833596 loss: 0.36604246905662174\n",
            "Round: 191 Weight: [1.64310536 0.81108402] Bias: -0.8432657176014347 loss: 0.36590788410153235\n",
            "Round: 192 Weight: [1.64610256 0.81248784] Bias: -0.8447549141376904 loss: 0.365774947694839\n",
            "Round: 193 Weight: [1.649082   0.81388383] Bias: -0.8462332244976056 loss: 0.3656436340146164\n",
            "Round: 194 Weight: [1.65204384 0.81527207] Bias: -0.8477007678807564 loss: 0.3655139177476439\n",
            "Round: 195 Weight: [1.65498824 0.81665261] Bias: -0.8491576617146998 loss: 0.36538577407718736\n",
            "Round: 196 Weight: [1.65791536 0.81802553] Bias: -0.8506040216880902 loss: 0.3652591786711303\n",
            "Round: 197 Weight: [1.66082535 0.8193909 ] Bias: -0.8520399617830509 loss: 0.3651341076704389\n",
            "Round: 198 Weight: [1.66371838 0.82074878] Bias: -0.853465594306817 loss: 0.3650105376779533\n",
            "Round: 199 Weight: [1.66659458 0.82209924] Bias: -0.8548810299226731 loss: 0.3648884457474906\n",
            "Round: 200 Weight: [1.66945411 0.82344234] Bias: -0.8562863776802008 loss: 0.3647678093732539\n",
            "Round: 201 Weight: [1.67229712 0.82477816] Bias: -0.8576817450448556 loss: 0.3646486064795348\n",
            "Round: 202 Weight: [1.67512374 0.82610674] Bias: -0.8590672379268917 loss: 0.3645308154106996\n",
            "Round: 203 Weight: [1.67793414 0.82742815] Bias: -0.8604429607096485 loss: 0.36441441492145255\n",
            "Round: 204 Weight: [1.68072844 0.82874245] Bias: -0.8618090162772193 loss: 0.3642993841673653\n",
            "Round: 205 Weight: [1.68350678 0.83004971] Bias: -0.863165506041514 loss: 0.3641857026956646\n",
            "Round: 206 Weight: [1.68626931 0.83134999] Bias: -0.8645125299687351 loss: 0.36407335043627065\n",
            "Round: 207 Weight: [1.68901616 0.83264333] Bias: -0.8658501866052792 loss: 0.3639623076930778\n",
            "Round: 208 Weight: [1.69174747 0.83392981] Bias: -0.8671785731030801 loss: 0.36385255513547\n",
            "Round: 209 Weight: [1.69446337 0.83520947] Bias: -0.8684977852444068 loss: 0.3637440737900637\n",
            "Round: 210 Weight: [1.69716399 0.83648238] Bias: -0.8698079174661308 loss: 0.3636368450326719\n",
            "Round: 211 Weight: [1.69984945 0.83774859] Bias: -0.8711090628834761 loss: 0.36353085058048135\n",
            "Round: 212 Weight: [1.7025199  0.83900815] Bias: -0.8724013133132636 loss: 0.363426072484437\n",
            "Round: 213 Weight: [1.70517544 0.84026112] Bias: -0.8736847592966644 loss: 0.36332249312182735\n",
            "Round: 214 Weight: [1.70781622 0.84150755] Bias: -0.8749594901214726 loss: 0.36322009518906495\n",
            "Round: 215 Weight: [1.71044235 0.8427475 ] Bias: -0.8762255938439102 loss: 0.3631188616946549\n",
            "Round: 216 Weight: [1.71305396 0.84398102] Bias: -0.8774831573099761 loss: 0.3630187759523472\n",
            "Round: 217 Weight: [1.71565116 0.84520816] Bias: -0.8787322661763488 loss: 0.36291982157446634\n",
            "Round: 218 Weight: [1.71823407 0.84642896] Bias: -0.8799730049308561 loss: 0.36282198246541353\n",
            "Round: 219 Weight: [1.72080282 0.84764349] Bias: -0.8812054569125192 loss: 0.3627252428153357\n",
            "Round: 220 Weight: [1.72335751 0.84885179] Bias: -0.8824297043311853 loss: 0.3626295870939568\n",
            "Round: 221 Weight: [1.72589827 0.85005391] Bias: -0.8836458282867553 loss: 0.36253500004456707\n",
            "Round: 222 Weight: [1.7284252 0.8512499] Bias: -0.8848539087880185 loss: 0.3624414666781643\n",
            "Round: 223 Weight: [1.73093842 0.8524398 ] Bias: -0.8860540247711022 loss: 0.3623489722677438\n",
            "Round: 224 Weight: [1.73343804 0.85362367] Bias: -0.8872462541175472 loss: 0.3622575023427323\n",
            "Round: 225 Weight: [1.73592416 0.85480154] Bias: -0.8884306736720162 loss: 0.3621670426835614\n",
            "Round: 226 Weight: [1.7383969  0.85597348] Bias: -0.8896073592596452 loss: 0.36207757931637735\n",
            "Round: 227 Weight: [1.74085637 0.85713951] Bias: -0.8907763857030456 loss: 0.36198909850788186\n",
            "Round: 228 Weight: [1.74330266 0.85829969] Bias: -0.891937826838966 loss: 0.36190158676030126\n",
            "Round: 229 Weight: [1.74573589 0.85945407] Bias: -0.8930917555346203 loss: 0.36181503080648053\n",
            "Round: 230 Weight: [1.74815615 0.86060268] Bias: -0.8942382437036914 loss: 0.3617294176050968\n",
            "Round: 231 Weight: [1.75056355 0.86174557] Bias: -0.8953773623220178 loss: 0.3616447343359921\n",
            "Round: 232 Weight: [1.75295819 0.86288278] Bias: -0.896509181442969 loss: 0.3615609683956179\n",
            "Round: 233 Weight: [1.75534017 0.86401435] Bias: -0.897633770212519 loss: 0.36147810739259295\n",
            "Round: 234 Weight: [1.75770959 0.86514033] Bias: -0.8987511968840236 loss: 0.36139613914336666\n",
            "Round: 235 Weight: [1.76006654 0.86626076] Bias: -0.8998615288327083 loss: 0.36131505166798844\n",
            "Round: 236 Weight: [1.76241113 0.86737568] Bias: -0.9009648325698744 loss: 0.36123483318597854\n",
            "Round: 237 Weight: [1.76474344 0.86848513] Bias: -0.9020611737568279 loss: 0.36115547211229765\n",
            "Round: 238 Weight: [1.76706357 0.86958915] Bias: -0.9031506172185403 loss: 0.36107695705341303\n",
            "Round: 239 Weight: [1.76937161 0.87068777] Bias: -0.904233226957044 loss: 0.36099927680345795\n",
            "Round: 240 Weight: [1.77166767 0.87178105] Bias: -0.9053090661645712 loss: 0.3609224203404821\n",
            "Round: 241 Weight: [1.77395182 0.87286901] Bias: -0.9063781972364404 loss: 0.36084637682279114\n",
            "Round: 242 Weight: [1.77622415 0.8739517 ] Bias: -0.907440681783697 loss: 0.36077113558537094\n",
            "Round: 243 Weight: [1.77848477 0.87502915] Bias: -0.9084965806455126 loss: 0.3606966861363976\n",
            "Round: 244 Weight: [1.78073375 0.87610141] Bias: -0.9095459539013497 loss: 0.3606230181538268\n",
            "Round: 245 Weight: [1.78297118 0.8771685 ] Bias: -0.9105888608828955 loss: 0.36055012148206445\n",
            "Round: 246 Weight: [1.78519715 0.87823046] Bias: -0.9116253601857709 loss: 0.3604779861287128\n",
            "Round: 247 Weight: [1.78741175 0.87928734] Bias: -0.9126555096810198 loss: 0.36040660226139287\n",
            "Round: 248 Weight: [1.78961505 0.88033916] Bias: -0.9136793665263827 loss: 0.36033596020463937\n",
            "Round: 249 Weight: [1.79180715 0.88138597] Bias: -0.9146969871773597 loss: 0.36026605043686705\n",
            "Round: 250 Weight: [1.79398812 0.88242779] Bias: -0.9157084273980679 loss: 0.36019686358740605\n",
            "Round: 251 Weight: [1.79615804 0.88346467] Bias: -0.9167137422718973 loss: 0.36012839043360517\n",
            "Round: 252 Weight: [1.79831701 0.88449663] Bias: -0.9177129862119691 loss: 0.3600606218980003\n",
            "Round: 253 Weight: [1.80046509 0.88552371] Bias: -0.918706212971402 loss: 0.35999354904554715\n",
            "Round: 254 Weight: [1.80260237 0.88654595] Bias: -0.9196934756533892 loss: 0.3599271630809163\n",
            "Round: 255 Weight: [1.80472893 0.88756337] Bias: -0.9206748267210908 loss: 0.35986145534584835\n",
            "Round: 256 Weight: [1.80684483 0.88857602] Bias: -0.9216503180073459 loss: 0.3597964173165693\n",
            "Round: 257 Weight: [1.80895017 0.88958391] Bias: -0.9226200007242075 loss: 0.3597320406012623\n",
            "Round: 258 Weight: [1.81104501 0.8905871 ] Bias: -0.9235839254723046 loss: 0.3596683169375963\n",
            "Round: 259 Weight: [1.81312944 0.89158559] Bias: -0.9245421422500352 loss: 0.3596052381903092\n",
            "Round: 260 Weight: [1.81520352 0.89257944] Bias: -0.9254947004625922 loss: 0.35954279634884373\n",
            "Round: 261 Weight: [1.81726733 0.89356867] Bias: -0.9264416489308288 loss: 0.3594809835250361\n",
            "Round: 262 Weight: [1.81932094 0.89455331] Bias: -0.9273830358999637 loss: 0.35941979195085483\n",
            "Round: 263 Weight: [1.82136442 0.89553339] Bias: -0.9283189090481313 loss: 0.35935921397618853\n",
            "Round: 264 Weight: [1.82339785 0.89650894] Bias: -0.9292493154947791 loss: 0.3592992420666825\n",
            "Round: 265 Weight: [1.8254213  0.89747999] Bias: -0.9301743018089166 loss: 0.35923986880162173\n",
            "Round: 266 Weight: [1.82743483 0.89844658] Bias: -0.9310939140172175 loss: 0.3591810868718594\n",
            "Round: 267 Weight: [1.82943852 0.89940872] Bias: -0.9320081976119794 loss: 0.3591228890777908\n",
            "Round: 268 Weight: [1.83143244 0.90036646] Bias: -0.9329171975589428 loss: 0.3590652683273694\n",
            "Round: 269 Weight: [1.83341664 0.90131982] Bias: -0.9338209583049732 loss: 0.35900821763416674\n",
            "Round: 270 Weight: [1.83539121 0.90226882] Bias: -0.9347195237856094 loss: 0.3589517301154725\n",
            "Round: 271 Weight: [1.8373562 0.9032135] Bias: -0.9356129374324784 loss: 0.3588957989904352\n",
            "Round: 272 Weight: [1.83931169 0.90415388] Bias: -0.9365012421805836 loss: 0.35884041757824303\n",
            "Round: 273 Weight: [1.84125773 0.90508999] Bias: -0.9373844804754645 loss: 0.3587855792963415\n",
            "Round: 274 Weight: [1.84319439 0.90602186] Bias: -0.9382626942802343 loss: 0.35873127765868995\n",
            "Round: 275 Weight: [1.84512174 0.90694952] Bias: -0.9391359250824949 loss: 0.358677506274054\n",
            "Round: 276 Weight: [1.84703984 0.90787299] Bias: -0.9400042139011338 loss: 0.3586242588443332\n",
            "Round: 277 Weight: [1.84894876 0.9087923 ] Bias: -0.9408676012930042 loss: 0.35857152916292456\n",
            "Round: 278 Weight: [1.85084854 0.90970748] Bias: -0.9417261273594911 loss: 0.3585193111131192\n",
            "Round: 279 Weight: [1.85273927 0.91061855] Bias: -0.9425798317529653 loss: 0.35846759866653166\n",
            "Round: 280 Weight: [1.85462099 0.91152554] Bias: -0.943428753683128 loss: 0.35841638588156344\n",
            "Round: 281 Weight: [1.85649377 0.91242847] Bias: -0.9442729319232473 loss: 0.3583656669018959\n",
            "Round: 282 Weight: [1.85835766 0.91332737] Bias: -0.9451124048162908 loss: 0.35831543595501536\n",
            "Round: 283 Weight: [1.86021274 0.91422227] Bias: -0.9459472102809526 loss: 0.35826568735076825\n",
            "Round: 284 Weight: [1.86205904 0.91511318] Bias: -0.9467773858175816 loss: 0.35821641547994443\n",
            "Round: 285 Weight: [1.86389665 0.91600014] Bias: -0.9476029685140084 loss: 0.3581676148128911\n",
            "Round: 286 Weight: [1.8657256  0.91688317] Bias: -0.9484239950512758 loss: 0.3581192798981533\n",
            "Round: 287 Weight: [1.86754596 0.91776229] Bias: -0.9492405017092745 loss: 0.358071405361142\n",
            "Round: 288 Weight: [1.86935779 0.91863753] Bias: -0.9500525243722838 loss: 0.3580239859028295\n",
            "Round: 289 Weight: [1.87116114 0.9195089 ] Bias: -0.9508600985344212 loss: 0.35797701629847084\n",
            "Round: 290 Weight: [1.87295606 0.92037645] Bias: -0.9516632593050024 loss: 0.35793049139634964\n",
            "Round: 291 Weight: [1.87474262 0.92124018] Bias: -0.9524620414138124 loss: 0.35788440611655054\n",
            "Round: 292 Weight: [1.87652086 0.92210012] Bias: -0.9532564792162903 loss: 0.35783875544975496\n",
            "Round: 293 Weight: [1.87829084 0.9229563 ] Bias: -0.9540466066986292 loss: 0.35779353445606066\n",
            "Round: 294 Weight: [1.88005262 0.92380873] Bias: -0.9548324574827922 loss: 0.3577487382638249\n",
            "Round: 295 Weight: [1.88180624 0.92465744] Bias: -0.9556140648314481 loss: 0.35770436206853035\n",
            "Round: 296 Weight: [1.88355176 0.92550246] Bias: -0.9563914616528252 loss: 0.35766040113167263\n",
            "Round: 297 Weight: [1.88528924 0.9263438 ] Bias: -0.9571646805054879 loss: 0.3576168507796706\n",
            "Round: 298 Weight: [1.88701871 0.92718148] Bias: -0.957933753603035 loss: 0.3575737064027967\n",
            "Round: 299 Weight: [1.88874024 0.92801554] Bias: -0.9586987128187231 loss: 0.3575309634541289\n",
            "Round: 300 Weight: [1.89045387 0.92884598] Bias: -0.9594595896900154 loss: 0.35748861744852234\n",
            "Round: 301 Weight: [1.89215966 0.92967283] Bias: -0.9602164154230576 loss: 0.3574466639616017\n",
            "Round: 302 Weight: [1.89385765 0.93049612] Bias: -0.960969220897082 loss: 0.35740509862877134\n",
            "Round: 303 Weight: [1.8955479  0.93131586] Bias: -0.9617180366687421 loss: 0.35736391714424626\n",
            "Round: 304 Weight: [1.89723044 0.93213207] Bias: -0.9624628929763774 loss: 0.35732311526010024\n",
            "Round: 305 Weight: [1.89890534 0.93294478] Bias: -0.9632038197442115 loss: 0.3572826887853329\n",
            "Round: 306 Weight: [1.90057264 0.933754  ] Bias: -0.9639408465864829 loss: 0.3572426335849539\n",
            "Round: 307 Weight: [1.90223238 0.93455976] Bias: -0.9646740028115112 loss: 0.3572029455790847\n",
            "Round: 308 Weight: [1.90388462 0.93536207] Bias: -0.9654033174256993 loss: 0.3571636207420777\n",
            "Round: 309 Weight: [1.9055294  0.93616096] Bias: -0.9661288191374727 loss: 0.35712465510165137\n",
            "Round: 310 Weight: [1.90716676 0.93695644] Bias: -0.9668505363611571 loss: 0.3570860447380416\n",
            "Round: 311 Weight: [1.90879675 0.93774854] Bias: -0.9675684972207959 loss: 0.35704778578316976\n",
            "Round: 312 Weight: [1.91041943 0.93853728] Bias: -0.968282729553907 loss: 0.3570098744198252\n",
            "Round: 313 Weight: [1.91203483 0.93932267] Bias: -0.9689932609151835 loss: 0.3569723068808636\n",
            "Round: 314 Weight: [1.91364299 0.94010473] Bias: -0.9697001185801346 loss: 0.35693507944842023\n",
            "Round: 315 Weight: [1.91524397 0.94088349] Bias: -0.9704033295486723 loss: 0.3568981884531375\n",
            "Round: 316 Weight: [1.9168378  0.94165895] Bias: -0.9711029205486414 loss: 0.35686163027340645\n",
            "Round: 317 Weight: [1.91842453 0.94243115] Bias: -0.9717989180392963 loss: 0.3568254013346231\n",
            "Round: 318 Weight: [1.92000421 0.94320009] Bias: -0.9724913482147236 loss: 0.356789498108458\n",
            "Round: 319 Weight: [1.92157687 0.9439658 ] Bias: -0.973180237007213 loss: 0.3567539171121386\n",
            "Round: 320 Weight: [1.92314256 0.9447283 ] Bias: -0.9738656100905768 loss: 0.3567186549077453\n",
            "Round: 321 Weight: [1.92470132 0.94548759] Bias: -0.9745474928834185 loss: 0.3566837081015202\n",
            "Round: 322 Weight: [1.9262532  0.94624371] Bias: -0.9752259105523517 loss: 0.35664907334318885\n",
            "Round: 323 Weight: [1.92779822 0.94699667] Bias: -0.9759008880151716 loss: 0.3566147473252926\n",
            "Round: 324 Weight: [1.92933645 0.94774649] Bias: -0.9765724499439763 loss: 0.35658072678253533\n",
            "Round: 325 Weight: [1.9308679  0.94849318] Bias: -0.9772406207682433 loss: 0.3565470084911401\n",
            "Round: 326 Weight: [1.93239264 0.94923676] Bias: -0.9779054246778587 loss: 0.356513589268218\n",
            "Round: 327 Weight: [1.93391069 0.94997725] Bias: -0.9785668856261012 loss: 0.3564804659711487\n",
            "Round: 328 Weight: [1.93542209 0.95071466] Bias: -0.9792250273325812 loss: 0.3564476354969707\n",
            "Round: 329 Weight: [1.93692689 0.95144902] Bias: -0.9798798732861368 loss: 0.3564150947817844\n",
            "Round: 330 Weight: [1.93842513 0.95218033] Bias: -0.9805314467476861 loss: 0.3563828408001637\n",
            "Round: 331 Weight: [1.93991684 0.95290863] Bias: -0.9811797707530375 loss: 0.35635087056457965\n",
            "Round: 332 Weight: [1.94140205 0.95363391] Bias: -0.9818248681156582 loss: 0.35631918112483313\n",
            "Round: 333 Weight: [1.94288082 0.95435621] Bias: -0.9824667614294016 loss: 0.35628776956749836\n",
            "Round: 334 Weight: [1.94435318 0.95507553] Bias: -0.9831054730711956 loss: 0.3562566330153752\n",
            "Round: 335 Weight: [1.94581916 0.95579189] Bias: -0.9837410252036899 loss: 0.3562257686269522\n",
            "Round: 336 Weight: [1.9472788  0.95650531] Bias: -0.9843734397778658 loss: 0.35619517359587793\n",
            "Round: 337 Weight: [1.94873214 0.95721581] Bias: -0.9850027385356072 loss: 0.35616484515044206\n",
            "Round: 338 Weight: [1.95017922 0.95792339] Bias: -0.9856289430122336 loss: 0.3561347805530655\n",
            "Round: 339 Weight: [1.95162007 0.95862808] Bias: -0.9862520745389977 loss: 0.35610497709979916\n",
            "Round: 340 Weight: [1.95305473 0.95932989] Bias: -0.9868721542455453 loss: 0.3560754321198312\n",
            "Round: 341 Weight: [1.95448323 0.96002884] Bias: -0.9874892030623404 loss: 0.35604614297500314\n",
            "Round: 342 Weight: [1.95590561 0.96072494] Bias: -0.9881032417230552 loss: 0.35601710705933415\n",
            "Round: 343 Weight: [1.9573219 0.9614182] Bias: -0.988714290766925 loss: 0.35598832179855305\n",
            "Round: 344 Weight: [1.95873214 0.96210865] Bias: -0.98932237054107 loss: 0.3559597846496391\n",
            "Round: 345 Weight: [1.96013637 0.96279629] Bias: -0.9899275012027838 loss: 0.35593149310036987\n",
            "Round: 346 Weight: [1.96153461 0.96348115] Bias: -0.9905297027217885 loss: 0.3559034446688773\n",
            "Round: 347 Weight: [1.96292691 0.96416323] Bias: -0.991128994882458 loss: 0.3558756369032108\n",
            "Round: 348 Weight: [1.96431329 0.96484256] Bias: -0.9917253972860098 loss: 0.3558480673809081\n",
            "Round: 349 Weight: [1.96569379 0.96551914] Bias: -0.9923189293526656 loss: 0.35582073370857326\n",
            "Round: 350 Weight: [1.96706845 0.96619299] Bias: -0.9929096103237808 loss: 0.35579363352146176\n",
            "Round: 351 Weight: [1.96843729 0.96686413] Bias: -0.9934974592639444 loss: 0.3557667644830721\n",
            "Round: 352 Weight: [1.96980034 0.96753256] Bias: -0.9940824950630494 loss: 0.35574012428474533\n",
            "Round: 353 Weight: [1.97115765 0.96819831] Bias: -0.9946647364383331 loss: 0.3557137106452698\n",
            "Round: 354 Weight: [1.97250924 0.96886138] Bias: -0.9952442019363903 loss: 0.35568752131049364\n",
            "Round: 355 Weight: [1.97385515 0.9695218 ] Bias: -0.9958209099351567 loss: 0.35566155405294325\n",
            "Round: 356 Weight: [1.9751954  0.97017957] Bias: -0.9963948786458656 loss: 0.35563580667144784\n",
            "Round: 357 Weight: [1.97653004 0.97083471] Bias: -0.9969661261149769 loss: 0.35561027699077075\n",
            "Round: 358 Weight: [1.97785908 0.97148723] Bias: -0.9975346702260794 loss: 0.35558496286124625\n",
            "Round: 359 Weight: [1.97918256 0.97213715] Bias: -0.9981005287017669 loss: 0.35555986215842256\n",
            "Round: 360 Weight: [1.98050051 0.97278448] Bias: -0.9986637191054873 loss: 0.3555349727827109\n",
            "Round: 361 Weight: [1.98181297 0.97342923] Bias: -0.999224258843368 loss: 0.35551029265903994\n",
            "Round: 362 Weight: [1.98311996 0.97407142] Bias: -0.9997821651660139 loss: 0.35548581973651583\n",
            "Round: 363 Weight: [1.98442151 0.97471105] Bias: -1.0003374551702828 loss: 0.35546155198808843\n",
            "Round: 364 Weight: [1.98571765 0.97534815] Bias: -1.000890145801035 loss: 0.35543748741022196\n",
            "Round: 365 Weight: [1.98700841 0.97598272] Bias: -1.0014402538528593 loss: 0.35541362402257176\n",
            "Round: 366 Weight: [1.98829383 0.97661478] Bias: -1.0019877959717753 loss: 0.35538995986766575\n",
            "Round: 367 Weight: [1.98957392 0.97724434] Bias: -1.0025327886569135 loss: 0.3553664930105914\n",
            "Round: 368 Weight: [1.99084873 0.97787141] Bias: -1.003075248262171 loss: 0.35534322153868764\n",
            "Round: 369 Weight: [1.99211827 0.97849601] Bias: -1.0036151909978457 loss: 0.3553201435612411\n",
            "Round: 370 Weight: [1.99338258 0.97911815] Bias: -1.004152632932248 loss: 0.35529725720918853\n",
            "Round: 371 Weight: [1.99464168 0.97973784] Bias: -1.0046875899932914 loss: 0.35527456063482243\n",
            "Round: 372 Weight: [1.99589561 0.98035509] Bias: -1.0052200779700602 loss: 0.35525205201150223\n",
            "Round: 373 Weight: [1.99714439 0.98096992] Bias: -1.0057501125143578 loss: 0.3552297295333703\n",
            "Round: 374 Weight: [1.99838805 0.98158234] Bias: -1.006277709142233 loss: 0.35520759141507136\n",
            "Round: 375 Weight: [1.99962661 0.98219235] Bias: -1.0068028832354872 loss: 0.3551856358914775\n",
            "Round: 376 Weight: [2.00086011 0.98279998] Bias: -1.0073256500431589 loss: 0.35516386121741683\n",
            "Round: 377 Weight: [2.00208857 0.98340523] Bias: -1.0078460246829917 loss: 0.35514226566740653\n",
            "Round: 378 Weight: [2.00331201 0.98400812] Bias: -1.0083640221428805 loss: 0.3551208475353901\n",
            "Round: 379 Weight: [2.00453047 0.98460865] Bias: -1.0088796572822987 loss: 0.3550996051344789\n",
            "Round: 380 Weight: [2.00574397 0.98520684] Bias: -1.009392944833708 loss: 0.3550785367966974\n",
            "Round: 381 Weight: [2.00695254 0.98580271] Bias: -1.0099038994039475 loss: 0.3550576408727324\n",
            "Round: 382 Weight: [2.0081562  0.98639625] Bias: -1.010412535475606 loss: 0.3550369157316866\n",
            "Round: 383 Weight: [2.00935498 0.98698749] Bias: -1.0109188674083758 loss: 0.3550163597608355\n",
            "Round: 384 Weight: [2.0105489  0.98757644] Bias: -1.0114229094403882 loss: 0.3549959713653879\n",
            "Round: 385 Weight: [2.011738  0.9881631] Bias: -1.0119246756895326 loss: 0.3549757489682511\n",
            "Round: 386 Weight: [2.01292229 0.98874748] Bias: -1.0124241801547573 loss: 0.3549556910097983\n",
            "Round: 387 Weight: [2.0141018  0.98932961] Bias: -1.0129214367173538 loss: 0.3549357959476404\n",
            "Round: 388 Weight: [2.01527656 0.98990948] Bias: -1.0134164591422241 loss: 0.35491606225640154\n",
            "Round: 389 Weight: [2.01644659 0.99048712] Bias: -1.0139092610791325 loss: 0.35489648842749727\n",
            "Round: 390 Weight: [2.01761192 0.99106253] Bias: -1.0143998560639396 loss: 0.35487707296891663\n",
            "Round: 391 Weight: [2.01877256 0.99163572] Bias: -1.0148882575198215 loss: 0.35485781440500735\n",
            "Round: 392 Weight: [2.01992855 0.9922067 ] Bias: -1.015374478758473 loss: 0.35483871127626454\n",
            "Round: 393 Weight: [2.02107991 0.99277549] Bias: -1.0158585329812957 loss: 0.35481976213912203\n",
            "Round: 394 Weight: [2.02222666 0.99334209] Bias: -1.016340433280569 loss: 0.3548009655657476\n",
            "Round: 395 Weight: [2.02336883 0.99390652] Bias: -1.0168201926406089 loss: 0.3547823201438406\n",
            "Round: 396 Weight: [2.02450643 0.99446878] Bias: -1.0172978239389097 loss: 0.354763824476433\n",
            "Round: 397 Weight: [2.02563951 0.99502889] Bias: -1.0177733399472724 loss: 0.3547454771816934\n",
            "Round: 398 Weight: [2.02676806 0.99558685] Bias: -1.0182467533329178 loss: 0.354727276892734\n",
            "Round: 399 Weight: [2.02789213 0.99614268] Bias: -1.0187180766595862 loss: 0.3547092222574198\n",
            "Round: 400 Weight: [2.02901173 0.99669639] Bias: -1.0191873223886232 loss: 0.3546913119381818\n",
            "Round: 401 Weight: [2.03012689 0.99724799] Bias: -1.0196545028800503 loss: 0.354673544611832\n",
            "Round: 402 Weight: [2.03123763 0.99779748] Bias: -1.0201196303936242 loss: 0.3546559189693816\n",
            "Round: 403 Weight: [2.03234396 0.99834488] Bias: -1.020582717089881 loss: 0.3546384337158617\n",
            "Round: 404 Weight: [2.03344592 0.99889019] Bias: -1.0210437750311676 loss: 0.35462108757014654\n",
            "Round: 405 Weight: [2.03454353 0.99943344] Bias: -1.0215028161826618 loss: 0.35460387926478015\n",
            "Round: 406 Weight: [2.0356368  0.99997462] Bias: -1.0219598524133766 loss: 0.354586807545804\n",
            "Round: 407 Weight: [2.03672576 1.00051374] Bias: -1.0224148954971541 loss: 0.35456987117258876\n",
            "Round: 408 Weight: [2.03781044 1.00105083] Bias: -1.022867957113647 loss: 0.35455306891766725\n",
            "Round: 409 Weight: [2.03889085 1.00158588] Bias: -1.0233190488492863 loss: 0.35453639956657107\n",
            "Round: 410 Weight: [2.03996701 1.0021189 ] Bias: -1.0237681821982392 loss: 0.3545198619176683\n",
            "Round: 411 Weight: [2.04103895 1.00264991] Bias: -1.024215368563353 loss: 0.3545034547820046\n",
            "Round: 412 Weight: [2.04210668 1.00317892] Bias: -1.0246606192570886 loss: 0.35448717698314614\n",
            "Round: 413 Weight: [2.04317024 1.00370593] Bias: -1.0251039455024422 loss: 0.35447102735702446\n",
            "Round: 414 Weight: [2.04422963 1.00423095] Bias: -1.0255453584338552 loss: 0.3544550047517844\n",
            "Round: 415 Weight: [2.04528488 1.00475399] Bias: -1.0259848690981133 loss: 0.35443910802763373\n",
            "Round: 416 Weight: [2.04633601 1.00527507] Bias: -1.0264224884552349 loss: 0.35442333605669485\n",
            "Round: 417 Weight: [2.04738304 1.00579419] Bias: -1.0268582273793478 loss: 0.3544076877228586\n",
            "Round: 418 Weight: [2.048426   1.00631135] Bias: -1.027292096659556 loss: 0.35439216192164064\n",
            "Round: 419 Weight: [2.04946489 1.00682658] Bias: -1.0277241070007948 loss: 0.35437675756003917\n",
            "Round: 420 Weight: [2.05049975 1.00733988] Bias: -1.028154269024677 loss: 0.35436147355639547\n",
            "Round: 421 Weight: [2.05153059 1.00785125] Bias: -1.0285825932703274 loss: 0.3543463088402557\n",
            "Round: 422 Weight: [2.05255743 1.00836071] Bias: -1.0290090901952085 loss: 0.3543312623522348\n",
            "Round: 423 Weight: [2.05358029 1.00886826] Bias: -1.0294337701759346 loss: 0.3543163330438828\n",
            "Round: 424 Weight: [2.05459919 1.00937392] Bias: -1.0298566435090775 loss: 0.3543015198775526\n",
            "Round: 425 Weight: [2.05561415 1.00987769] Bias: -1.030277720411962 loss: 0.3542868218262694\n",
            "Round: 426 Weight: [2.05662519 1.01037958] Bias: -1.0306970110234515 loss: 0.3542722378736026\n",
            "Round: 427 Weight: [2.05763233 1.0108796 ] Bias: -1.0311145254047247 loss: 0.35425776701353906\n",
            "Round: 428 Weight: [2.05863558 1.01137776] Bias: -1.0315302735400422 loss: 0.3542434082503579\n",
            "Round: 429 Weight: [2.05963498 1.01187406] Bias: -1.0319442653375053 loss: 0.35422916059850773\n",
            "Round: 430 Weight: [2.06063052 1.01236853] Bias: -1.032356510629804 loss: 0.3542150230824853\n",
            "Round: 431 Weight: [2.06162224 1.01286115] Bias: -1.0327670191749578 loss: 0.35420099473671507\n",
            "Round: 432 Weight: [2.06261016 1.01335195] Bias: -1.0331758006570462 loss: 0.3541870746054319\n",
            "Round: 433 Weight: [2.06359428 1.01384093] Bias: -1.0335828646869316 loss: 0.3541732617425643\n",
            "Round: 434 Weight: [2.06457463 1.01432809] Bias: -1.033988220802973 loss: 0.3541595552116197\n",
            "Round: 435 Weight: [2.06555123 1.01481346] Bias: -1.0343918784717316 loss: 0.35414595408557054\n",
            "Round: 436 Weight: [2.0665241  1.01529703] Bias: -1.0347938470886682 loss: 0.35413245744674376\n",
            "Round: 437 Weight: [2.06749324 1.01577881] Bias: -1.0351941359788317 loss: 0.35411906438670937\n",
            "Round: 438 Weight: [2.06845869 1.01625881] Bias: -1.0355927543975403 loss: 0.3541057740061728\n",
            "Round: 439 Weight: [2.06942046 1.01673705] Bias: -1.0359897115310546 loss: 0.3540925854148671\n",
            "Round: 440 Weight: [2.07037857 1.01721352] Bias: -1.0363850164972417 loss: 0.35407949773144737\n",
            "Round: 441 Weight: [2.07133302 1.01768823] Bias: -1.0367786783462338 loss: 0.3540665100833866\n",
            "Round: 442 Weight: [2.07228385 1.0181612 ] Bias: -1.0371707060610764 loss: 0.3540536216068727\n",
            "Round: 443 Weight: [2.07323107 1.01863243] Bias: -1.0375611085583714 loss: 0.35404083144670706\n",
            "Round: 444 Weight: [2.0741747  1.01910193] Bias: -1.037949894688911 loss: 0.3540281387562044\n",
            "Round: 445 Weight: [2.07511474 1.01956971] Bias: -1.038337073238305 loss: 0.3540155426970942\n",
            "Round: 446 Weight: [2.07605123 1.02003577] Bias: -1.038722652927601 loss: 0.35400304243942277\n",
            "Round: 447 Weight: [2.07698417 1.02050012] Bias: -1.0391066424138968 loss: 0.35399063716145807\n",
            "Round: 448 Weight: [2.07791359 1.02096277] Bias: -1.0394890502909466 loss: 0.3539783260495938\n",
            "Round: 449 Weight: [2.0788395  1.02142373] Bias: -1.0398698850897596 loss: 0.35396610829825675\n",
            "Round: 450 Weight: [2.07976191 1.02188301] Bias: -1.0402491552791913 loss: 0.35395398310981385\n",
            "Round: 451 Weight: [2.08068085 1.0223406 ] Bias: -1.0406268692665293 loss: 0.3539419496944816\n",
            "Round: 452 Weight: [2.08159633 1.02279653] Bias: -1.0410030353980715 loss: 0.3539300072702358\n",
            "Round: 453 Weight: [2.08250836 1.02325079] Bias: -1.041377661959698 loss: 0.3539181550627233\n",
            "Round: 454 Weight: [2.08341696 1.0237034 ] Bias: -1.0417507571774358 loss: 0.35390639230517396\n",
            "Round: 455 Weight: [2.08432215 1.02415436] Bias: -1.0421223292180184 loss: 0.3538947182383149\n",
            "Round: 456 Weight: [2.08522395 1.02460367] Bias: -1.042492386189438 loss: 0.35388313211028494\n",
            "Round: 457 Weight: [2.08612237 1.02505136] Bias: -1.0428609361414916 loss: 0.3538716331765506\n",
            "Round: 458 Weight: [2.08701742 1.02549741] Bias: -1.0432279870663212 loss: 0.3538602206998232\n",
            "Round: 459 Weight: [2.08790912 1.02594185] Bias: -1.043593546898948 loss: 0.3538488939499769\n",
            "Round: 460 Weight: [2.08879749 1.02638468] Bias: -1.0439576235177996 loss: 0.35383765220396796\n",
            "Round: 461 Weight: [2.08968254 1.0268259 ] Bias: -1.0443202247452334 loss: 0.35382649474575495\n",
            "Round: 462 Weight: [2.09056428 1.02726552] Bias: -1.0446813583480514 loss: 0.35381542086622025\n",
            "Round: 463 Weight: [2.09144274 1.02770355] Bias: -1.0450410320380112 loss: 0.35380442986309174\n",
            "Round: 464 Weight: [2.09231793 1.02814   ] Bias: -1.0453992534723306 loss: 0.3537935210408669\n",
            "Round: 465 Weight: [2.09318986 1.02857487] Bias: -1.0457560302541866 loss: 0.35378269371073684\n",
            "Round: 466 Weight: [2.09405855 1.02900816] Bias: -1.0461113699332087 loss: 0.3537719471905113\n",
            "Round: 467 Weight: [2.09492401 1.0294399 ] Bias: -1.0464652800059675 loss: 0.35376128080454533\n",
            "Round: 468 Weight: [2.09578626 1.02987008] Bias: -1.0468177679164568 loss: 0.3537506938836662\n",
            "Round: 469 Weight: [2.09664531 1.0302987 ] Bias: -1.0471688410565707 loss: 0.35374018576510186\n",
            "Round: 470 Weight: [2.09750118 1.03072579] Bias: -1.047518506766576 loss: 0.35372975579240973\n",
            "Round: 471 Weight: [2.09835388 1.03115134] Bias: -1.0478667723355783 loss: 0.35371940331540697\n",
            "Round: 472 Weight: [2.09920342 1.03157535] Bias: -1.0482136450019848 loss: 0.3537091276901008\n",
            "Round: 473 Weight: [2.10004983 1.03199785] Bias: -1.0485591319539596 loss: 0.35369892827862115\n",
            "Round: 474 Weight: [2.10089311 1.03241882] Bias: -1.0489032403298755 loss: 0.35368880444915246\n",
            "Round: 475 Weight: [2.10173328 1.03283829] Bias: -1.049245977218761 loss: 0.35367875557586786\n",
            "Round: 476 Weight: [2.10257035 1.03325625] Bias: -1.049587349660742 loss: 0.3536687810388626\n",
            "Round: 477 Weight: [2.10340434 1.03367272] Bias: -1.049927364647478 loss: 0.3536588802240903\n",
            "Round: 478 Weight: [2.10423526 1.03408769] Bias: -1.0502660291225951 loss: 0.35364905252329826\n",
            "Round: 479 Weight: [2.10506312 1.03450118] Bias: -1.0506033499821126 loss: 0.3536392973339643\n",
            "Round: 480 Weight: [2.10588794 1.03491319] Bias: -1.0509393340748663 loss: 0.3536296140592346\n",
            "Round: 481 Weight: [2.10670974 1.03532373] Bias: -1.0512739882029263 loss: 0.3536200021078619\n",
            "Round: 482 Weight: [2.10752852 1.0357328 ] Bias: -1.0516073191220112 loss: 0.35361046089414466\n",
            "Round: 483 Weight: [2.1083443  1.03614042] Bias: -1.0519393335418972 loss: 0.35360098983786714\n",
            "Round: 484 Weight: [2.10915709 1.03654658] Bias: -1.052270038126822 loss: 0.35359158836423993\n",
            "Round: 485 Weight: [2.10996691 1.03695129] Bias: -1.0525994394958866 loss: 0.35358225590384107\n",
            "Round: 486 Weight: [2.11077377 1.03735456] Bias: -1.0529275442234507 loss: 0.3535729918925591\n",
            "Round: 487 Weight: [2.11157768 1.0377564 ] Bias: -1.0532543588395242 loss: 0.3535637957715348\n",
            "Round: 488 Weight: [2.11237866 1.03815681] Bias: -1.0535798898301563 loss: 0.35355466698710536\n",
            "Round: 489 Weight: [2.11317672 1.0385558 ] Bias: -1.0539041436378174 loss: 0.35354560499074883\n",
            "Round: 490 Weight: [2.11397186 1.03895337] Bias: -1.0542271266617795 loss: 0.3535366092390286\n",
            "Round: 491 Weight: [2.11476412 1.03934953] Bias: -1.0545488452584921 loss: 0.3535276791935392\n",
            "Round: 492 Weight: [2.11555349 1.03974428] Bias: -1.0548693057419523 loss: 0.3535188143208529\n",
            "Round: 493 Weight: [2.11633999 1.04013764] Bias: -1.0551885143840734 loss: 0.3535100140924663\n",
            "Round: 494 Weight: [2.11712363 1.0405296 ] Bias: -1.0555064774150482 loss: 0.35350127798474806\n",
            "Round: 495 Weight: [2.11790443 1.04092018] Bias: -1.055823201023709 loss: 0.3534926054788873\n",
            "Round: 496 Weight: [2.1186824  1.04130937] Bias: -1.0561386913578832 loss: 0.3534839960608423\n",
            "Round: 497 Weight: [2.11945755 1.04169719] Bias: -1.0564529545247456 loss: 0.35347544922129026\n",
            "Round: 498 Weight: [2.12022989 1.04208364] Bias: -1.0567659965911675 loss: 0.3534669644555773\n",
            "Round: 499 Weight: [2.12099944 1.04246873] Bias: -1.0570778235840608 loss: 0.3534585412636691\n",
            "Round: 500 Weight: [2.12176621 1.04285245] Bias: -1.0573884414907198 loss: 0.3534501791501023\n",
            "Round: 501 Weight: [2.12253021 1.04323483] Bias: -1.057697856259159 loss: 0.3534418776239368\n",
            "Round: 502 Weight: [2.12329144 1.04361586] Bias: -1.058006073798447 loss: 0.35343363619870766\n",
            "Round: 503 Weight: [2.12404994 1.04399554] Bias: -1.0583130999790369 loss: 0.3534254543923786\n",
            "Round: 504 Weight: [2.1248057 1.0443739] Bias: -1.0586189406330946 loss: 0.3534173317272957\n",
            "Round: 505 Weight: [2.12555873 1.04475092] Bias: -1.0589236015548216 loss: 0.35340926773014125\n",
            "Round: 506 Weight: [2.12630906 1.04512661] Bias: -1.0592270885007762 loss: 0.35340126193188887\n",
            "Round: 507 Weight: [2.12705669 1.04550099] Bias: -1.0595294071901908 loss: 0.3533933138677587\n",
            "Round: 508 Weight: [2.12780163 1.04587406] Bias: -1.0598305633052851 loss: 0.3533854230771732\n",
            "Round: 509 Weight: [2.1285439  1.04624581] Bias: -1.0601305624915773 loss: 0.3533775891037136\n",
            "Round: 510 Weight: [2.12928351 1.04661626] Bias: -1.060429410358192 loss: 0.3533698114950766\n",
            "Round: 511 Weight: [2.13002046 1.04698542] Bias: -1.0607271124781636 loss: 0.3533620898030325\n",
            "Round: 512 Weight: [2.13075478 1.04735328] Bias: -1.0610236743887387 loss: 0.35335442358338187\n",
            "Round: 513 Weight: [2.13148646 1.04771986] Bias: -1.061319101591673 loss: 0.3533468123959148\n",
            "Round: 514 Weight: [2.13221553 1.04808515] Bias: -1.0616133995535273 loss: 0.3533392558043701\n",
            "Round: 515 Weight: [2.13294199 1.04844917] Bias: -1.0619065737059594 loss: 0.3533317533763939\n",
            "Round: 516 Weight: [2.13366586 1.04881192] Bias: -1.0621986294460133 loss: 0.3533243046834999\n",
            "Round: 517 Weight: [2.13438714 1.0491734 ] Bias: -1.062489572136405 loss: 0.35331690930102977\n",
            "Round: 518 Weight: [2.13510585 1.04953363] Bias: -1.0627794071058059 loss: 0.353309566808114\n",
            "Round: 519 Weight: [2.135822   1.04989259] Bias: -1.063068139649124 loss: 0.35330227678763304\n",
            "Round: 520 Weight: [2.1365356  1.05025031] Bias: -1.0633557750277804 loss: 0.3532950388261789\n",
            "Round: 521 Weight: [2.13724665 1.05060678] Bias: -1.063642318469985 loss: 0.3532878525140179\n",
            "Round: 522 Weight: [2.13795518 1.05096201] Bias: -1.0639277751710077 loss: 0.3532807174450525\n",
            "Round: 523 Weight: [2.13866119 1.05131601] Bias: -1.064212150293448 loss: 0.35327363321678507\n",
            "Round: 524 Weight: [2.1393647  1.05166878] Bias: -1.0644954489675023 loss: 0.353266599430281\n",
            "Round: 525 Weight: [2.14006571 1.05202032] Bias: -1.0647776762912267 loss: 0.35325961569013253\n",
            "Round: 526 Weight: [2.14076423 1.05237064] Bias: -1.0650588373307988 loss: 0.3532526816044235\n",
            "Round: 527 Weight: [2.14146027 1.05271975] Bias: -1.0653389371207764 loss: 0.3532457967846939\n",
            "Round: 528 Weight: [2.14215385 1.05306764] Bias: -1.0656179806643538 loss: 0.35323896084590467\n",
            "Round: 529 Weight: [2.14284498 1.05341434] Bias: -1.0658959729336148 loss: 0.3532321734064039\n",
            "Round: 530 Weight: [2.14353366 1.05375983] Bias: -1.0661729188697842 loss: 0.35322543408789236\n",
            "Round: 531 Weight: [2.14421991 1.05410412] Bias: -1.066448823383476 loss: 0.3532187425153898\n",
            "Round: 532 Weight: [2.14490373 1.05444723] Bias: -1.0667236913549396 loss: 0.3532120983172023\n",
            "Round: 533 Weight: [2.14558514 1.05478915] Bias: -1.066997527634304 loss: 0.3532055011248883\n",
            "Round: 534 Weight: [2.14626415 1.05512989] Bias: -1.067270337041818 loss: 0.35319895057322753\n",
            "Round: 535 Weight: [2.14694077 1.05546945] Bias: -1.0675421243680896 loss: 0.35319244630018737\n",
            "Round: 536 Weight: [2.147615   1.05580784] Bias: -1.067812894374323 loss: 0.3531859879468924\n",
            "Round: 537 Weight: [2.14828686 1.05614507] Bias: -1.0680826517925521 loss: 0.35317957515759185\n",
            "Round: 538 Weight: [2.14895635 1.05648113] Bias: -1.0683514013258724 loss: 0.3531732075796298\n",
            "Round: 539 Weight: [2.1496235  1.05681603] Bias: -1.0686191476486713 loss: 0.3531668848634132\n",
            "Round: 540 Weight: [2.15028829 1.05714979] Bias: -1.0688858954068547 loss: 0.3531606066623826\n",
            "Round: 541 Weight: [2.15095076 1.05748239] Bias: -1.0691516492180733 loss: 0.35315437263298133\n",
            "Round: 542 Weight: [2.1516109  1.05781385] Bias: -1.0694164136719437 loss: 0.35314818243462676\n",
            "Round: 543 Weight: [2.15226873 1.05814417] Bias: -1.0696801933302718 loss: 0.35314203572967984\n",
            "Round: 544 Weight: [2.15292425 1.05847336] Bias: -1.0699429927272688 loss: 0.3531359321834171\n",
            "Round: 545 Weight: [2.15357748 1.05880142] Bias: -1.07020481636977 loss: 0.3531298714640015\n",
            "Round: 546 Weight: [2.15422842 1.05912835] Bias: -1.0704656687374476 loss: 0.3531238532424543\n",
            "Round: 547 Weight: [2.15487709 1.05945416] Bias: -1.0707255542830247 loss: 0.3531178771926268\n",
            "Round: 548 Weight: [2.15552349 1.05977886] Bias: -1.0709844774324844 loss: 0.3531119429911729\n",
            "Round: 549 Weight: [2.15616763 1.06010244] Bias: -1.0712424425852782 loss: 0.35310605031752135\n",
            "Round: 550 Weight: [2.15680953 1.06042491] Bias: -1.071499454114533 loss: 0.3531001988538493\n",
            "Round: 551 Weight: [2.15744919 1.06074629] Bias: -1.0717555163672556 loss: 0.3530943882850545\n",
            "Round: 552 Weight: [2.15808662 1.06106656] Bias: -1.072010633664534 loss: 0.35308861829873006\n",
            "Round: 553 Weight: [2.15872182 1.06138574] Bias: -1.072264810301739 loss: 0.3530828885851372\n",
            "Round: 554 Weight: [2.15935482 1.06170383] Bias: -1.072518050548722 loss: 0.3530771988371799\n",
            "Round: 555 Weight: [2.15998562 1.06202083] Bias: -1.0727703586500124 loss: 0.3530715487503791\n",
            "Round: 556 Weight: [2.16061422 1.06233675] Bias: -1.0730217388250116 loss: 0.35306593802284736\n",
            "Round: 557 Weight: [2.16124064 1.06265159] Bias: -1.0732721952681867 loss: 0.35306036635526394\n",
            "Round: 558 Weight: [2.16186488 1.06296537] Bias: -1.0735217321492614 loss: 0.35305483345085\n",
            "Round: 559 Weight: [2.16248696 1.06327807] Bias: -1.073770353613405 loss: 0.35304933901534385\n",
            "Round: 560 Weight: [2.16310688 1.06358971] Bias: -1.07401806378142 loss: 0.35304388275697707\n",
            "Round: 561 Weight: [2.16372465 1.06390028] Bias: -1.0742648667499288 loss: 0.3530384643864503\n",
            "Round: 562 Weight: [2.16434029 1.0642098 ] Bias: -1.0745107665915563 loss: 0.35303308361690977\n",
            "Round: 563 Weight: [2.16495379 1.06451827] Bias: -1.0747557673551131 loss: 0.3530277401639234\n",
            "Round: 564 Weight: [2.16556517 1.06482569] Bias: -1.074999873065776 loss: 0.3530224337454584\n",
            "Round: 565 Weight: [2.16617444 1.06513207] Bias: -1.0752430877252663 loss: 0.3530171640818573\n",
            "Round: 566 Weight: [2.1667816  1.06543741] Bias: -1.0754854153120286 loss: 0.35301193089581623\n",
            "Round: 567 Weight: [2.16738667 1.06574171] Bias: -1.075726859781404 loss: 0.35300673391236187\n",
            "Round: 568 Weight: [2.16798965 1.06604498] Bias: -1.0759674250658064 loss: 0.35300157285882977\n",
            "Round: 569 Weight: [2.16859054 1.06634722] Bias: -1.076207115074893 loss: 0.3529964474648417\n",
            "Round: 570 Weight: [2.16918937 1.06664844] Bias: -1.0764459336957364 loss: 0.3529913574622846\n",
            "Round: 571 Weight: [2.16978614 1.06694864] Bias: -1.0766838847929927 loss: 0.35298630258528874\n",
            "Round: 572 Weight: [2.17038085 1.06724783] Bias: -1.0769209722090698 loss: 0.35298128257020667\n",
            "Round: 573 Weight: [2.17097352 1.067546  ] Bias: -1.0771571997642928 loss: 0.35297629715559187\n",
            "Round: 574 Weight: [2.17156414 1.06784316] Bias: -1.077392571257069 loss: 0.35297134608217856\n",
            "Round: 575 Weight: [2.17215274 1.06813932] Bias: -1.0776270904640513 loss: 0.3529664290928604\n",
            "Round: 576 Weight: [2.17273932 1.06843448] Bias: -1.077860761140298 loss: 0.3529615459326709\n",
            "Round: 577 Weight: [2.17332388 1.06872865] Bias: -1.0780935870194348 loss: 0.3529566963487625\n",
            "Round: 578 Weight: [2.17390644 1.06902182] Bias: -1.0783255718138123 loss: 0.35295188009038736\n",
            "Round: 579 Weight: [2.17448701 1.069314  ] Bias: -1.0785567192146632 loss: 0.3529470969088773\n",
            "Round: 580 Weight: [2.17506558 1.0696052 ] Bias: -1.078787032892258 loss: 0.35294234655762435\n",
            "Round: 581 Weight: [2.17564217 1.06989542] Bias: -1.0790165164960592 loss: 0.3529376287920616\n",
            "Round: 582 Weight: [2.17621679 1.07018466] Bias: -1.0792451736548745 loss: 0.3529329433696438\n",
            "Round: 583 Weight: [2.17678944 1.07047293] Bias: -1.0794730079770076 loss: 0.352928290049829\n",
            "Round: 584 Weight: [2.17736014 1.07076023] Bias: -1.0797000230504088 loss: 0.35292366859405944\n",
            "Round: 585 Weight: [2.17792889 1.07104656] Bias: -1.0799262224428237 loss: 0.3529190787657433\n",
            "Round: 586 Weight: [2.17849569 1.07133193] Bias: -1.08015160970194 loss: 0.35291452033023624\n",
            "Round: 587 Weight: [2.17906056 1.07161635] Bias: -1.0803761883555343 loss: 0.35290999305482357\n",
            "Round: 588 Weight: [2.1796235 1.0718998] Bias: -1.0805999619116162 loss: 0.3529054967087021\n",
            "Round: 589 Weight: [2.18018453 1.07218231] Bias: -1.0808229338585724 loss: 0.3529010310629627\n",
            "Round: 590 Weight: [2.18074364 1.07246387] Bias: -1.0810451076653083 loss: 0.35289659589057254\n",
            "Round: 591 Weight: [2.18130085 1.07274449] Bias: -1.0812664867813888 loss: 0.3528921909663579\n",
            "Round: 592 Weight: [2.18185617 1.07302416] Bias: -1.0814870746371783 loss: 0.35288781606698666\n",
            "Round: 593 Weight: [2.18240959 1.0733029 ] Bias: -1.0817068746439786 loss: 0.35288347097095235\n",
            "Round: 594 Weight: [2.18296114 1.07358071] Bias: -1.0819258901941666 loss: 0.35287915545855597\n",
            "Round: 595 Weight: [2.18351081 1.07385759] Bias: -1.0821441246613297 loss: 0.35287486931189027\n",
            "Round: 596 Weight: [2.18405862 1.07413354] Bias: -1.0823615814004008 loss: 0.35287061231482314\n",
            "Round: 597 Weight: [2.18460456 1.07440857] Bias: -1.0825782637477914 loss: 0.3528663842529812\n",
            "Round: 598 Weight: [2.18514866 1.07468268] Bias: -1.0827941750215244 loss: 0.3528621849137338\n",
            "Round: 599 Weight: [2.18569091 1.07495588] Bias: -1.083009318521365 loss: 0.35285801408617706\n",
            "Round: 600 Weight: [2.18623132 1.07522816] Bias: -1.0832236975289502 loss: 0.352853871561118\n",
            "Round: 601 Weight: [2.1867699  1.07549953] Bias: -1.0834373153079189 loss: 0.3528497571310592\n",
            "Round: 602 Weight: [2.18730666 1.07577001] Bias: -1.0836501751040382 loss: 0.35284567059018307\n",
            "Round: 603 Weight: [2.18784161 1.07603957] Bias: -1.0838622801453308 loss: 0.3528416117343365\n",
            "Round: 604 Weight: [2.18837474 1.07630825] Bias: -1.0840736336422003 loss: 0.3528375803610162\n",
            "Round: 605 Weight: [2.18890608 1.07657602] Bias: -1.0842842387875553 loss: 0.3528335762693533\n",
            "Round: 606 Weight: [2.18943562 1.07684291] Bias: -1.0844940987569331 loss: 0.3528295992600985\n",
            "Round: 607 Weight: [2.18996337 1.0771089 ] Bias: -1.0847032167086215 loss: 0.3528256491356079\n",
            "Round: 608 Weight: [2.19048934 1.07737402] Bias: -1.08491159578378 loss: 0.35282172569982767\n",
            "Round: 609 Weight: [2.19101354 1.07763825] Bias: -1.0851192391065607 loss: 0.3528178287582806\n",
            "Round: 610 Weight: [2.19153598 1.0779016 ] Bias: -1.0853261497842257 loss: 0.35281395811805116\n",
            "Round: 611 Weight: [2.19205665 1.07816408] Bias: -1.0855323309072664 loss: 0.35281011358777187\n",
            "Round: 612 Weight: [2.19257557 1.07842569] Bias: -1.0857377855495203 loss: 0.35280629497760896\n",
            "Round: 613 Weight: [2.19309274 1.07868643] Bias: -1.0859425167682861 loss: 0.352802502099249\n",
            "Round: 614 Weight: [2.19360818 1.07894631] Bias: -1.0861465276044402 loss: 0.3527987347658851\n",
            "Round: 615 Weight: [2.19412188 1.07920532] Bias: -1.0863498210825493 loss: 0.35279499279220317\n",
            "Round: 616 Weight: [2.19463386 1.07946348] Bias: -1.0865524002109839 loss: 0.3527912759943688\n",
            "Round: 617 Weight: [2.19514411 1.07972078] Bias: -1.0867542679820301 loss: 0.35278758419001416\n",
            "Round: 618 Weight: [2.19565266 1.07997723] Bias: -1.0869554273720012 loss: 0.35278391719822444\n",
            "Round: 619 Weight: [2.1961595  1.08023283] Bias: -1.0871558813413473 loss: 0.3527802748395251\n",
            "Round: 620 Weight: [2.19666464 1.08048758] Bias: -1.0873556328347647 loss: 0.35277665693586957\n",
            "Round: 621 Weight: [2.19716809 1.0807415 ] Bias: -1.0875546847813038 loss: 0.35277306331062536\n",
            "Round: 622 Weight: [2.19766985 1.08099457] Bias: -1.087753040094477 loss: 0.35276949378856254\n",
            "Round: 623 Weight: [2.19816993 1.08124681] Bias: -1.0879507016723644 loss: 0.3527659481958408\n",
            "Round: 624 Weight: [2.19866834 1.08149821] Bias: -1.0881476723977197 loss: 0.3527624263599972\n",
            "Round: 625 Weight: [2.19916508 1.08174879] Bias: -1.0883439551380747 loss: 0.3527589281099341\n",
            "Round: 626 Weight: [2.19966016 1.08199854] Bias: -1.088539552745843 loss: 0.3527554532759065\n",
            "Round: 627 Weight: [2.20015358 1.08224746] Bias: -1.088734468058423 loss: 0.3527520016895114\n",
            "Round: 628 Weight: [2.20064536 1.08249557] Bias: -1.0889287038982993 loss: 0.35274857318367403\n",
            "Round: 629 Weight: [2.2011355  1.08274286] Bias: -1.0891222630731445 loss: 0.352745167592638\n",
            "Round: 630 Weight: [2.201624   1.08298933] Bias: -1.0893151483759194 loss: 0.35274178475195256\n",
            "Round: 631 Weight: [2.20211088 1.08323499] Bias: -1.0895073625849714 loss: 0.35273842449846116\n",
            "Round: 632 Weight: [2.20259613 1.08347984] Bias: -1.0896989084641342 loss: 0.35273508667029063\n",
            "Round: 633 Weight: [2.20307976 1.08372389] Bias: -1.0898897887628252 loss: 0.35273177110683973\n",
            "Round: 634 Weight: [2.20356178 1.08396714] Bias: -1.0900800062161422 loss: 0.3527284776487674\n",
            "Round: 635 Weight: [2.2040422  1.08420958] Bias: -1.0902695635449597 loss: 0.3527252061379825\n",
            "Round: 636 Weight: [2.20452102 1.08445123] Bias: -1.0904584634560242 loss: 0.35272195641763254\n",
            "Round: 637 Weight: [2.20499825 1.08469209] Bias: -1.0906467086420484 loss: 0.3527187283320928\n",
            "Round: 638 Weight: [2.2054739  1.08493216] Bias: -1.0908343017818058 loss: 0.3527155217269556\n",
            "Round: 639 Weight: [2.20594796 1.08517143] Bias: -1.0910212455402226 loss: 0.35271233644901984\n",
            "Round: 640 Weight: [2.20642045 1.08540993] Bias: -1.0912075425684704 loss: 0.3527091723462806\n",
            "Round: 641 Weight: [2.20689137 1.08564764] Bias: -1.0913931955040577 loss: 0.35270602926791805\n",
            "Round: 642 Weight: [2.20736073 1.08588457] Bias: -1.0915782069709203 loss: 0.35270290706428803\n",
            "Round: 643 Weight: [2.20782853 1.08612073] Bias: -1.0917625795795114 loss: 0.3526998055869114\n",
            "Round: 644 Weight: [2.20829478 1.08635611] Bias: -1.0919463159268905 loss: 0.3526967246884639\n",
            "Round: 645 Weight: [2.20875949 1.08659072] Bias: -1.0921294185968122 loss: 0.3526936642227662\n",
            "Round: 646 Weight: [2.20922266 1.08682457] Bias: -1.0923118901598137 loss: 0.352690624044774\n",
            "Round: 647 Weight: [2.2096843  1.08705765] Bias: -1.0924937331733018 loss: 0.35268760401056837\n",
            "Round: 648 Weight: [2.21014441 1.08728997] Bias: -1.0926749501816393 loss: 0.35268460397734575\n",
            "Round: 649 Weight: [2.21060299 1.08752152] Bias: -1.0928555437162304 loss: 0.35268162380340856\n",
            "Round: 650 Weight: [2.21106007 1.08775233] Bias: -1.0930355162956056 loss: 0.3526786633481555\n",
            "Round: 651 Weight: [2.21151563 1.08798238] Bias: -1.0932148704255058 loss: 0.3526757224720723\n",
            "Round: 652 Weight: [2.21196969 1.08821167] Bias: -1.0933936085989662 loss: 0.3526728010367223\n",
            "Round: 653 Weight: [2.21242225 1.08844022] Bias: -1.0935717332963986 loss: 0.35266989890473693\n",
            "Round: 654 Weight: [2.21287332 1.08866803] Bias: -1.093749246985674 loss: 0.352667015939807\n",
            "Round: 655 Weight: [2.21332289 1.08889509] Bias: -1.0939261521222037 loss: 0.3526641520066734\n",
            "Round: 656 Weight: [2.21377099 1.08912141] Bias: -1.0941024511490203 loss: 0.352661306971118\n",
            "Round: 657 Weight: [2.21421761 1.089347  ] Bias: -1.0942781464968578 loss: 0.35265848069995503\n",
            "Round: 658 Weight: [2.21466276 1.08957185] Bias: -1.0944532405842313 loss: 0.35265567306102186\n",
            "Round: 659 Weight: [2.21510645 1.08979597] Bias: -1.0946277358175156 loss: 0.3526528839231707\n",
            "Round: 660 Weight: [2.21554867 1.09001936] Bias: -1.0948016345910236 loss: 0.3526501131562596\n",
            "Round: 661 Weight: [2.21598945 1.09024202] Bias: -1.094974939287084 loss: 0.3526473606311442\n",
            "Round: 662 Weight: [2.21642877 1.09046396] Bias: -1.0951476522761179 loss: 0.352644626219669\n",
            "Round: 663 Weight: [2.21686665 1.09068518] Bias: -1.095319775916716 loss: 0.35264190979465915\n",
            "Round: 664 Weight: [2.21730309 1.09090567] Bias: -1.095491312555713 loss: 0.3526392112299117\n",
            "Round: 665 Weight: [2.2177381  1.09112546] Bias: -1.0956622645282645 loss: 0.352636530400188\n",
            "Round: 666 Weight: [2.21817168 1.09134453] Bias: -1.09583263415792 loss: 0.35263386718120504\n",
            "Round: 667 Weight: [2.21860383 1.09156288] Bias: -1.096002423756698 loss: 0.3526312214496277\n",
            "Round: 668 Weight: [2.21903457 1.09178053] Bias: -1.0961716356251585 loss: 0.35262859308306027\n",
            "Round: 669 Weight: [2.2194639  1.09199748] Bias: -1.0963402720524764 loss: 0.35262598196003925\n",
            "Round: 670 Weight: [2.21989183 1.09221372] Bias: -1.0965083353165137 loss: 0.35262338796002457\n",
            "Round: 671 Weight: [2.22031835 1.09242926] Bias: -1.0966758276838906 loss: 0.3526208109633927\n",
            "Round: 672 Weight: [2.22074347 1.0926441 ] Bias: -1.0968427514100574 loss: 0.3526182508514283\n",
            "Round: 673 Weight: [2.22116721 1.09285825] Bias: -1.097009108739364 loss: 0.35261570750631677\n",
            "Round: 674 Weight: [2.22158956 1.0930717 ] Bias: -1.0971749019051313 loss: 0.35261318081113685\n",
            "Round: 675 Weight: [2.22201052 1.09328446] Bias: -1.097340133129719 loss: 0.3526106706498531\n",
            "Round: 676 Weight: [2.22243012 1.09349654] Bias: -1.0975048046245957 loss: 0.35260817690730806\n",
            "Round: 677 Weight: [2.22284834 1.09370793] Bias: -1.0976689185904067 loss: 0.3526056994692155\n",
            "Round: 678 Weight: [2.22326519 1.09391863] Bias: -1.0978324772170418 loss: 0.35260323822215267\n",
            "Round: 679 Weight: [2.22368069 1.09412866] Bias: -1.0979954826837028 loss: 0.35260079305355335\n",
            "Round: 680 Weight: [2.22409483 1.094338  ] Bias: -1.0981579371589703 loss: 0.35259836385170057\n",
            "Round: 681 Weight: [2.22450762 1.09454668] Bias: -1.0983198428008691 loss: 0.35259595050571946\n",
            "Round: 682 Weight: [2.22491906 1.09475467] Bias: -1.0984812017569354 loss: 0.3525935529055705\n",
            "Round: 683 Weight: [2.22532917 1.094962  ] Bias: -1.0986420161642805 loss: 0.35259117094204234\n",
            "Round: 684 Weight: [2.22573793 1.09516866] Bias: -1.0988022881496564 loss: 0.3525888045067447\n",
            "Round: 685 Weight: [2.22614537 1.09537465] Bias: -1.0989620198295198 loss: 0.3525864534921025\n",
            "Round: 686 Weight: [2.22655148 1.09557998] Bias: -1.0991212133100956 loss: 0.3525841177913476\n",
            "Round: 687 Weight: [2.22695627 1.09578464] Bias: -1.0992798706874403 loss: 0.35258179729851347\n",
            "Round: 688 Weight: [2.22735975 1.09598865] Bias: -1.0994379940475048 loss: 0.35257949190842774\n",
            "Round: 689 Weight: [2.22776191 1.096192  ] Bias: -1.0995955854661963 loss: 0.35257720151670624\n",
            "Round: 690 Weight: [2.22816276 1.0963947 ] Bias: -1.0997526470094403 loss: 0.35257492601974566\n",
            "Round: 691 Weight: [2.22856232 1.09659674] Bias: -1.0999091807332422 loss: 0.352572665314718\n",
            "Round: 692 Weight: [2.22896057 1.09679813] Bias: -1.1000651886837471 loss: 0.3525704192995633\n",
            "Round: 693 Weight: [2.22935754 1.09699888] Bias: -1.1002206728973016 loss: 0.3525681878729843\n",
            "Round: 694 Weight: [2.22975321 1.09719898] Bias: -1.1003756354005123 loss: 0.35256597093443925\n",
            "Round: 695 Weight: [2.23014761 1.09739844] Bias: -1.100530078210306 loss: 0.35256376838413617\n",
            "Round: 696 Weight: [2.23054072 1.09759726] Bias: -1.1006840033339884 loss: 0.3525615801230266\n",
            "Round: 697 Weight: [2.23093256 1.09779544] Bias: -1.100837412769303 loss: 0.35255940605279945\n",
            "Round: 698 Weight: [2.23132313 1.09799298] Bias: -1.100990308504489 loss: 0.35255724607587513\n",
            "Round: 699 Weight: [2.23171244 1.09818989] Bias: -1.1011426925183385 loss: 0.3525551000953992\n",
            "Round: 700 Weight: [2.23210049 1.09838617] Bias: -1.1012945667802543 loss: 0.35255296801523667\n",
            "Round: 701 Weight: [2.23248728 1.09858182] Bias: -1.1014459332503064 loss: 0.3525508497399663\n",
            "Round: 702 Weight: [2.23287282 1.09877684] Bias: -1.1015967938792883 loss: 0.35254874517487433\n",
            "Round: 703 Weight: [2.23325711 1.09897124] Bias: -1.1017471506087733 loss: 0.3525466542259491\n",
            "Round: 704 Weight: [2.23364017 1.09916501] Bias: -1.1018970053711694 loss: 0.3525445767998749\n",
            "Round: 705 Weight: [2.23402198 1.09935817] Bias: -1.102046360089775 loss: 0.35254251280402693\n",
            "Round: 706 Weight: [2.23440256 1.0995507 ] Bias: -1.1021952166788331 loss: 0.352540462146465\n",
            "Round: 707 Weight: [2.23478192 1.09974262] Bias: -1.102343577043586 loss: 0.35253842473592856\n",
            "Round: 708 Weight: [2.23516005 1.09993393] Bias: -1.1024914430803288 loss: 0.3525364004818304\n",
            "Round: 709 Weight: [2.23553695 1.10012462] Bias: -1.1026388166764625 loss: 0.3525343892942522\n",
            "Round: 710 Weight: [2.23591265 1.10031471] Bias: -1.1027856997105479 loss: 0.35253239108393825\n",
            "Round: 711 Weight: [2.23628713 1.10050419] Bias: -1.102932094052358 loss: 0.3525304057622905\n",
            "Round: 712 Weight: [2.23666041 1.10069306] Bias: -1.1030780015629298 loss: 0.3525284332413632\n",
            "Round: 713 Weight: [2.23703248 1.10088133] Bias: -1.1032234240946168 loss: 0.3525264734338575\n",
            "Round: 714 Weight: [2.23740336 1.101069  ] Bias: -1.1033683634911402 loss: 0.3525245262531163\n",
            "Round: 715 Weight: [2.23777304 1.10125607] Bias: -1.1035128215876397 loss: 0.3525225916131192\n",
            "Round: 716 Weight: [2.23814154 1.10144254] Bias: -1.103656800210725 loss: 0.3525206694284769\n",
            "Round: 717 Weight: [2.23850885 1.10162842] Bias: -1.1038003011785253 loss: 0.35251875961442675\n",
            "Round: 718 Weight: [2.23887498 1.1018137 ] Bias: -1.1039433263007399 loss: 0.3525168620868274\n",
            "Round: 719 Weight: [2.23923993 1.1019984 ] Bias: -1.1040858773786875 loss: 0.3525149767621535\n",
            "Round: 720 Weight: [2.23960371 1.1021825 ] Bias: -1.1042279562053559 loss: 0.35251310355749144\n",
            "Round: 721 Weight: [2.23996632 1.10236602] Bias: -1.10436956456545 loss: 0.35251124239053383\n",
            "Round: 722 Weight: [2.24032776 1.10254896] Bias: -1.1045107042354416 loss: 0.3525093931795748\n",
            "Round: 723 Weight: [2.24068805 1.10273131] Bias: -1.1046513769836164 loss: 0.3525075558435054\n",
            "Round: 724 Weight: [2.24104718 1.10291309] Bias: -1.1047915845701224 loss: 0.35250573030180876\n",
            "Round: 725 Weight: [2.24140516 1.10309428] Bias: -1.1049313287470175 loss: 0.3525039164745549\n",
            "Round: 726 Weight: [2.24176199 1.1032749 ] Bias: -1.1050706112583162 loss: 0.3525021142823968\n",
            "Round: 727 Weight: [2.24211768 1.10345494] Bias: -1.1052094338400364 loss: 0.352500323646565\n",
            "Round: 728 Weight: [2.24247223 1.10363442] Bias: -1.1053477982202469 loss: 0.35249854448886353\n",
            "Round: 729 Weight: [2.24282564 1.10381332] Bias: -1.1054857061191117 loss: 0.3524967767316652\n",
            "Round: 730 Weight: [2.24317792 1.10399165] Bias: -1.1056231592489374 loss: 0.3524950202979068\n",
            "Round: 731 Weight: [2.24352908 1.10416942] Bias: -1.1057601593142177 loss: 0.35249327511108497\n",
            "Round: 732 Weight: [2.24387911 1.10434662] Bias: -1.1058967080116788 loss: 0.35249154109525166\n",
            "Round: 733 Weight: [2.24422802 1.10452326] Bias: -1.1060328070303247 loss: 0.3524898181750095\n",
            "Round: 734 Weight: [2.24457582 1.10469935] Bias: -1.1061684580514806 loss: 0.35248810627550786\n",
            "Round: 735 Weight: [2.2449225  1.10487487] Bias: -1.1063036627488376 loss: 0.352486405322438\n",
            "Round: 736 Weight: [2.24526808 1.10504983] Bias: -1.1064384227884974 loss: 0.3524847152420292\n",
            "Round: 737 Weight: [2.24561255 1.10522425] Bias: -1.106572739829014 loss: 0.3524830359610442\n",
            "Round: 738 Weight: [2.24595593 1.1053981 ] Bias: -1.1067066155214382 loss: 0.3524813674067753\n",
            "Round: 739 Weight: [2.24629821 1.10557141] Bias: -1.1068400515093606 loss: 0.3524797095070397\n",
            "Round: 740 Weight: [2.24663939 1.10574417] Bias: -1.1069730494289536 loss: 0.352478062190176\n",
            "Round: 741 Weight: [2.24697949 1.10591638] Bias: -1.1071056109090134 loss: 0.3524764253850396\n",
            "Round: 742 Weight: [2.2473185  1.10608805] Bias: -1.107237737571003 loss: 0.3524747990209987\n",
            "Round: 743 Weight: [2.24765644 1.10625918] Bias: -1.1073694310290931 loss: 0.35247318302793035\n",
            "Round: 744 Weight: [2.24799329 1.10642976] Bias: -1.107500692890204 loss: 0.35247157733621653\n",
            "Round: 745 Weight: [2.24832908 1.1065998 ] Bias: -1.1076315247540462 loss: 0.35246998187673995\n",
            "Round: 746 Weight: [2.24866379 1.10676931] Bias: -1.1077619282131614 loss: 0.3524683965808804\n",
            "Round: 747 Weight: [2.24899744 1.10693828] Bias: -1.1078919048529632 loss: 0.3524668213805104\n",
            "Round: 748 Weight: [2.24933003 1.10710672] Bias: -1.1080214562517772 loss: 0.3524652562079921\n",
            "Round: 749 Weight: [2.24966156 1.10727462] Bias: -1.1081505839808807 loss: 0.35246370099617264\n",
            "Round: 750 Weight: [2.24999204 1.107442  ] Bias: -1.1082792896045432 loss: 0.3524621556783807\n",
            "Round: 751 Weight: [2.25032146 1.10760885] Bias: -1.1084075746800646 loss: 0.3524606201884229\n",
            "Round: 752 Weight: [2.25064984 1.10777517] Bias: -1.108535440757815 loss: 0.35245909446057977\n",
            "Round: 753 Weight: [2.25097718 1.10794096] Bias: -1.1086628893812738 loss: 0.35245757842960224\n",
            "Round: 754 Weight: [2.25130347 1.10810624] Bias: -1.1087899220870674 loss: 0.3524560720307079\n",
            "Round: 755 Weight: [2.25162873 1.10827099] Bias: -1.1089165404050085 loss: 0.3524545751995773\n",
            "Round: 756 Weight: [2.25195296 1.10843522] Bias: -1.1090427458581336 loss: 0.35245308787235047\n",
            "Round: 757 Weight: [2.25227616 1.10859894] Bias: -1.1091685399627405 loss: 0.35245160998562325\n",
            "Round: 758 Weight: [2.25259833 1.10876214] Bias: -1.109293924228426 loss: 0.35245014147644405\n",
            "Round: 759 Weight: [2.25291948 1.10892482] Bias: -1.109418900158124 loss: 0.3524486822823096\n",
            "Round: 760 Weight: [2.25323962 1.109087  ] Bias: -1.109543469248141 loss: 0.35244723234116215\n",
            "Round: 761 Weight: [2.25355874 1.10924866] Bias: -1.1096676329881936 loss: 0.35244579159138617\n",
            "Round: 762 Weight: [2.25387685 1.10940981] Bias: -1.1097913928614453 loss: 0.3524443599718039\n",
            "Round: 763 Weight: [2.25419395 1.10957046] Bias: -1.1099147503445421 loss: 0.3524429374216732\n",
            "Round: 764 Weight: [2.25451005 1.10973061] Bias: -1.1100377069076488 loss: 0.35244152388068317\n",
            "Round: 765 Weight: [2.25482515 1.10989024] Bias: -1.1101602640144845 loss: 0.3524401192889517\n",
            "Round: 766 Weight: [2.25513925 1.11004938] Bias: -1.1102824231223585 loss: 0.35243872358702116\n",
            "Round: 767 Weight: [2.25545236 1.11020802] Bias: -1.1104041856822047 loss: 0.3524373367158562\n",
            "Round: 768 Weight: [2.25576447 1.11036616] Bias: -1.1105255531386176 loss: 0.35243595861683963\n",
            "Round: 769 Weight: [2.25607561 1.1105238 ] Bias: -1.1106465269298862 loss: 0.3524345892317696\n",
            "Round: 770 Weight: [2.25638575 1.11068095] Bias: -1.1107671084880293 loss: 0.35243322850285647\n",
            "Round: 771 Weight: [2.25669492 1.1108376 ] Bias: -1.110887299238829 loss: 0.35243187637271933\n",
            "Round: 772 Weight: [2.25700311 1.11099377] Bias: -1.1110071006018654 loss: 0.3524305327843831\n",
            "Round: 773 Weight: [2.25731033 1.11114944] Bias: -1.11112651399055 loss: 0.3524291976812755\n",
            "Round: 774 Weight: [2.25761658 1.11130463] Bias: -1.111245540812159 loss: 0.3524278710072235\n",
            "Round: 775 Weight: [2.25792187 1.11145932] Bias: -1.1113641824678677 loss: 0.3524265527064508\n",
            "Round: 776 Weight: [2.25822619 1.11161354] Bias: -1.1114824403527825 loss: 0.35242524272357456\n",
            "Round: 777 Weight: [2.25852955 1.11176727] Bias: -1.1116003158559744 loss: 0.35242394100360225\n",
            "Round: 778 Weight: [2.25883195 1.11192052] Bias: -1.1117178103605116 loss: 0.3524226474919288\n",
            "Round: 779 Weight: [2.25913341 1.11207329] Bias: -1.1118349252434918 loss: 0.3524213621343338\n",
            "Round: 780 Weight: [2.25943391 1.11222558] Bias: -1.1119516618760745 loss: 0.35242008487697823\n",
            "Round: 781 Weight: [2.25973346 1.11237739] Bias: -1.1120680216235133 loss: 0.35241881566640176\n",
            "Round: 782 Weight: [2.26003208 1.11252873] Bias: -1.1121840058451868 loss: 0.35241755444952\n",
            "Round: 783 Weight: [2.26032975 1.1126796 ] Bias: -1.1122996158946317 loss: 0.3524163011736212\n",
            "Round: 784 Weight: [2.26062649 1.11282999] Bias: -1.1124148531195728 loss: 0.3524150557863637\n",
            "Round: 785 Weight: [2.26092229 1.11297992] Bias: -1.1125297188619547 loss: 0.3524138182357732\n",
            "Round: 786 Weight: [2.26121716 1.11312937] Bias: -1.1126442144579731 loss: 0.3524125884702399\n",
            "Round: 787 Weight: [2.26151111 1.11327836] Bias: -1.1127583412381048 loss: 0.3524113664385154\n",
            "Round: 788 Weight: [2.26180413 1.11342688] Bias: -1.1128721005271387 loss: 0.3524101520897106\n",
            "Round: 789 Weight: [2.26209623 1.11357494] Bias: -1.1129854936442063 loss: 0.35240894537329237\n",
            "Round: 790 Weight: [2.26238741 1.11372254] Bias: -1.1130985219028113 loss: 0.3524077462390811\n",
            "Round: 791 Weight: [2.26267768 1.11386967] Bias: -1.1132111866108605 loss: 0.3524065546372482\n",
            "Round: 792 Weight: [2.26296704 1.11401635] Bias: -1.113323489070692 loss: 0.3524053705183129\n",
            "Round: 793 Weight: [2.26325549 1.11416257] Bias: -1.1134354305791065 loss: 0.3524041938331405\n",
            "Round: 794 Weight: [2.26354303 1.11430833] Bias: -1.1135470124273952 loss: 0.35240302453293876\n",
            "Round: 795 Weight: [2.26382968 1.11445364] Bias: -1.1136582359013698 loss: 0.35240186256925604\n",
            "Round: 796 Weight: [2.26411542 1.11459849] Bias: -1.1137691022813914 loss: 0.35240070789397854\n",
            "Round: 797 Weight: [2.26440027 1.1147429 ] Bias: -1.1138796128423987 loss: 0.3523995604593274\n",
            "Round: 798 Weight: [2.26468422 1.11488685] Bias: -1.1139897688539373 loss: 0.35239842021785667\n",
            "Round: 799 Weight: [2.26496729 1.11503035] Bias: -1.1140995715801876 loss: 0.3523972871224508\n",
            "Round: 800 Weight: [2.26524947 1.11517341] Bias: -1.1142090222799932 loss: 0.35239616112632144\n",
            "Round: 801 Weight: [2.26553076 1.11531602] Bias: -1.114318122206889 loss: 0.35239504218300594\n",
            "Round: 802 Weight: [2.26581118 1.11545819] Bias: -1.1144268726091286 loss: 0.3523939302463644\n",
            "Round: 803 Weight: [2.26609072 1.11559992] Bias: -1.1145352747297126 loss: 0.3523928252705771\n",
            "Round: 804 Weight: [2.26636938 1.1157412 ] Bias: -1.1146433298064158 loss: 0.35239172721014256\n",
            "Round: 805 Weight: [2.26664717 1.11588205] Bias: -1.114751039071814 loss: 0.35239063601987464\n",
            "Round: 806 Weight: [2.26692409 1.11602246] Bias: -1.1148584037533122 loss: 0.35238955165490077\n",
            "Round: 807 Weight: [2.26720015 1.11616243] Bias: -1.1149654250731706 loss: 0.3523884740706589\n",
            "Round: 808 Weight: [2.26747534 1.11630197] Bias: -1.1150721042485316 loss: 0.35238740322289597\n",
            "Round: 809 Weight: [2.26774967 1.11644107] Bias: -1.1151784424914468 loss: 0.35238633906766476\n",
            "Round: 810 Weight: [2.26802315 1.11657974] Bias: -1.1152844410089027 loss: 0.3523852815613225\n",
            "Round: 811 Weight: [2.26829577 1.11671798] Bias: -1.1153901010028475 loss: 0.3523842306605275\n",
            "Round: 812 Weight: [2.26856755 1.11685579] Bias: -1.115495423670217 loss: 0.3523831863222382\n",
            "Round: 813 Weight: [2.26883847 1.11699317] Bias: -1.1156004102029609 loss: 0.3523821485037098\n",
            "Round: 814 Weight: [2.26910855 1.11713013] Bias: -1.1157050617880675 loss: 0.3523811171624927\n",
            "Round: 815 Weight: [2.26937778 1.11726666] Bias: -1.1158093796075905 loss: 0.3523800922564302\n",
            "Round: 816 Weight: [2.26964618 1.11740276] Bias: -1.1159133648386739 loss: 0.3523790737436562\n",
            "Round: 817 Weight: [2.26991374 1.11753845] Bias: -1.116017018653577 loss: 0.3523780615825928\n",
            "Round: 818 Weight: [2.27018046 1.11767371] Bias: -1.1161203422196995 loss: 0.35237705573194894\n",
            "Round: 819 Weight: [2.27044636 1.11780856] Bias: -1.1162233366996073 loss: 0.3523760561507173\n",
            "Round: 820 Weight: [2.27071142 1.11794299] Bias: -1.116326003251056 loss: 0.352375062798173\n",
            "Round: 821 Weight: [2.27097566 1.118077  ] Bias: -1.1164283430270165 loss: 0.3523740756338711\n",
            "Round: 822 Weight: [2.27123908 1.11821059] Bias: -1.116530357175699 loss: 0.35237309461764443\n",
            "Round: 823 Weight: [2.27150167 1.11834377] Bias: -1.1166320468405773 loss: 0.352372119709602\n",
            "Round: 824 Weight: [2.27176345 1.11847654] Bias: -1.116733413160413 loss: 0.35237115087012655\n",
            "Round: 825 Weight: [2.27202442 1.1186089 ] Bias: -1.1168344572692797 loss: 0.3523701880598724\n",
            "Round: 826 Weight: [2.27228457 1.11874085] Bias: -1.1169351802965863 loss: 0.3523692312397642\n",
            "Round: 827 Weight: [2.27254392 1.11887239] Bias: -1.1170355833671017 loss: 0.352368280370994\n",
            "Round: 828 Weight: [2.27280245 1.11900352] Bias: -1.1171356676009772 loss: 0.3523673354150199\n",
            "Round: 829 Weight: [2.27306019 1.11913425] Bias: -1.11723543411377 loss: 0.35236639633356387\n",
            "Round: 830 Weight: [2.27331712 1.11926457] Bias: -1.1173348840164679 loss: 0.3523654630886098\n",
            "Round: 831 Weight: [2.27357326 1.11939449] Bias: -1.1174340184155103 loss: 0.3523645356424014\n",
            "Round: 832 Weight: [2.2738286  1.11952401] Bias: -1.1175328384128125 loss: 0.352363613957441\n",
            "Round: 833 Weight: [2.27408314 1.11965313] Bias: -1.1176313451057884 loss: 0.35236269799648684\n",
            "Round: 834 Weight: [2.2743369  1.11978185] Bias: -1.1177295395873728 loss: 0.3523617877225514\n",
            "Round: 835 Weight: [2.27458987 1.11991017] Bias: -1.1178274229460436 loss: 0.3523608830988998\n",
            "Round: 836 Weight: [2.27484205 1.1200381 ] Bias: -1.1179249962658453 loss: 0.3523599840890478\n",
            "Round: 837 Weight: [2.27509345 1.12016563] Bias: -1.11802226062641 loss: 0.3523590906567597\n",
            "Round: 838 Weight: [2.27534407 1.12029277] Bias: -1.1181192171029808 loss: 0.3523582027660471\n",
            "Round: 839 Weight: [2.27559392 1.12041951] Bias: -1.1182158667664321 loss: 0.3523573203811665\n",
            "Round: 840 Weight: [2.27584299 1.12054586] Bias: -1.1183122106832932 loss: 0.3523564434666178\n",
            "Round: 841 Weight: [2.27609129 1.12067183] Bias: -1.1184082499157686 loss: 0.3523555719871427\n",
            "Round: 842 Weight: [2.27633882 1.1207974 ] Bias: -1.1185039855217602 loss: 0.3523547059077223\n",
            "Round: 843 Weight: [2.27658558 1.12092259] Bias: -1.1185994185548889 loss: 0.3523538451935762\n",
            "Round: 844 Weight: [2.27683158 1.12104739] Bias: -1.1186945500645153 loss: 0.35235298981016\n",
            "Round: 845 Weight: [2.27707681 1.12117181] Bias: -1.1187893810957614 loss: 0.35235213972316426\n",
            "Round: 846 Weight: [2.27732129 1.12129585] Bias: -1.1188839126895311 loss: 0.35235129489851197\n",
            "Round: 847 Weight: [2.27756501 1.1214195 ] Bias: -1.1189781458825319 loss: 0.3523504553023576\n",
            "Round: 848 Weight: [2.27780798 1.12154277] Bias: -1.1190720817072946 loss: 0.35234962090108535\n",
            "Round: 849 Weight: [2.27805019 1.12166566] Bias: -1.1191657211921948 loss: 0.3523487916613069\n",
            "Round: 850 Weight: [2.27829166 1.12178818] Bias: -1.1192590653614731 loss: 0.35234796754986014\n",
            "Round: 851 Weight: [2.27853238 1.12191031] Bias: -1.1193521152352557 loss: 0.3523471485338079\n",
            "Round: 852 Weight: [2.27877235 1.12203207] Bias: -1.119444871829574 loss: 0.3523463345804356\n",
            "Round: 853 Weight: [2.27901159 1.12215346] Bias: -1.1195373361563856 loss: 0.3523455256572499\n",
            "Round: 854 Weight: [2.27925008 1.12227447] Bias: -1.1196295092235937 loss: 0.3523447217319775\n",
            "Round: 855 Weight: [2.27948784 1.12239511] Bias: -1.1197213920350675 loss: 0.35234392277256293\n",
            "Round: 856 Weight: [2.27972486 1.12251538] Bias: -1.1198129855906613 loss: 0.3523431287471674\n",
            "Round: 857 Weight: [2.27996116 1.12263528] Bias: -1.119904290886235 loss: 0.352342339624167\n",
            "Round: 858 Weight: [2.28019672 1.12275481] Bias: -1.119995308913673 loss: 0.35234155537215134\n",
            "Round: 859 Weight: [2.28043155 1.12287398] Bias: -1.1200860406609032 loss: 0.3523407759599218\n",
            "Round: 860 Weight: [2.28066567 1.12299277] Bias: -1.120176487111918 loss: 0.35234000135649024\n",
            "Round: 861 Weight: [2.28089906 1.12311121] Bias: -1.1202666492467914 loss: 0.35233923153107727\n",
            "Round: 862 Weight: [2.28113172 1.12322928] Bias: -1.1203565280416996 loss: 0.35233846645311057\n",
            "Round: 863 Weight: [2.28136368 1.12334698] Bias: -1.1204461244689392 loss: 0.35233770609222415\n",
            "Round: 864 Weight: [2.28159491 1.12346433] Bias: -1.1205354394969462 loss: 0.352336950418256\n",
            "Round: 865 Weight: [2.28182544 1.12358132] Bias: -1.1206244740903146 loss: 0.3523361994012472\n",
            "Round: 866 Weight: [2.28205525 1.12369794] Bias: -1.1207132292098154 loss: 0.35233545301144004\n",
            "Round: 867 Weight: [2.28228436 1.12381421] Bias: -1.1208017058124147 loss: 0.35233471121927695\n",
            "Round: 868 Weight: [2.28251276 1.12393012] Bias: -1.1208899048512921 loss: 0.3523339739953988\n",
            "Round: 869 Weight: [2.28274046 1.12404568] Bias: -1.1209778272758593 loss: 0.3523332413106435\n",
            "Round: 870 Weight: [2.28296745 1.12416088] Bias: -1.1210654740317778 loss: 0.35233251313604486\n",
            "Round: 871 Weight: [2.28319375 1.12427573] Bias: -1.1211528460609776 loss: 0.35233178944283083\n",
            "Round: 872 Weight: [2.28341935 1.12439023] Bias: -1.1212399443016745 loss: 0.35233107020242227\n",
            "Round: 873 Weight: [2.28364426 1.12450438] Bias: -1.1213267696883882 loss: 0.35233035538643176\n",
            "Round: 874 Weight: [2.28386848 1.12461817] Bias: -1.1214133231519599 loss: 0.35232964496666164\n",
            "Round: 875 Weight: [2.284092   1.12473162] Bias: -1.1214996056195703 loss: 0.35232893891510336\n",
            "Round: 876 Weight: [2.28431484 1.12484472] Bias: -1.121585618014757 loss: 0.35232823720393575\n",
            "Round: 877 Weight: [2.284537   1.12495748] Bias: -1.1216713612574314 loss: 0.3523275398055236\n",
            "Round: 878 Weight: [2.28475847 1.12506989] Bias: -1.1217568362638968 loss: 0.3523268466924165\n",
            "Round: 879 Weight: [2.28497926 1.12518195] Bias: -1.121842043946865 loss: 0.35232615783734766\n",
            "Round: 880 Weight: [2.28519937 1.12529368] Bias: -1.1219269852154738 loss: 0.3523254732132323\n",
            "Round: 881 Weight: [2.28541881 1.12540506] Bias: -1.122011660975304 loss: 0.35232479279316653\n",
            "Round: 882 Weight: [2.28563757 1.1255161 ] Bias: -1.1220960721283957 loss: 0.35232411655042606\n",
            "Round: 883 Weight: [2.28585566 1.1256268 ] Bias: -1.122180219573266 loss: 0.3523234444584647\n",
            "Round: 884 Weight: [2.28607309 1.12573716] Bias: -1.122264104204925 loss: 0.35232277649091354\n",
            "Round: 885 Weight: [2.28628984 1.12584719] Bias: -1.1223477269148932 loss: 0.35232211262157925\n",
            "Round: 886 Weight: [2.28650593 1.12595688] Bias: -1.122431088591217 loss: 0.352321452824443\n",
            "Round: 887 Weight: [2.28672136 1.12606623] Bias: -1.1225141901184859 loss: 0.35232079707365915\n",
            "Round: 888 Weight: [2.28693613 1.12617525] Bias: -1.1225970323778485 loss: 0.35232014534355444\n",
            "Round: 889 Weight: [2.28715024 1.12628394] Bias: -1.122679616247029 loss: 0.3523194976086262\n",
            "Round: 890 Weight: [2.28736369 1.12639229] Bias: -1.1227619426003428 loss: 0.3523188538435412\n",
            "Round: 891 Weight: [2.28757649 1.12650031] Bias: -1.1228440123087133 loss: 0.3523182140231349\n",
            "Round: 892 Weight: [2.28778863 1.12660801] Bias: -1.122925826239687 loss: 0.3523175781224098\n",
            "Round: 893 Weight: [2.28800013 1.12671537] Bias: -1.12300738525745 loss: 0.35231694611653464\n",
            "Round: 894 Weight: [2.28821098 1.12682241] Bias: -1.1230886902228436 loss: 0.35231631798084256\n",
            "Round: 895 Weight: [2.28842118 1.12692912] Bias: -1.1231697419933797 loss: 0.35231569369083104\n",
            "Round: 896 Weight: [2.28863074 1.12703551] Bias: -1.1232505414232568 loss: 0.35231507322215966\n",
            "Round: 897 Weight: [2.28883966 1.12714157] Bias: -1.123331089363375 loss: 0.3523144565506492\n",
            "Round: 898 Weight: [2.28904794 1.12724731] Bias: -1.1234113866613522 loss: 0.3523138436522814\n",
            "Round: 899 Weight: [2.28925558 1.12735273] Bias: -1.1234914341615383 loss: 0.35231323450319646\n",
            "Round: 900 Weight: [2.28946259 1.12745782] Bias: -1.1235712327050311 loss: 0.35231262907969285\n",
            "Round: 901 Weight: [2.28966896 1.12756259] Bias: -1.1236507831296918 loss: 0.3523120273582259\n",
            "Round: 902 Weight: [2.2898747  1.12766705] Bias: -1.1237300862701591 loss: 0.3523114293154066\n",
            "Round: 903 Weight: [2.29007982 1.12777119] Bias: -1.123809142957865 loss: 0.35231083492800097\n",
            "Round: 904 Weight: [2.2902843  1.12787501] Bias: -1.123887954021049 loss: 0.35231024417292817\n",
            "Round: 905 Weight: [2.29048816 1.12797851] Bias: -1.1239665202847733 loss: 0.35230965702726014\n",
            "Round: 906 Weight: [2.2906914 1.1280817] Bias: -1.1240448425709377 loss: 0.3523090734682202\n",
            "Round: 907 Weight: [2.29089402 1.12818457] Bias: -1.1241229216982938 loss: 0.3523084934731822\n",
            "Round: 908 Weight: [2.29109602 1.12828713] Bias: -1.1242007584824592 loss: 0.3523079170196692\n",
            "Round: 909 Weight: [2.2912974  1.12838938] Bias: -1.124278353735933 loss: 0.35230734408535236\n",
            "Round: 910 Weight: [2.29149817 1.12849132] Bias: -1.12435570826811 loss: 0.3523067746480505\n",
            "Round: 911 Weight: [2.29169833 1.12859295] Bias: -1.1244328228852933 loss: 0.3523062086857282\n",
            "Round: 912 Weight: [2.29189787 1.12869427] Bias: -1.124509698390711 loss: 0.35230564617649557\n",
            "Round: 913 Weight: [2.29209681 1.12879528] Bias: -1.1245863355845285 loss: 0.35230508709860675\n",
            "Round: 914 Weight: [2.29229513 1.12889598] Bias: -1.1246627352638632 loss: 0.3523045314304591\n",
            "Round: 915 Weight: [2.29249286 1.12899638] Bias: -1.1247388982227988 loss: 0.352303979150592\n",
            "Round: 916 Weight: [2.29268998 1.12909647] Bias: -1.1248148252523988 loss: 0.35230343023768623\n",
            "Round: 917 Weight: [2.2928865  1.12919626] Bias: -1.1248905171407202 loss: 0.35230288467056264\n",
            "Round: 918 Weight: [2.29308242 1.12929575] Bias: -1.124965974672827 loss: 0.3523023424281812\n",
            "Round: 919 Weight: [2.29327774 1.12939493] Bias: -1.1250411986308053 loss: 0.35230180348964024\n",
            "Round: 920 Weight: [2.29347247 1.12949381] Bias: -1.1251161897937747 loss: 0.35230126783417537\n",
            "Round: 921 Weight: [2.29366661 1.1295924 ] Bias: -1.1251909489379033 loss: 0.3523007354411585\n",
            "Round: 922 Weight: [2.29386015 1.12969068] Bias: -1.125265476836421 loss: 0.35230020629009684\n",
            "Round: 923 Weight: [2.29405311 1.12978866] Bias: -1.1253397742596325 loss: 0.35229968036063203\n",
            "Round: 924 Weight: [2.29424547 1.12988635] Bias: -1.1254138419749304 loss: 0.3522991576325394\n",
            "Round: 925 Weight: [2.29443726 1.12998374] Bias: -1.125487680746809 loss: 0.3522986380857265\n",
            "Round: 926 Weight: [2.29462845 1.13008083] Bias: -1.125561291336877 loss: 0.35229812170023284\n",
            "Round: 927 Weight: [2.29481907 1.13017763] Bias: -1.125634674503871 loss: 0.35229760845622865\n",
            "Round: 928 Weight: [2.29500911 1.13027414] Bias: -1.1257078310036674 loss: 0.3522970983340137\n",
            "Round: 929 Weight: [2.29519857 1.13037036] Bias: -1.1257807615892965 loss: 0.35229659131401686\n",
            "Round: 930 Weight: [2.29538745 1.13046628] Bias: -1.125853467010955 loss: 0.35229608737679524\n",
            "Round: 931 Weight: [2.29557576 1.13056191] Bias: -1.1259259480160186 loss: 0.3522955865030326\n",
            "Round: 932 Weight: [2.29576349 1.13065725] Bias: -1.1259982053490545 loss: 0.3522950886735395\n",
            "Round: 933 Weight: [2.29595066 1.1307523 ] Bias: -1.1260702397518347 loss: 0.3522945938692514\n",
            "Round: 934 Weight: [2.29613725 1.13084707] Bias: -1.1261420519633478 loss: 0.3522941020712288\n",
            "Round: 935 Weight: [2.29632328 1.13094155] Bias: -1.1262136427198122 loss: 0.3522936132606552\n",
            "Round: 936 Weight: [2.29650875 1.13103574] Bias: -1.1262850127546875 loss: 0.35229312741883767\n",
            "Round: 937 Weight: [2.29669365 1.13112965] Bias: -1.1263561627986884 loss: 0.3522926445272046\n",
            "Round: 938 Weight: [2.29687799 1.13122327] Bias: -1.1264270935797953 loss: 0.35229216456730583\n",
            "Round: 939 Weight: [2.29706177 1.13131661] Bias: -1.1264978058232678 loss: 0.3522916875208114\n",
            "Round: 940 Weight: [2.29724499 1.13140966] Bias: -1.126568300251656 loss: 0.35229121336951075\n",
            "Round: 941 Weight: [2.29742765 1.13150244] Bias: -1.1266385775848131 loss: 0.352290742095312\n",
            "Round: 942 Weight: [2.29760976 1.13159493] Bias: -1.1267086385399072 loss: 0.3522902736802412\n",
            "Round: 943 Weight: [2.29779132 1.13168715] Bias: -1.1267784838314334 loss: 0.35228980810644117\n",
            "Round: 944 Weight: [2.29797233 1.13177908] Bias: -1.1268481141712254 loss: 0.35228934535617107\n",
            "Round: 945 Weight: [2.29815279 1.13187074] Bias: -1.1269175302684675 loss: 0.3522888854118054\n",
            "Round: 946 Weight: [2.2983327  1.13196212] Bias: -1.1269867328297063 loss: 0.3522884282558333\n",
            "Round: 947 Weight: [2.29851207 1.13205323] Bias: -1.1270557225588627 loss: 0.35228797387085764\n",
            "Round: 948 Weight: [2.29869089 1.13214405] Bias: -1.127124500157243 loss: 0.35228752223959436\n",
            "Round: 949 Weight: [2.29886917 1.13223461] Bias: -1.1271930663235508 loss: 0.35228707334487197\n",
            "Round: 950 Weight: [2.29904691 1.13232489] Bias: -1.1272614217538983 loss: 0.35228662716962983\n",
            "Round: 951 Weight: [2.29922411 1.1324149 ] Bias: -1.1273295671418182 loss: 0.35228618369691855\n",
            "Round: 952 Weight: [2.29940078 1.13250463] Bias: -1.1273975031782744 loss: 0.3522857429098985\n",
            "Round: 953 Weight: [2.29957691 1.1325941 ] Bias: -1.1274652305516735 loss: 0.3522853047918393\n",
            "Round: 954 Weight: [2.2997525  1.13268329] Bias: -1.1275327499478767 loss: 0.352284869326119\n",
            "Round: 955 Weight: [2.29992757 1.13277222] Bias: -1.12760006205021 loss: 0.35228443649622343\n",
            "Round: 956 Weight: [2.3001021  1.13286088] Bias: -1.1276671675394763 loss: 0.35228400628574547\n",
            "Round: 957 Weight: [2.30027611 1.13294927] Bias: -1.1277340670939657 loss: 0.3522835786783839\n",
            "Round: 958 Weight: [2.30044959 1.13303739] Bias: -1.1278007613894667 loss: 0.35228315365794344\n",
            "Round: 959 Weight: [2.30062254 1.13312524] Bias: -1.1278672510992775 loss: 0.3522827312083335\n",
            "Round: 960 Weight: [2.30079497 1.13321284] Bias: -1.1279335368942165 loss: 0.35228231131356735\n",
            "Round: 961 Weight: [2.30096688 1.13330016] Bias: -1.1279996194426334 loss: 0.35228189395776205\n",
            "Round: 962 Weight: [2.30113828 1.13338723] Bias: -1.1280654994104198 loss: 0.3522814791251369\n",
            "Round: 963 Weight: [2.30130915 1.13347403] Bias: -1.1281311774610199 loss: 0.35228106680001353\n",
            "Round: 964 Weight: [2.3014795  1.13356057] Bias: -1.1281966542554414 loss: 0.3522806569668147\n",
            "Round: 965 Weight: [2.30164934 1.13364685] Bias: -1.1282619304522659 loss: 0.3522802496100637\n",
            "Round: 966 Weight: [2.30181867 1.13373287] Bias: -1.1283270067076594 loss: 0.3522798447143839\n",
            "Round: 967 Weight: [2.30198749 1.13381863] Bias: -1.128391883675383 loss: 0.3522794422644976\n",
            "Round: 968 Weight: [2.30215579 1.13390413] Bias: -1.1284565620068032 loss: 0.35227904224522605\n",
            "Round: 969 Weight: [2.30232359 1.13398937] Bias: -1.1285210423509027 loss: 0.352278644641488\n",
            "Round: 970 Weight: [2.30249088 1.13407436] Bias: -1.1285853253542895 loss: 0.3522782494382997\n",
            "Round: 971 Weight: [2.30265767 1.13415909] Bias: -1.1286494116612087 loss: 0.3522778566207738\n",
            "Round: 972 Weight: [2.30282395 1.13424357] Bias: -1.128713301913552 loss: 0.35227746617411887\n",
            "Round: 973 Weight: [2.30298973 1.13432779] Bias: -1.1287769967508676 loss: 0.35227707808363884\n",
            "Round: 974 Weight: [2.30315501 1.13441176] Bias: -1.1288404968103707 loss: 0.35227669233473224\n",
            "Round: 975 Weight: [2.30331979 1.13449547] Bias: -1.1289038027269533 loss: 0.35227630891289113\n",
            "Round: 976 Weight: [2.30348407 1.13457894] Bias: -1.128966915133195 loss: 0.35227592780370176\n",
            "Round: 977 Weight: [2.30364786 1.13466215] Bias: -1.1290298346593715 loss: 0.3522755489928422\n",
            "Round: 978 Weight: [2.30381115 1.13474511] Bias: -1.129092561933466 loss: 0.3522751724660831\n",
            "Round: 979 Weight: [2.30397395 1.13482782] Bias: -1.129155097581178 loss: 0.35227479820928626\n",
            "Round: 980 Weight: [2.30413626 1.13491029] Bias: -1.1292174422259333 loss: 0.35227442620840466\n",
            "Round: 981 Weight: [2.30429808 1.1349925 ] Bias: -1.1292795964888944 loss: 0.3522740564494812\n",
            "Round: 982 Weight: [2.30445942 1.13507447] Bias: -1.1293415609889694 loss: 0.3522736889186485\n",
            "Round: 983 Weight: [2.30462026 1.13515619] Bias: -1.129403336342822 loss: 0.35227332360212815\n",
            "Round: 984 Weight: [2.30478063 1.13523767] Bias: -1.1294649231648808 loss: 0.3522729604862301\n",
            "Round: 985 Weight: [2.30494051 1.1353189 ] Bias: -1.1295263220673493 loss: 0.3522725995573522\n",
            "Round: 986 Weight: [2.3050999  1.13539989] Bias: -1.129587533660215 loss: 0.35227224080197933\n",
            "Round: 987 Weight: [2.30525882 1.13548063] Bias: -1.1296485585512595 loss: 0.3522718842066833\n",
            "Round: 988 Weight: [2.30541726 1.13556113] Bias: -1.1297093973460668 loss: 0.35227152975812165\n",
            "Round: 989 Weight: [2.30557522 1.13564139] Bias: -1.1297700506480335 loss: 0.3522711774430375\n",
            "Round: 990 Weight: [2.30573271 1.13572141] Bias: -1.1298305190583777 loss: 0.35227082724825903\n",
            "Round: 991 Weight: [2.30588972 1.13580119] Bias: -1.1298908031761488 loss: 0.3522704791606982\n",
            "Round: 992 Weight: [2.30604626 1.13588073] Bias: -1.1299509035982356 loss: 0.3522701331673514\n",
            "Round: 993 Weight: [2.30620233 1.13596003] Bias: -1.1300108209193769 loss: 0.35226978925529767\n",
            "Round: 994 Weight: [2.30635793 1.13603909] Bias: -1.1300705557321693 loss: 0.35226944741169897\n",
            "Round: 995 Weight: [2.30651306 1.13611791] Bias: -1.130130108627077 loss: 0.3522691076237992\n",
            "Round: 996 Weight: [2.30666772 1.1361965 ] Bias: -1.1301894801924406 loss: 0.3522687698789239\n",
            "Round: 997 Weight: [2.30682192 1.13627485] Bias: -1.1302486710144861 loss: 0.3522684341644794\n",
            "Round: 998 Weight: [2.30697566 1.13635297] Bias: -1.1303076816773339 loss: 0.3522681004679525\n",
            "Round: 999 Weight: [2.30712893 1.13643085] Bias: -1.1303665127630071 loss: 0.3522677687769101\n",
            "Round: 1000 Weight: [2.30728174 1.1365085 ] Bias: -1.1304251648514416 loss: 0.35226743907899805\n",
            "Round: 1001 Weight: [2.30743409 1.13658592] Bias: -1.1304836385204935 loss: 0.35226711136194155\n",
            "Round: 1002 Weight: [2.30758599 1.1366631 ] Bias: -1.1305419343459484 loss: 0.3522667856135436\n",
            "Round: 1003 Weight: [2.30773743 1.13674006] Bias: -1.1306000529015305 loss: 0.35226646182168525\n",
            "Round: 1004 Weight: [2.30788841 1.13681678] Bias: -1.1306579947589106 loss: 0.35226613997432477\n",
            "Round: 1005 Weight: [2.30803894 1.13689327] Bias: -1.130715760487715 loss: 0.35226582005949697\n",
            "Round: 1006 Weight: [2.30818902 1.13696954] Bias: -1.130773350655534 loss: 0.3522655020653132\n",
            "Round: 1007 Weight: [2.30833865 1.13704557] Bias: -1.1308307658279304 loss: 0.35226518597996026\n",
            "Round: 1008 Weight: [2.30848782 1.13712138] Bias: -1.1308880065684483 loss: 0.35226487179170024\n",
            "Round: 1009 Weight: [2.30863656 1.13719696] Bias: -1.130945073438621 loss: 0.35226455948887\n",
            "Round: 1010 Weight: [2.30878484 1.13727231] Bias: -1.1310019669979798 loss: 0.3522642490598804\n",
            "Round: 1011 Weight: [2.30893268 1.13734744] Bias: -1.1310586878040623 loss: 0.3522639404932163\n",
            "Round: 1012 Weight: [2.30908007 1.13742234] Bias: -1.13111523641242 loss: 0.35226363377743564\n",
            "Round: 1013 Weight: [2.30922703 1.13749702] Bias: -1.1311716133766276 loss: 0.35226332890116896\n",
            "Round: 1014 Weight: [2.30937354 1.13757147] Bias: -1.131227819248291 loss: 0.35226302585311925\n",
            "Round: 1015 Weight: [2.30951961 1.13764571] Bias: -1.1312838545770547 loss: 0.3522627246220611\n",
            "Round: 1016 Weight: [2.30966524 1.13771972] Bias: -1.1313397199106108 loss: 0.35226242519684065\n",
            "Round: 1017 Weight: [2.30981044 1.1377935 ] Bias: -1.1313954157947068 loss: 0.35226212756637454\n",
            "Round: 1018 Weight: [2.3099552  1.13786707] Bias: -1.1314509427731536 loss: 0.3522618317196499\n",
            "Round: 1019 Weight: [2.31009953 1.13794042] Bias: -1.1315063013878333 loss: 0.35226153764572365\n",
            "Round: 1020 Weight: [2.31024343 1.13801355] Bias: -1.1315614921787078 loss: 0.35226124533372244\n",
            "Round: 1021 Weight: [2.31038689 1.13808646] Bias: -1.1316165156838263 loss: 0.3522609547728413\n",
            "Round: 1022 Weight: [2.31052993 1.13815915] Bias: -1.1316713724393328 loss: 0.3522606659523444\n",
            "Round: 1023 Weight: [2.31067253 1.13823162] Bias: -1.1317260629794752 loss: 0.3522603788615633\n",
            "Round: 1024 Weight: [2.31081471 1.13830388] Bias: -1.1317805878366116 loss: 0.35226009348989784\n",
            "Round: 1025 Weight: [2.31095646 1.13837592] Bias: -1.1318349475412193 loss: 0.3522598098268143\n",
            "Round: 1026 Weight: [2.31109779 1.13844775] Bias: -1.1318891426219015 loss: 0.35225952786184606\n",
            "Round: 1027 Weight: [2.3112387  1.13851936] Bias: -1.1319431736053962 loss: 0.35225924758459287\n",
            "Round: 1028 Weight: [2.31137918 1.13859076] Bias: -1.1319970410165827 loss: 0.35225896898471976\n",
            "Round: 1029 Weight: [2.31151924 1.13866194] Bias: -1.13205074537849 loss: 0.35225869205195776\n",
            "Round: 1030 Weight: [2.31165889 1.13873292] Bias: -1.1321042872123042 loss: 0.3522584167761025\n",
            "Round: 1031 Weight: [2.31179811 1.13880368] Bias: -1.1321576670373754 loss: 0.352258143147014\n",
            "Round: 1032 Weight: [2.31193692 1.13887422] Bias: -1.1322108853712263 loss: 0.35225787115461676\n",
            "Round: 1033 Weight: [2.31207531 1.13894456] Bias: -1.132263942729559 loss: 0.3522576007888986\n",
            "Round: 1034 Weight: [2.31221329 1.13901469] Bias: -1.1323168396262626 loss: 0.35225733203991094\n",
            "Round: 1035 Weight: [2.31235086 1.13908461] Bias: -1.1323695765734205 loss: 0.35225706489776754\n",
            "Round: 1036 Weight: [2.31248801 1.13915432] Bias: -1.132422154081318 loss: 0.352256799352645\n",
            "Round: 1037 Weight: [2.31262476 1.13922382] Bias: -1.132474572658449 loss: 0.35225653539478163\n",
            "Round: 1038 Weight: [2.31276109 1.13929311] Bias: -1.1325268328115246 loss: 0.35225627301447765\n",
            "Round: 1039 Weight: [2.31289702 1.1393622 ] Bias: -1.1325789350454787 loss: 0.352256012202094\n",
            "Round: 1040 Weight: [2.31303255 1.13943108] Bias: -1.1326308798634765 loss: 0.352255752948053\n",
            "Round: 1041 Weight: [2.31316766 1.13949976] Bias: -1.132682667766921 loss: 0.3522554952428368\n",
            "Round: 1042 Weight: [2.31330238 1.13956823] Bias: -1.1327342992554605 loss: 0.3522552390769879\n",
            "Round: 1043 Weight: [2.31343669 1.1396365 ] Bias: -1.1327857748269956 loss: 0.35225498444110814\n",
            "Round: 1044 Weight: [2.3135706  1.13970456] Bias: -1.132837094977686 loss: 0.35225473132585866\n",
            "Round: 1045 Weight: [2.3137041  1.13977242] Bias: -1.132888260201958 loss: 0.3522544797219596\n",
            "Round: 1046 Weight: [2.31383721 1.13984008] Bias: -1.1329392709925115 loss: 0.3522542296201892\n",
            "Round: 1047 Weight: [2.31396993 1.13990753] Bias: -1.1329901278403263 loss: 0.35225398101138383\n",
            "Round: 1048 Weight: [2.31410224 1.13997479] Bias: -1.13304083123467 loss: 0.3522537338864376\n",
            "Round: 1049 Weight: [2.31423417 1.14004184] Bias: -1.1330913816631043 loss: 0.35225348823630187\n",
            "Round: 1050 Weight: [2.31436569 1.1401087 ] Bias: -1.1331417796114918 loss: 0.352253244051985\n",
            "Round: 1051 Weight: [2.31449683 1.14017535] Bias: -1.1331920255640033 loss: 0.35225300132455156\n",
            "Round: 1052 Weight: [2.31462757 1.14024181] Bias: -1.1332421200031242 loss: 0.3522527600451227\n",
            "Round: 1053 Weight: [2.31475792 1.14030807] Bias: -1.1332920634096615 loss: 0.3522525202048749\n",
            "Round: 1054 Weight: [2.31488789 1.14037413] Bias: -1.1333418562627506 loss: 0.3522522817950405\n",
            "Round: 1055 Weight: [2.31501747 1.14044   ] Bias: -1.1333914990398617 loss: 0.3522520448069066\n",
            "Round: 1056 Weight: [2.31514666 1.14050567] Bias: -1.1334409922168067 loss: 0.35225180923181526\n",
            "Round: 1057 Weight: [2.31527546 1.14057114] Bias: -1.133490336267746 loss: 0.35225157506116256\n",
            "Round: 1058 Weight: [2.31540388 1.14063642] Bias: -1.1335395316651944 loss: 0.35225134228639876\n",
            "Round: 1059 Weight: [2.31553192 1.1407015 ] Bias: -1.1335885788800288 loss: 0.3522511108990277\n",
            "Round: 1060 Weight: [2.31565957 1.14076639] Bias: -1.133637478381494 loss: 0.35225088089060674\n",
            "Round: 1061 Weight: [2.31578685 1.14083109] Bias: -1.133686230637209 loss: 0.3522506522527457\n",
            "Round: 1062 Weight: [2.31591375 1.1408956 ] Bias: -1.1337348361131745 loss: 0.35225042497710735\n",
            "Round: 1063 Weight: [2.31604026 1.14095991] Bias: -1.1337832952737779 loss: 0.35225019905540655\n",
            "Round: 1064 Weight: [2.3161664  1.14102403] Bias: -1.1338316085818012 loss: 0.3522499744794103\n",
            "Round: 1065 Weight: [2.31629217 1.14108796] Bias: -1.1338797764984265 loss: 0.35224975124093677\n",
            "Round: 1066 Weight: [2.31641756 1.1411517 ] Bias: -1.1339277994832424 loss: 0.3522495293318556\n",
            "Round: 1067 Weight: [2.31654257 1.14121525] Bias: -1.133975677994251 loss: 0.3522493087440873\n",
            "Round: 1068 Weight: [2.31666722 1.14127862] Bias: -1.1340234124878732 loss: 0.3522490894696031\n",
            "Round: 1069 Weight: [2.31679149 1.14134179] Bias: -1.1340710034189558 loss: 0.35224887150042394\n",
            "Round: 1070 Weight: [2.31691539 1.14140478] Bias: -1.1341184512407774 loss: 0.35224865482862133\n",
            "Round: 1071 Weight: [2.31703893 1.14146758] Bias: -1.1341657564050545 loss: 0.35224843944631595\n",
            "Round: 1072 Weight: [2.31716209 1.14153019] Bias: -1.134212919361948 loss: 0.35224822534567773\n",
            "Round: 1073 Weight: [2.31728489 1.14159261] Bias: -1.134259940560069 loss: 0.3522480125189258\n",
            "Round: 1074 Weight: [2.31740732 1.14165485] Bias: -1.1343068204464855 loss: 0.3522478009583277\n",
            "Round: 1075 Weight: [2.31752939 1.14171691] Bias: -1.1343535594667276 loss: 0.35224759065619926\n",
            "Round: 1076 Weight: [2.3176511  1.14177878] Bias: -1.1344001580647944 loss: 0.3522473816049043\n",
            "Round: 1077 Weight: [2.31777244 1.14184047] Bias: -1.13444661668316 loss: 0.3522471737968546\n",
            "Round: 1078 Weight: [2.31789343 1.14190197] Bias: -1.1344929357627782 loss: 0.3522469672245089\n",
            "Round: 1079 Weight: [2.31801405 1.1419633 ] Bias: -1.1345391157430906 loss: 0.35224676188037324\n",
            "Round: 1080 Weight: [2.31813431 1.14202443] Bias: -1.1345851570620311 loss: 0.35224655775700026\n",
            "Round: 1081 Weight: [2.31825422 1.14208539] Bias: -1.1346310601560319 loss: 0.35224635484698924\n",
            "Round: 1082 Weight: [2.31837377 1.14214617] Bias: -1.13467682546003 loss: 0.35224615314298546\n",
            "Round: 1083 Weight: [2.31849296 1.14220677] Bias: -1.1347224534074725 loss: 0.3522459526376801\n",
            "Round: 1084 Weight: [2.3186118  1.14226718] Bias: -1.134767944430323 loss: 0.3522457533238099\n",
            "Round: 1085 Weight: [2.31873029 1.14232742] Bias: -1.1348132989590667 loss: 0.35224555519415673\n",
            "Round: 1086 Weight: [2.31884842 1.14238748] Bias: -1.1348585174227168 loss: 0.35224535824154773\n",
            "Round: 1087 Weight: [2.31896621 1.14244736] Bias: -1.1349036002488202 loss: 0.3522451624588545\n",
            "Round: 1088 Weight: [2.31908364 1.14250706] Bias: -1.134948547863463 loss: 0.3522449678389929\n",
            "Round: 1089 Weight: [2.31920072 1.14256659] Bias: -1.1349933606912763 loss: 0.3522447743749231\n",
            "Round: 1090 Weight: [2.31931746 1.14262594] Bias: -1.1350380391554415 loss: 0.352244582059649\n",
            "Round: 1091 Weight: [2.31943385 1.14268511] Bias: -1.135082583677697 loss: 0.35224439088621795\n",
            "Round: 1092 Weight: [2.31954989 1.14274411] Bias: -1.1351269946783424 loss: 0.3522442008477208\n",
            "Round: 1093 Weight: [2.31966559 1.14280293] Bias: -1.1351712725762455 loss: 0.3522440119372911\n",
            "Round: 1094 Weight: [2.31978095 1.14286158] Bias: -1.1352154177888467 loss: 0.35224382414810523\n",
            "Round: 1095 Weight: [2.31989596 1.14292005] Bias: -1.1352594307321655 loss: 0.3522436374733819\n",
            "Round: 1096 Weight: [2.32001063 1.14297835] Bias: -1.1353033118208056 loss: 0.3522434519063819\n",
            "Round: 1097 Weight: [2.32012496 1.14303648] Bias: -1.13534706146796 loss: 0.35224326744040807\n",
            "Round: 1098 Weight: [2.32023895 1.14309444] Bias: -1.135390680085417 loss: 0.35224308406880483\n",
            "Round: 1099 Weight: [2.3203526  1.14315222] Bias: -1.1354341680835656 loss: 0.3522429017849578\n",
            "Round: 1100 Weight: [2.32046592 1.14320983] Bias: -1.135477525871401 loss: 0.3522427205822937\n",
            "Round: 1101 Weight: [2.3205789  1.14326728] Bias: -1.1355207538565295 loss: 0.3522425404542801\n",
            "Round: 1102 Weight: [2.32069154 1.14332455] Bias: -1.1355638524451743 loss: 0.35224236139442505\n",
            "Round: 1103 Weight: [2.32080385 1.14338165] Bias: -1.135606822042181 loss: 0.3522421833962768\n",
            "Round: 1104 Weight: [2.32091583 1.14343858] Bias: -1.1356496630510224 loss: 0.35224200645342385\n",
            "Round: 1105 Weight: [2.32102748 1.14349535] Bias: -1.135692375873804 loss: 0.3522418305594943\n",
            "Round: 1106 Weight: [2.32113879 1.14355194] Bias: -1.1357349609112695 loss: 0.3522416557081557\n",
            "Round: 1107 Weight: [2.32124977 1.14360837] Bias: -1.135777418562806 loss: 0.352241481893115\n",
            "Round: 1108 Weight: [2.32136043 1.14366464] Bias: -1.1358197492264488 loss: 0.35224130910811796\n",
            "Round: 1109 Weight: [2.32147075 1.14372073] Bias: -1.1358619532988872 loss: 0.35224113734694923\n",
            "Round: 1110 Weight: [2.32158075 1.14377666] Bias: -1.1359040311754691 loss: 0.3522409666034319\n",
            "Round: 1111 Weight: [2.32169042 1.14383242] Bias: -1.135945983250207 loss: 0.3522407968714273\n",
            "Round: 1112 Weight: [2.32179977 1.14388802] Bias: -1.1359878099157819 loss: 0.35224062814483487\n",
            "Round: 1113 Weight: [2.3219088  1.14394346] Bias: -1.1360295115635493 loss: 0.3522404604175915\n",
            "Round: 1114 Weight: [2.3220175  1.14399873] Bias: -1.1360710885835443 loss: 0.35224029368367205\n",
            "Round: 1115 Weight: [2.32212588 1.14405383] Bias: -1.1361125413644861 loss: 0.35224012793708825\n",
            "Round: 1116 Weight: [2.32223393 1.14410878] Bias: -1.1361538702937837 loss: 0.35223996317188905\n",
            "Round: 1117 Weight: [2.32234167 1.14416356] Bias: -1.1361950757575403 loss: 0.35223979938216027\n",
            "Round: 1118 Weight: [2.32244909 1.14421818] Bias: -1.1362361581405587 loss: 0.35223963656202406\n",
            "Round: 1119 Weight: [2.32255619 1.14427263] Bias: -1.136277117826346 loss: 0.3522394747056392\n",
            "Round: 1120 Weight: [2.32266297 1.14432693] Bias: -1.136317955197119 loss: 0.35223931380720025\n",
            "Round: 1121 Weight: [2.32276944 1.14438106] Bias: -1.1363586706338082 loss: 0.3522391538609379\n",
            "Round: 1122 Weight: [2.32287559 1.14443504] Bias: -1.136399264516064 loss: 0.35223899486111826\n",
            "Round: 1123 Weight: [2.32298143 1.14448886] Bias: -1.1364397372222605 loss: 0.35223883680204304\n",
            "Round: 1124 Weight: [2.32308695 1.14454251] Bias: -1.1364800891295008 loss: 0.352238679678049\n",
            "Round: 1125 Weight: [2.32319216 1.14459601] Bias: -1.1365203206136218 loss: 0.35223852348350787\n",
            "Round: 1126 Weight: [2.32329706 1.14464935] Bias: -1.1365604320491989 loss: 0.35223836821282617\n",
            "Round: 1127 Weight: [2.32340165 1.14470253] Bias: -1.1366004238095508 loss: 0.35223821386044485\n",
            "Round: 1128 Weight: [2.32350593 1.14475556] Bias: -1.1366402962667448 loss: 0.3522380604208393\n",
            "Round: 1129 Weight: [2.3236099  1.14480843] Bias: -1.1366800497916008 loss: 0.3522379078885189\n",
            "Round: 1130 Weight: [2.32371357 1.14486114] Bias: -1.136719684753696 loss: 0.3522377562580266\n",
            "Round: 1131 Weight: [2.32381693 1.1449137 ] Bias: -1.1367592015213706 loss: 0.3522376055239394\n",
            "Round: 1132 Weight: [2.32391998 1.1449661 ] Bias: -1.1367986004617314 loss: 0.3522374556808677\n",
            "Round: 1133 Weight: [2.32402272 1.14501835] Bias: -1.1368378819406568 loss: 0.35223730672345477\n",
            "Round: 1134 Weight: [2.32412517 1.14507044] Bias: -1.136877046322802 loss: 0.3522371586463772\n",
            "Round: 1135 Weight: [2.32422731 1.14512238] Bias: -1.1369160939716025 loss: 0.3522370114443442\n",
            "Round: 1136 Weight: [2.32432914 1.14517416] Bias: -1.13695502524928 loss: 0.35223686511209756\n",
            "Round: 1137 Weight: [2.32443068 1.14522579] Bias: -1.1369938405168458 loss: 0.3522367196444116\n",
            "Round: 1138 Weight: [2.32453192 1.14527727] Bias: -1.1370325401341064 loss: 0.3522365750360926\n",
            "Round: 1139 Weight: [2.32463285 1.1453286 ] Bias: -1.137071124459667 loss: 0.3522364312819789\n",
            "Round: 1140 Weight: [2.32473349 1.14537978] Bias: -1.1371095938509368 loss: 0.3522362883769407\n",
            "Round: 1141 Weight: [2.32483384 1.1454308 ] Bias: -1.1371479486641334 loss: 0.35223614631587946\n",
            "Round: 1142 Weight: [2.32493388 1.14548168] Bias: -1.1371861892542867 loss: 0.35223600509372827\n",
            "Round: 1143 Weight: [2.32503363 1.1455324 ] Bias: -1.1372243159752444 loss: 0.35223586470545126\n",
            "Round: 1144 Weight: [2.32513308 1.14558298] Bias: -1.1372623291796755 loss: 0.3522357251460435\n",
            "Round: 1145 Weight: [2.32523225 1.14563341] Bias: -1.1373002292190748 loss: 0.35223558641053104\n",
            "Round: 1146 Weight: [2.32533111 1.14568368] Bias: -1.137338016443768 loss: 0.3522354484939699\n",
            "Round: 1147 Weight: [2.32542969 1.14573381] Bias: -1.1373756912029156 loss: 0.3522353113914472\n",
            "Round: 1148 Weight: [2.32552797 1.14578379] Bias: -1.137413253844517 loss: 0.35223517509807983\n",
            "Round: 1149 Weight: [2.32562597 1.14583363] Bias: -1.1374507047154152 loss: 0.35223503960901476\n",
            "Round: 1150 Weight: [2.32572367 1.14588331] Bias: -1.1374880441613013 loss: 0.35223490491942866\n",
            "Round: 1151 Weight: [2.32582109 1.14593285] Bias: -1.1375252725267184 loss: 0.3522347710245279\n",
            "Round: 1152 Weight: [2.32591822 1.14598225] Bias: -1.137562390155066 loss: 0.35223463791954834\n",
            "Round: 1153 Weight: [2.32601506 1.14603149] Bias: -1.1375993973886045 loss: 0.35223450559975483\n",
            "Round: 1154 Weight: [2.32611162 1.1460806 ] Bias: -1.1376362945684593 loss: 0.35223437406044156\n",
            "Round: 1155 Weight: [2.32620789 1.14612956] Bias: -1.1376730820346248 loss: 0.3522342432969313\n",
            "Round: 1156 Weight: [2.32630388 1.14617837] Bias: -1.137709760125969 loss: 0.3522341133045757\n",
            "Round: 1157 Weight: [2.32639958 1.14622704] Bias: -1.1377463291802372 loss: 0.35223398407875484\n",
            "Round: 1158 Weight: [2.326495   1.14627557] Bias: -1.1377827895340569 loss: 0.35223385561487724\n",
            "Round: 1159 Weight: [2.32659014 1.14632395] Bias: -1.1378191415229413 loss: 0.35223372790837926\n",
            "Round: 1160 Weight: [2.326685   1.14637219] Bias: -1.1378553854812936 loss: 0.35223360095472533\n",
            "Round: 1161 Weight: [2.32677958 1.14642029] Bias: -1.1378915217424113 loss: 0.35223347474940797\n",
            "Round: 1162 Weight: [2.32687388 1.14646825] Bias: -1.1379275506384903 loss: 0.35223334928794686\n",
            "Round: 1163 Weight: [2.32696791 1.14651606] Bias: -1.1379634725006287 loss: 0.3522332245658895\n",
            "Round: 1164 Weight: [2.32706165 1.14656374] Bias: -1.1379992876588312 loss: 0.35223310057881024\n",
            "Round: 1165 Weight: [2.32715512 1.14661127] Bias: -1.1380349964420127 loss: 0.3522329773223109\n",
            "Round: 1166 Weight: [2.32724832 1.14665867] Bias: -1.1380705991780031 loss: 0.35223285479202\n",
            "Round: 1167 Weight: [2.32734123 1.14670592] Bias: -1.1381060961935505 loss: 0.35223273298359287\n",
            "Round: 1168 Weight: [2.32743388 1.14675304] Bias: -1.1381414878143254 loss: 0.35223261189271143\n",
            "Round: 1169 Weight: [2.32752625 1.14680002] Bias: -1.1381767743649254 loss: 0.35223249151508396\n",
            "Round: 1170 Weight: [2.32761835 1.14684686] Bias: -1.138211956168878 loss: 0.352232371846445\n",
            "Round: 1171 Weight: [2.32771018 1.14689356] Bias: -1.1382470335486452 loss: 0.35223225288255516\n",
            "Round: 1172 Weight: [2.32780173 1.14694012] Bias: -1.1382820068256276 loss: 0.35223213461920105\n",
            "Round: 1173 Weight: [2.32789302 1.14698655] Bias: -1.1383168763201679 loss: 0.3522320170521949\n",
            "Round: 1174 Weight: [2.32798404 1.14703284] Bias: -1.1383516423515547 loss: 0.35223190017737455\n",
            "Round: 1175 Weight: [2.32807479 1.14707899] Bias: -1.1383863052380272 loss: 0.3522317839906033\n",
            "Round: 1176 Weight: [2.32816527 1.14712501] Bias: -1.1384208652967782 loss: 0.35223166848776977\n",
            "Round: 1177 Weight: [2.32825549 1.14717089] Bias: -1.138455322843958 loss: 0.3522315536647877\n",
            "Round: 1178 Weight: [2.32834544 1.14721664] Bias: -1.1384896781946787 loss: 0.3522314395175955\n",
            "Round: 1179 Weight: [2.32843513 1.14726226] Bias: -1.1385239316630178 loss: 0.3522313260421566\n",
            "Round: 1180 Weight: [2.32852455 1.14730773] Bias: -1.138558083562022 loss: 0.3522312132344592\n",
            "Round: 1181 Weight: [2.32861371 1.14735308] Bias: -1.1385921342037104 loss: 0.3522311010905158\n",
            "Round: 1182 Weight: [2.3287026  1.14739829] Bias: -1.1386260838990796 loss: 0.352230989606363\n",
            "Round: 1183 Weight: [2.32879124 1.14744337] Bias: -1.138659932958106 loss: 0.35223087877806214\n",
            "Round: 1184 Weight: [2.32887961 1.14748832] Bias: -1.1386936816897506 loss: 0.352230768601698\n",
            "Round: 1185 Weight: [2.32896772 1.14753313] Bias: -1.1387273304019618 loss: 0.3522306590733797\n",
            "Round: 1186 Weight: [2.32905558 1.14757781] Bias: -1.1387608794016804 loss: 0.35223055018923966\n",
            "Round: 1187 Weight: [2.32914317 1.14762237] Bias: -1.1387943289948415 loss: 0.3522304419454343\n",
            "Round: 1188 Weight: [2.32923051 1.14766679] Bias: -1.1388276794863796 loss: 0.352230334338143\n",
            "Round: 1189 Weight: [2.32931759 1.14771107] Bias: -1.138860931180232 loss: 0.3522302273635688\n",
            "Round: 1190 Weight: [2.32940441 1.14775523] Bias: -1.1388940843793418 loss: 0.35223012101793777\n",
            "Round: 1191 Weight: [2.32949098 1.14779926] Bias: -1.1389271393856621 loss: 0.35223001529749876\n",
            "Round: 1192 Weight: [2.3295773  1.14784316] Bias: -1.1389600965001594 loss: 0.35222991019852373\n",
            "Round: 1193 Weight: [2.32966336 1.14788694] Bias: -1.1389929560228174 loss: 0.3522298057173073\n",
            "Round: 1194 Weight: [2.32974916 1.14793058] Bias: -1.13902571825264 loss: 0.3522297018501663\n",
            "Round: 1195 Weight: [2.32983472 1.14797409] Bias: -1.1390583834876558 loss: 0.35222959859344055\n",
            "Round: 1196 Weight: [2.32992002 1.14801748] Bias: -1.1390909520249206 loss: 0.3522294959434917\n",
            "Round: 1197 Weight: [2.33000507 1.14806074] Bias: -1.1391234241605217 loss: 0.3522293938967036\n",
            "Round: 1198 Weight: [2.33008988 1.14810387] Bias: -1.1391558001895812 loss: 0.35222929244948226\n",
            "Round: 1199 Weight: [2.33017443 1.14814688] Bias: -1.139188080406259 loss: 0.3522291915982555\n",
            "Round: 1200 Weight: [2.33025873 1.14818975] Bias: -1.1392202651037575 loss: 0.3522290913394728\n",
            "Round: 1201 Weight: [2.33034279 1.14823251] Bias: -1.1392523545743234 loss: 0.35222899166960503\n",
            "Round: 1202 Weight: [2.3304266  1.14827514] Bias: -1.1392843491092526 loss: 0.352228892585145\n",
            "Round: 1203 Weight: [2.33051016 1.14831764] Bias: -1.139316248998893 loss: 0.35222879408260643\n",
            "Round: 1204 Weight: [2.33059348 1.14836002] Bias: -1.139348054532648 loss: 0.3522286961585243\n",
            "Round: 1205 Weight: [2.33067655 1.14840227] Bias: -1.1393797659989797 loss: 0.3522285988094547\n",
            "Round: 1206 Weight: [2.33075938 1.1484444 ] Bias: -1.139411383685413 loss: 0.35222850203197464\n",
            "Round: 1207 Weight: [2.33084196 1.1484864 ] Bias: -1.139442907878538 loss: 0.3522284058226819\n",
            "Round: 1208 Weight: [2.33092431 1.14852829] Bias: -1.139474338864014 loss: 0.35222831017819495\n",
            "Round: 1209 Weight: [2.33100641 1.14857005] Bias: -1.139505676926573 loss: 0.3522282150951527\n",
            "Round: 1210 Weight: [2.33108827 1.14861168] Bias: -1.1395369223500222 loss: 0.35222812057021446\n",
            "Round: 1211 Weight: [2.33116989 1.1486532 ] Bias: -1.1395680754172486 loss: 0.35222802660006003\n",
            "Round: 1212 Weight: [2.33125126 1.14869459] Bias: -1.139599136410221 loss: 0.352227933181389\n",
            "Round: 1213 Weight: [2.3313324  1.14873586] Bias: -1.139630105609994 loss: 0.3522278403109213\n",
            "Round: 1214 Weight: [2.33141331 1.14877701] Bias: -1.1396609832967115 loss: 0.3522277479853966\n",
            "Round: 1215 Weight: [2.33149397 1.14881804] Bias: -1.1396917697496094 loss: 0.35222765620157426\n",
            "Round: 1216 Weight: [2.3315744  1.14885895] Bias: -1.1397224652470193 loss: 0.35222756495623364\n",
            "Round: 1217 Weight: [2.33165459 1.14889974] Bias: -1.1397530700663712 loss: 0.3522274742461731\n",
            "Round: 1218 Weight: [2.33173455 1.14894041] Bias: -1.1397835844841973 loss: 0.3522273840682109\n",
            "Round: 1219 Weight: [2.33181427 1.14898096] Bias: -1.1398140087761348 loss: 0.3522272944191842\n",
            "Round: 1220 Weight: [2.33189375 1.14902139] Bias: -1.1398443432169298 loss: 0.35222720529594964\n",
            "Round: 1221 Weight: [2.33197301 1.1490617 ] Bias: -1.1398745880804395 loss: 0.35222711669538265\n",
            "Round: 1222 Weight: [2.33205203 1.1491019 ] Bias: -1.1399047436396361 loss: 0.35222702861437777\n",
            "Round: 1223 Weight: [2.33213082 1.14914198] Bias: -1.1399348101666096 loss: 0.35222694104984814\n",
            "Round: 1224 Weight: [2.33220938 1.14918194] Bias: -1.1399647879325712 loss: 0.35222685399872594\n",
            "Round: 1225 Weight: [2.3322877  1.14922178] Bias: -1.139994677207856 loss: 0.3522267674579614\n",
            "Round: 1226 Weight: [2.3323658 1.1492615] Bias: -1.1400244782619269 loss: 0.35222668142452374\n",
            "Round: 1227 Weight: [2.33244367 1.14930111] Bias: -1.140054191363377 loss: 0.3522265958954002\n",
            "Round: 1228 Weight: [2.33252131 1.14934061] Bias: -1.1400838167799332 loss: 0.3522265108675964\n",
            "Round: 1229 Weight: [2.33259872 1.14937998] Bias: -1.1401133547784585 loss: 0.35222642633813595\n",
            "Round: 1230 Weight: [2.33267591 1.14941924] Bias: -1.1401428056249563 loss: 0.3522263423040605\n",
            "Round: 1231 Weight: [2.33275287 1.14945839] Bias: -1.1401721695845721 loss: 0.3522262587624298\n",
            "Round: 1232 Weight: [2.3328296  1.14949742] Bias: -1.1402014469215975 loss: 0.35222617571032105\n",
            "Round: 1233 Weight: [2.33290611 1.14953634] Bias: -1.1402306378994733 loss: 0.3522260931448293\n",
            "Round: 1234 Weight: [2.33298239 1.14957515] Bias: -1.1402597427807915 loss: 0.35222601106306706\n",
            "Round: 1235 Weight: [2.33305845 1.14961384] Bias: -1.1402887618272994 loss: 0.35222592946216463\n",
            "Round: 1236 Weight: [2.33313429 1.14965241] Bias: -1.1403176952999023 loss: 0.35222584833926907\n",
            "Round: 1237 Weight: [2.33320991 1.14969088] Bias: -1.1403465434586662 loss: 0.3522257676915452\n",
            "Round: 1238 Weight: [2.3332853  1.14972923] Bias: -1.1403753065628206 loss: 0.3522256875161747\n",
            "Round: 1239 Weight: [2.33336047 1.14976747] Bias: -1.1404039848707626 loss: 0.35222560781035633\n",
            "Round: 1240 Weight: [2.33343542 1.14980559] Bias: -1.1404325786400582 loss: 0.35222552857130585\n",
            "Round: 1241 Weight: [2.33351016 1.14984361] Bias: -1.1404610881274466 loss: 0.35222544979625553\n",
            "Round: 1242 Weight: [2.33358467 1.14988151] Bias: -1.1404895135888427 loss: 0.35222537148245486\n",
            "Round: 1243 Weight: [2.33365896 1.1499193 ] Bias: -1.1405178552793394 loss: 0.3522252936271696\n",
            "Round: 1244 Weight: [2.33373304 1.14995699] Bias: -1.1405461134532116 loss: 0.35222521622768177\n",
            "Round: 1245 Weight: [2.3338069  1.14999456] Bias: -1.140574288363918 loss: 0.35222513928129046\n",
            "Round: 1246 Weight: [2.33388055 1.15003202] Bias: -1.140602380264105 loss: 0.3522250627853104\n",
            "Round: 1247 Weight: [2.33395397 1.15006937] Bias: -1.1406303894056087 loss: 0.3522249867370729\n",
            "Round: 1248 Weight: [2.33402719 1.15010662] Bias: -1.1406583160394583 loss: 0.3522249111339254\n",
            "Round: 1249 Weight: [2.33410019 1.15014375] Bias: -1.140686160415879 loss: 0.35222483597323095\n",
            "Round: 1250 Weight: [2.33417297 1.15018078] Bias: -1.1407139227842937 loss: 0.3522247612523689\n",
            "Round: 1251 Weight: [2.33424554 1.15021769] Bias: -1.1407416033933278 loss: 0.3522246869687341\n",
            "Round: 1252 Weight: [2.3343179 1.1502545] Bias: -1.1407692024908103 loss: 0.3522246131197376\n",
            "Round: 1253 Weight: [2.33439005 1.1502912 ] Bias: -1.1407967203237772 loss: 0.3522245397028052\n",
            "Round: 1254 Weight: [2.33446198 1.1503278 ] Bias: -1.1408241571384747 loss: 0.3522244667153792\n",
            "Round: 1255 Weight: [2.33453371 1.15036428] Bias: -1.1408515131803614 loss: 0.35222439415491635\n",
            "Round: 1256 Weight: [2.33460523 1.15040067] Bias: -1.140878788694111 loss: 0.3522243220188896\n",
            "Round: 1257 Weight: [2.33467653 1.15043694] Bias: -1.1409059839236153 loss: 0.3522242503047865\n",
            "Round: 1258 Weight: [2.33474763 1.15047311] Bias: -1.1409330991119873 loss: 0.35222417901010994\n",
            "Round: 1259 Weight: [2.33481852 1.15050917] Bias: -1.1409601345015634 loss: 0.352224108132378\n",
            "Round: 1260 Weight: [2.3348892  1.15054513] Bias: -1.1409870903339063 loss: 0.35222403766912347\n",
            "Round: 1261 Weight: [2.33495967 1.15058098] Bias: -1.1410139668498074 loss: 0.35222396761789404\n",
            "Round: 1262 Weight: [2.33502994 1.15061672] Bias: -1.1410407642892901 loss: 0.35222389797625214\n",
            "Round: 1263 Weight: [2.33510001 1.15065237] Bias: -1.1410674828916123 loss: 0.35222382874177516\n",
            "Round: 1264 Weight: [2.33516986 1.1506879 ] Bias: -1.1410941228952687 loss: 0.35222375991205457\n",
            "Round: 1265 Weight: [2.33523952 1.15072334] Bias: -1.1411206845379935 loss: 0.35222369148469673\n",
            "Round: 1266 Weight: [2.33530897 1.15075867] Bias: -1.141147168056764 loss: 0.3522236234573222\n",
            "Round: 1267 Weight: [2.33537821 1.15079389] Bias: -1.1411735736878017 loss: 0.3522235558275659\n",
            "Round: 1268 Weight: [2.33544726 1.15082902] Bias: -1.1411999016665761 loss: 0.35222348859307717\n",
            "Round: 1269 Weight: [2.3355161  1.15086404] Bias: -1.1412261522278073 loss: 0.352223421751519\n",
            "Round: 1270 Weight: [2.33558474 1.15089896] Bias: -1.1412523256054676 loss: 0.3522233553005688\n",
            "Round: 1271 Weight: [2.33565318 1.15093378] Bias: -1.1412784220327854 loss: 0.35222328923791785\n",
            "Round: 1272 Weight: [2.33572142 1.15096849] Bias: -1.1413044417422467 loss: 0.3522232235612715\n",
            "Round: 1273 Weight: [2.33578946 1.15100311] Bias: -1.1413303849655982 loss: 0.3522231582683485\n",
            "Round: 1274 Weight: [2.3358573  1.15103762] Bias: -1.1413562519338503 loss: 0.35222309335688146\n",
            "Round: 1275 Weight: [2.33592495 1.15107203] Bias: -1.1413820428772787 loss: 0.3522230288246169\n",
            "Round: 1276 Weight: [2.33599239 1.15110634] Bias: -1.1414077580254278 loss: 0.35222296466931446\n",
            "Round: 1277 Weight: [2.33605964 1.15114055] Bias: -1.1414333976071125 loss: 0.35222290088874736\n",
            "Round: 1278 Weight: [2.33612669 1.15117466] Bias: -1.1414589618504212 loss: 0.3522228374807024\n",
            "Round: 1279 Weight: [2.33619355 1.15120868] Bias: -1.1414844509827184 loss: 0.3522227744429794\n",
            "Round: 1280 Weight: [2.33626021 1.15124259] Bias: -1.141509865230647 loss: 0.3522227117733915\n",
            "Round: 1281 Weight: [2.33632667 1.1512764 ] Bias: -1.1415352048201308 loss: 0.35222264946976495\n",
            "Round: 1282 Weight: [2.33639294 1.15131012] Bias: -1.1415604699763768 loss: 0.35222258752993907\n",
            "Round: 1283 Weight: [2.33645902 1.15134373] Bias: -1.1415856609238784 loss: 0.35222252595176606\n",
            "Round: 1284 Weight: [2.3365249  1.15137725] Bias: -1.1416107778864166 loss: 0.3522224647331112\n",
            "Round: 1285 Weight: [2.33659059 1.15141067] Bias: -1.141635821087064 loss: 0.35222240387185233\n",
            "Round: 1286 Weight: [2.33665609 1.15144399] Bias: -1.1416607907481864 loss: 0.35222234336588015\n",
            "Round: 1287 Weight: [2.3367214  1.15147722] Bias: -1.141685687091445 loss: 0.352222283213098\n",
            "Round: 1288 Weight: [2.33678652 1.15151035] Bias: -1.141710510337799 loss: 0.3522222234114218\n",
            "Round: 1289 Weight: [2.33685145 1.15154338] Bias: -1.1417352607075086 loss: 0.35222216395878\n",
            "Round: 1290 Weight: [2.33691618 1.15157631] Bias: -1.1417599384201371 loss: 0.35222210485311317\n",
            "Round: 1291 Weight: [2.33698073 1.15160915] Bias: -1.1417845436945526 loss: 0.3522220460923748\n",
            "Round: 1292 Weight: [2.33704509 1.15164189] Bias: -1.1418090767489315 loss: 0.3522219876745301\n",
            "Round: 1293 Weight: [2.33710927 1.15167454] Bias: -1.1418335378007602 loss: 0.3522219295975567\n",
            "Round: 1294 Weight: [2.33717325 1.15170709] Bias: -1.1418579270668379 loss: 0.3522218718594443\n",
            "Round: 1295 Weight: [2.33723705 1.15173955] Bias: -1.1418822447632782 loss: 0.3522218144581949\n",
            "Round: 1296 Weight: [2.33730066 1.15177191] Bias: -1.1419064911055121 loss: 0.35222175739182193\n",
            "Round: 1297 Weight: [2.33736409 1.15180418] Bias: -1.1419306663082907 loss: 0.3522217006583512\n",
            "Round: 1298 Weight: [2.33742733 1.15183636] Bias: -1.1419547705856865 loss: 0.3522216442558201\n",
            "Round: 1299 Weight: [2.33749038 1.15186844] Bias: -1.1419788041510965 loss: 0.3522215881822778\n",
            "Round: 1300 Weight: [2.33755325 1.15190042] Bias: -1.1420027672172444 loss: 0.3522215324357853\n",
            "Round: 1301 Weight: [2.33761594 1.15193232] Bias: -1.1420266599961826 loss: 0.3522214770144149\n",
            "Round: 1302 Weight: [2.33767845 1.15196412] Bias: -1.142050482699295 loss: 0.35222142191625083\n",
            "Round: 1303 Weight: [2.33774077 1.15199582] Bias: -1.1420742355372988 loss: 0.35222136713938845\n",
            "Round: 1304 Weight: [2.33780291 1.15202744] Bias: -1.142097918720247 loss: 0.3522213126819347\n",
            "Round: 1305 Weight: [2.33786487 1.15205896] Bias: -1.1421215324575305 loss: 0.3522212585420078\n",
            "Round: 1306 Weight: [2.33792665 1.15209039] Bias: -1.142145076957881 loss: 0.352221204717737\n",
            "Round: 1307 Weight: [2.33798825 1.15212173] Bias: -1.1421685524293723 loss: 0.3522211512072632\n",
            "Round: 1308 Weight: [2.33804967 1.15215298] Bias: -1.1421919590794234 loss: 0.3522210980087381\n",
            "Round: 1309 Weight: [2.33811091 1.15218414] Bias: -1.1422152971148 loss: 0.3522210451203244\n",
            "Round: 1310 Weight: [2.33817197 1.1522152 ] Bias: -1.1422385667416177 loss: 0.3522209925401961\n",
            "Round: 1311 Weight: [2.33823285 1.15224618] Bias: -1.142261768165343 loss: 0.35222094026653783\n",
            "Round: 1312 Weight: [2.33829356 1.15227706] Bias: -1.1422849015907965 loss: 0.35222088829754505\n",
            "Round: 1313 Weight: [2.33835408 1.15230786] Bias: -1.1423079672221546 loss: 0.35222083663142406\n",
            "Round: 1314 Weight: [2.33841443 1.15233856] Bias: -1.1423309652629516 loss: 0.3522207852663922\n",
            "Round: 1315 Weight: [2.33847461 1.15236918] Bias: -1.1423538959160828 loss: 0.35222073420067695\n",
            "Round: 1316 Weight: [2.33853461 1.15239971] Bias: -1.1423767593838055 loss: 0.3522206834325167\n",
            "Round: 1317 Weight: [2.33859444 1.15243014] Bias: -1.1423995558677418 loss: 0.3522206329601604\n",
            "Round: 1318 Weight: [2.33865409 1.15246049] Bias: -1.1424222855688806 loss: 0.35222058278186696\n",
            "Round: 1319 Weight: [2.33871356 1.15249075] Bias: -1.1424449486875798 loss: 0.3522205328959064\n",
            "Round: 1320 Weight: [2.33877287 1.15252093] Bias: -1.1424675454235687 loss: 0.3522204833005585\n",
            "Round: 1321 Weight: [2.338832   1.15255101] Bias: -1.1424900759759495 loss: 0.3522204339941137\n",
            "Round: 1322 Weight: [2.33889095 1.15258101] Bias: -1.1425125405432002 loss: 0.35222038497487235\n",
            "Round: 1323 Weight: [2.33894974 1.15261092] Bias: -1.1425349393231758 loss: 0.35222033624114524\n",
            "Round: 1324 Weight: [2.33900835 1.15264074] Bias: -1.1425572725131115 loss: 0.3522202877912528\n",
            "Round: 1325 Weight: [2.3390668  1.15267047] Bias: -1.1425795403096237 loss: 0.3522202396235261\n",
            "Round: 1326 Weight: [2.33912507 1.15270012] Bias: -1.1426017429087132 loss: 0.3522201917363056\n",
            "Round: 1327 Weight: [2.33918317 1.15272968] Bias: -1.1426238805057665 loss: 0.3522201441279418\n",
            "Round: 1328 Weight: [2.33924111 1.15275916] Bias: -1.142645953295558 loss: 0.3522200967967953\n",
            "Round: 1329 Weight: [2.33929887 1.15278855] Bias: -1.1426679614722521 loss: 0.3522200497412361\n",
            "Round: 1330 Weight: [2.33935647 1.15281786] Bias: -1.142689905229406 loss: 0.35222000295964434\n",
            "Round: 1331 Weight: [2.3394139  1.15284708] Bias: -1.1427117847599702 loss: 0.3522199564504095\n",
            "Round: 1332 Weight: [2.33947116 1.15287621] Bias: -1.1427336002562922 loss: 0.35221991021193055\n",
            "Round: 1333 Weight: [2.33952826 1.15290526] Bias: -1.1427553519101175 loss: 0.3522198642426165\n",
            "Round: 1334 Weight: [2.33958519 1.15293422] Bias: -1.1427770399125918 loss: 0.3522198185408855\n",
            "Round: 1335 Weight: [2.33964195 1.15296311] Bias: -1.1427986644542636 loss: 0.352219773105165\n",
            "Round: 1336 Weight: [2.33969855 1.1529919 ] Bias: -1.1428202257250852 loss: 0.35221972793389206\n",
            "Round: 1337 Weight: [2.33975498 1.15302061] Bias: -1.1428417239144157 loss: 0.352219683025513\n",
            "Round: 1338 Weight: [2.33981125 1.15304924] Bias: -1.1428631592110226 loss: 0.35221963837848347\n",
            "Round: 1339 Weight: [2.33986735 1.15307779] Bias: -1.1428845318030834 loss: 0.3522195939912681\n",
            "Round: 1340 Weight: [2.33992329 1.15310625] Bias: -1.1429058418781883 loss: 0.3522195498623409\n",
            "Round: 1341 Weight: [2.33997907 1.15313463] Bias: -1.1429270896233419 loss: 0.3522195059901847\n",
            "Round: 1342 Weight: [2.34003468 1.15316293] Bias: -1.142948275224965 loss: 0.35221946237329166\n",
            "Round: 1343 Weight: [2.34009014 1.15319114] Bias: -1.1429693988688965 loss: 0.3522194190101626\n",
            "Round: 1344 Weight: [2.34014543 1.15321928] Bias: -1.142990460740396 loss: 0.35221937589930774\n",
            "Round: 1345 Weight: [2.34020056 1.15324733] Bias: -1.1430114610241449 loss: 0.3522193330392457\n",
            "Round: 1346 Weight: [2.34025553 1.1532753 ] Bias: -1.1430323999042489 loss: 0.3522192904285039\n",
            "Round: 1347 Weight: [2.34031034 1.15330319] Bias: -1.14305327756424 loss: 0.35221924806561905\n",
            "Round: 1348 Weight: [2.34036499 1.15333099] Bias: -1.1430740941870776 loss: 0.352219205949136\n",
            "Round: 1349 Weight: [2.34041948 1.15335872] Bias: -1.1430948499551516 loss: 0.35221916407760856\n",
            "Round: 1350 Weight: [2.34047382 1.15338636] Bias: -1.1431155450502837 loss: 0.35221912244959913\n",
            "Round: 1351 Weight: [2.34052799 1.15341393] Bias: -1.143136179653729 loss: 0.3522190810636785\n",
            "Round: 1352 Weight: [2.34058201 1.15344141] Bias: -1.1431567539461784 loss: 0.35221903991842607\n",
            "Round: 1353 Weight: [2.34063587 1.15346882] Bias: -1.1431772681077605 loss: 0.35221899901242965\n",
            "Round: 1354 Weight: [2.34068957 1.15349614] Bias: -1.1431977223180432 loss: 0.3522189583442854\n",
            "Round: 1355 Weight: [2.34074312 1.15352339] Bias: -1.1432181167560356 loss: 0.35221891791259813\n",
            "Round: 1356 Weight: [2.34079651 1.15355055] Bias: -1.1432384516001899 loss: 0.3522188777159804\n",
            "Round: 1357 Weight: [2.34084975 1.15357764] Bias: -1.1432587270284038 loss: 0.3522188377530537\n",
            "Round: 1358 Weight: [2.34090283 1.15360465] Bias: -1.1432789432180213 loss: 0.352218798022447\n",
            "Round: 1359 Weight: [2.34095575 1.15363158] Bias: -1.1432991003458355 loss: 0.3522187585227978\n",
            "Round: 1360 Weight: [2.34100853 1.15365843] Bias: -1.14331919858809 loss: 0.3522187192527519\n",
            "Round: 1361 Weight: [2.34106114 1.1536852 ] Bias: -1.1433392381204808 loss: 0.3522186802109627\n",
            "Round: 1362 Weight: [2.34111361 1.1537119 ] Bias: -1.1433592191181583 loss: 0.3522186413960916\n",
            "Round: 1363 Weight: [2.34116592 1.15373852] Bias: -1.1433791417557286 loss: 0.35221860280680856\n",
            "Round: 1364 Weight: [2.34121808 1.15376506] Bias: -1.143399006207256 loss: 0.3522185644417907\n",
            "Round: 1365 Weight: [2.34127009 1.15379152] Bias: -1.1434188126462645 loss: 0.3522185262997236\n",
            "Round: 1366 Weight: [2.34132195 1.15381791] Bias: -1.1434385612457394 loss: 0.3522184883793001\n",
            "Round: 1367 Weight: [2.34137366 1.15384422] Bias: -1.1434582521781294 loss: 0.3522184506792212\n",
            "Round: 1368 Weight: [2.34142522 1.15387045] Bias: -1.143477885615348 loss: 0.35221841319819536\n",
            "Round: 1369 Weight: [2.34147662 1.15389661] Bias: -1.143497461728776 loss: 0.35221837593493893\n",
            "Round: 1370 Weight: [2.34152788 1.15392269] Bias: -1.1435169806892627 loss: 0.3522183388881757\n",
            "Round: 1371 Weight: [2.34157899 1.1539487 ] Bias: -1.1435364426671275 loss: 0.3522183020566372\n",
            "Round: 1372 Weight: [2.34162995 1.15397463] Bias: -1.1435558478321624 loss: 0.35221826543906243\n",
            "Round: 1373 Weight: [2.34168076 1.15400048] Bias: -1.1435751963536331 loss: 0.3522182290341975\n",
            "Round: 1374 Weight: [2.34173142 1.15402626] Bias: -1.1435944884002809 loss: 0.3522181928407967\n",
            "Round: 1375 Weight: [2.34178194 1.15405196] Bias: -1.1436137241403246 loss: 0.352218156857621\n",
            "Round: 1376 Weight: [2.34183231 1.15407759] Bias: -1.143632903741462 loss: 0.35221812108343925\n",
            "Round: 1377 Weight: [2.34188253 1.15410315] Bias: -1.1436520273708721 loss: 0.35221808551702716\n",
            "Round: 1378 Weight: [2.34193261 1.15412863] Bias: -1.1436710951952163 loss: 0.35221805015716806\n",
            "Round: 1379 Weight: [2.34198254 1.15415404] Bias: -1.14369010738064 loss: 0.3522180150026523\n",
            "Round: 1380 Weight: [2.34203233 1.15417937] Bias: -1.1437090640927752 loss: 0.3522179800522774\n",
            "Round: 1381 Weight: [2.34208197 1.15420463] Bias: -1.1437279654967412 loss: 0.35221794530484807\n",
            "Round: 1382 Weight: [2.34213146 1.15422982] Bias: -1.1437468117571468 loss: 0.35221791075917613\n",
            "Round: 1383 Weight: [2.34218082 1.15425493] Bias: -1.143765603038092 loss: 0.35221787641408026\n",
            "Round: 1384 Weight: [2.34223003 1.15427997] Bias: -1.1437843395031697 loss: 0.3522178422683865\n",
            "Round: 1385 Weight: [2.3422791  1.15430494] Bias: -1.1438030213154669 loss: 0.35221780832092736\n",
            "Round: 1386 Weight: [2.34232802 1.15432983] Bias: -1.1438216486375672 loss: 0.3522177745705429\n",
            "Round: 1387 Weight: [2.3423768  1.15435465] Bias: -1.1438402216315515 loss: 0.3522177410160793\n",
            "Round: 1388 Weight: [2.34242544 1.1543794 ] Bias: -1.1438587404590008 loss: 0.35221770765639016\n",
            "Round: 1389 Weight: [2.34247394 1.15440408] Bias: -1.1438772052809967 loss: 0.35221767449033564\n",
            "Round: 1390 Weight: [2.3425223  1.15442869] Bias: -1.1438956162581237 loss: 0.3522176415167827\n",
            "Round: 1391 Weight: [2.34257052 1.15445322] Bias: -1.1439139735504709 loss: 0.3522176087346049\n",
            "Round: 1392 Weight: [2.3426186  1.15447769] Bias: -1.1439322773176333 loss: 0.3522175761426827\n",
            "Round: 1393 Weight: [2.34266653 1.15450208] Bias: -1.1439505277187136 loss: 0.35221754373990277\n",
            "Round: 1394 Weight: [2.34271433 1.1545264 ] Bias: -1.1439687249123238 loss: 0.35221751152515895\n",
            "Round: 1395 Weight: [2.34276199 1.15455066] Bias: -1.1439868690565869 loss: 0.35221747949735116\n",
            "Round: 1396 Weight: [2.34280951 1.15457484] Bias: -1.1440049603091382 loss: 0.3522174476553861\n",
            "Round: 1397 Weight: [2.3428569  1.15459895] Bias: -1.1440229988271275 loss: 0.35221741599817685\n",
            "Round: 1398 Weight: [2.34290414 1.15462299] Bias: -1.14404098476722 loss: 0.35221738452464274\n",
            "Round: 1399 Weight: [2.34295125 1.15464696] Bias: -1.1440589182855982 loss: 0.35221735323370973\n",
            "Round: 1400 Weight: [2.34299822 1.15467086] Bias: -1.1440767995379642 loss: 0.35221732212431006\n",
            "Round: 1401 Weight: [2.34304506 1.1546947 ] Bias: -1.1440946286795397 loss: 0.3522172911953824\n",
            "Round: 1402 Weight: [2.34309176 1.15471846] Bias: -1.144112405865069 loss: 0.3522172604458715\n",
            "Round: 1403 Weight: [2.34313832 1.15474215] Bias: -1.1441301312488197 loss: 0.3522172298747284\n",
            "Round: 1404 Weight: [2.34318475 1.15476578] Bias: -1.1441478049845852 loss: 0.3522171994809104\n",
            "Round: 1405 Weight: [2.34323104 1.15478934] Bias: -1.1441654272256851 loss: 0.35221716926338115\n",
            "Round: 1406 Weight: [2.3432772  1.15481282] Bias: -1.1441829981249678 loss: 0.3522171392211098\n",
            "Round: 1407 Weight: [2.34332323 1.15483624] Bias: -1.1442005178348111 loss: 0.35221710935307243\n",
            "Round: 1408 Weight: [2.34336912 1.1548596 ] Bias: -1.1442179865071245 loss: 0.3522170796582506\n",
            "Round: 1409 Weight: [2.34341488 1.15488288] Bias: -1.1442354042933502 loss: 0.35221705013563204\n",
            "Round: 1410 Weight: [2.34346051 1.1549061 ] Bias: -1.1442527713444652 loss: 0.3522170207842105\n",
            "Round: 1411 Weight: [2.343506   1.15492925] Bias: -1.1442700878109826 loss: 0.35221699160298564\n",
            "Round: 1412 Weight: [2.34355136 1.15495233] Bias: -1.1442873538429525 loss: 0.352216962590963\n",
            "Round: 1413 Weight: [2.34359659 1.15497535] Bias: -1.1443045695899647 loss: 0.35221693374715424\n",
            "Round: 1414 Weight: [2.34364169 1.1549983 ] Bias: -1.144321735201149 loss: 0.3522169050705764\n",
            "Round: 1415 Weight: [2.34368666 1.15502118] Bias: -1.1443388508251775 loss: 0.3522168765602527\n",
            "Round: 1416 Weight: [2.34373149 1.15504399] Bias: -1.144355916610266 loss: 0.35221684821521204\n",
            "Round: 1417 Weight: [2.3437762  1.15506674] Bias: -1.144372932704175 loss: 0.35221682003448895\n",
            "Round: 1418 Weight: [2.34382078 1.15508943] Bias: -1.1443898992542116 loss: 0.35221679201712375\n",
            "Round: 1419 Weight: [2.34386522 1.15511205] Bias: -1.1444068164072314 loss: 0.3522167641621625\n",
            "Round: 1420 Weight: [2.34390954 1.1551346 ] Bias: -1.144423684309639 loss: 0.3522167364686568\n",
            "Round: 1421 Weight: [2.34395373 1.15515709] Bias: -1.1444405031073899 loss: 0.35221670893566376\n",
            "Round: 1422 Weight: [2.3439978  1.15517951] Bias: -1.1444572729459925 loss: 0.35221668156224634\n",
            "Round: 1423 Weight: [2.34404173 1.15520186] Bias: -1.1444739939705089 loss: 0.3522166543474727\n",
            "Round: 1424 Weight: [2.34408554 1.15522416] Bias: -1.144490666325556 loss: 0.3522166272904166\n",
            "Round: 1425 Weight: [2.34412922 1.15524638] Bias: -1.1445072901553084 loss: 0.35221660039015745\n",
            "Round: 1426 Weight: [2.34417277 1.15526855] Bias: -1.1445238656034984 loss: 0.3522165736457799\n",
            "Round: 1427 Weight: [2.3442162  1.15529065] Bias: -1.144540392813418 loss: 0.35221654705637406\n",
            "Round: 1428 Weight: [2.3442595  1.15531268] Bias: -1.1445568719279204 loss: 0.35221652062103537\n",
            "Round: 1429 Weight: [2.34430267 1.15533465] Bias: -1.1445733030894216 loss: 0.3522164943388647\n",
            "Round: 1430 Weight: [2.34434572 1.15535656] Bias: -1.144589686439901 loss: 0.3522164682089682\n",
            "Round: 1431 Weight: [2.34438865 1.1553784 ] Bias: -1.1446060221209038 loss: 0.3522164422304571\n",
            "Round: 1432 Weight: [2.34443145 1.15540018] Bias: -1.144622310273542 loss: 0.3522164164024482\n",
            "Round: 1433 Weight: [2.34447412 1.1554219 ] Bias: -1.1446385510384955 loss: 0.35221639072406313\n",
            "Round: 1434 Weight: [2.34451668 1.15544355] Bias: -1.1446547445560142 loss: 0.35221636519442917\n",
            "Round: 1435 Weight: [2.34455911 1.15546514] Bias: -1.144670890965919 loss: 0.35221633981267847\n",
            "Round: 1436 Weight: [2.34460141 1.15548667] Bias: -1.1446869904076025 loss: 0.35221631457794805\n",
            "Round: 1437 Weight: [2.3446436  1.15550814] Bias: -1.144703043020032 loss: 0.35221628948938044\n",
            "Round: 1438 Weight: [2.34468566 1.15552954] Bias: -1.1447190489417496 loss: 0.35221626454612304\n",
            "Round: 1439 Weight: [2.3447276  1.15555089] Bias: -1.1447350083108738 loss: 0.35221623974732835\n",
            "Round: 1440 Weight: [2.34476941 1.15557217] Bias: -1.1447509212651015 loss: 0.3522162150921538\n",
            "Round: 1441 Weight: [2.34481111 1.15559339] Bias: -1.1447667879417083 loss: 0.3522161905797617\n",
            "Round: 1442 Weight: [2.34485269 1.15561454] Bias: -1.1447826084775508 loss: 0.3522161662093195\n",
            "Round: 1443 Weight: [2.34489414 1.15563564] Bias: -1.1447983830090676 loss: 0.3522161419799994\n",
            "Round: 1444 Weight: [2.34493548 1.15565667] Bias: -1.1448141116722805 loss: 0.3522161178909786\n",
            "Round: 1445 Weight: [2.34497669 1.15567765] Bias: -1.1448297946027963 loss: 0.3522160939414389\n",
            "Round: 1446 Weight: [2.34501779 1.15569856] Bias: -1.144845431935808 loss: 0.3522160701305672\n",
            "Round: 1447 Weight: [2.34505876 1.15571941] Bias: -1.1448610238060952 loss: 0.3522160464575552\n",
            "Round: 1448 Weight: [2.34509962 1.1557402 ] Bias: -1.144876570348027 loss: 0.35221602292159904\n",
            "Round: 1449 Weight: [2.34514036 1.15576094] Bias: -1.1448920716955624 loss: 0.3522159995218999\n",
            "Round: 1450 Weight: [2.34518098 1.15578161] Bias: -1.1449075279822518 loss: 0.3522159762576636\n",
            "Round: 1451 Weight: [2.34522149 1.15580222] Bias: -1.1449229393412381 loss: 0.35221595312810045\n",
            "Round: 1452 Weight: [2.34526187 1.15582277] Bias: -1.1449383059052585 loss: 0.35221593013242564\n",
            "Round: 1453 Weight: [2.34530214 1.15584327] Bias: -1.1449536278066454 loss: 0.35221590726985885\n",
            "Round: 1454 Weight: [2.34534229 1.1558637 ] Bias: -1.144968905177328 loss: 0.3522158845396245\n",
            "Round: 1455 Weight: [2.34538233 1.15588407] Bias: -1.144984138148833 loss: 0.35221586194095134\n",
            "Round: 1456 Weight: [2.34542225 1.15590439] Bias: -1.1449993268522871 loss: 0.35221583947307294\n",
            "Round: 1457 Weight: [2.34546205 1.15592464] Bias: -1.145014471418417 loss: 0.3522158171352271\n",
            "Round: 1458 Weight: [2.34550174 1.15594484] Bias: -1.1450295719775512 loss: 0.3522157949266563\n",
            "Round: 1459 Weight: [2.34554132 1.15596498] Bias: -1.1450446286596216 loss: 0.3522157728466074\n",
            "Round: 1460 Weight: [2.34558078 1.15598506] Bias: -1.1450596415941645 loss: 0.3522157508943317\n",
            "Round: 1461 Weight: [2.34562012 1.15600508] Bias: -1.1450746109103218 loss: 0.35221572906908494\n",
            "Round: 1462 Weight: [2.34565935 1.15602505] Bias: -1.145089536736842 loss: 0.35221570737012714\n",
            "Round: 1463 Weight: [2.34569847 1.15604496] Bias: -1.1451044192020825 loss: 0.3522156857967227\n",
            "Round: 1464 Weight: [2.34573748 1.15606481] Bias: -1.1451192584340093 loss: 0.35221566434814056\n",
            "Round: 1465 Weight: [2.34577637 1.1560846 ] Bias: -1.1451340545601998 loss: 0.3522156430236536\n",
            "Round: 1466 Weight: [2.34581515 1.15610433] Bias: -1.145148807707843 loss: 0.35221562182253935\n",
            "Round: 1467 Weight: [2.34585381 1.15612401] Bias: -1.1451635180037416 loss: 0.35221560074407915\n",
            "Round: 1468 Weight: [2.34589237 1.15614363] Bias: -1.145178185574312 loss: 0.352215579787559\n",
            "Round: 1469 Weight: [2.34593081 1.15616319] Bias: -1.1451928105455869 loss: 0.35221555895226886\n",
            "Round: 1470 Weight: [2.34596914 1.1561827 ] Bias: -1.1452073930432158 loss: 0.3522155382375029\n",
            "Round: 1471 Weight: [2.34600736 1.15620215] Bias: -1.1452219331924665 loss: 0.35221551764255943\n",
            "Round: 1472 Weight: [2.34604547 1.15622155] Bias: -1.1452364311182257 loss: 0.35221549716674094\n",
            "Round: 1473 Weight: [2.34608347 1.15624088] Bias: -1.1452508869450013 loss: 0.35221547680935406\n",
            "Round: 1474 Weight: [2.34612136 1.15626017] Bias: -1.1452653007969227 loss: 0.3522154565697092\n",
            "Round: 1475 Weight: [2.34615914 1.15627939] Bias: -1.1452796727977423 loss: 0.35221543644712133\n",
            "Round: 1476 Weight: [2.34619681 1.15629856] Bias: -1.1452940030708372 loss: 0.35221541644090887\n",
            "Round: 1477 Weight: [2.34623437 1.15631768] Bias: -1.1453082917392094 loss: 0.35221539655039474\n",
            "Round: 1478 Weight: [2.34627183 1.15633674] Bias: -1.145322538925488 loss: 0.35221537677490555\n",
            "Round: 1479 Weight: [2.34630917 1.15635574] Bias: -1.1453367447519294 loss: 0.35221535711377183\n",
            "Round: 1480 Weight: [2.34634641 1.15637469] Bias: -1.1453509093404195 loss: 0.35221533756632845\n",
            "Round: 1481 Weight: [2.34638353 1.15639359] Bias: -1.1453650328124745 loss: 0.3522153181319136\n",
            "Round: 1482 Weight: [2.34642056 1.15641243] Bias: -1.1453791152892416 loss: 0.3522152988098697\n",
            "Round: 1483 Weight: [2.34645747 1.15643121] Bias: -1.1453931568915012 loss: 0.3522152795995431\n",
            "Round: 1484 Weight: [2.34649428 1.15644995] Bias: -1.145407157739667 loss: 0.35221526050028373\n",
            "Round: 1485 Weight: [2.34653098 1.15646862] Bias: -1.1454211179537874 loss: 0.3522152415114456\n",
            "Round: 1486 Weight: [2.34656757 1.15648725] Bias: -1.1454350376535476 loss: 0.3522152226323864\n",
            "Round: 1487 Weight: [2.34660406 1.15650582] Bias: -1.1454489169582696 loss: 0.3522152038624674\n",
            "Round: 1488 Weight: [2.34664044 1.15652433] Bias: -1.145462755986914 loss: 0.35221518520105394\n",
            "Round: 1489 Weight: [2.34667672 1.15654279] Bias: -1.1454765548580808 loss: 0.35221516664751484\n",
            "Round: 1490 Weight: [2.34671289 1.1565612 ] Bias: -1.1454903136900112 loss: 0.3522151482012229\n",
            "Round: 1491 Weight: [2.34674896 1.15657956] Bias: -1.1455040326005876 loss: 0.3522151298615541\n",
            "Round: 1492 Weight: [2.34678492 1.15659786] Bias: -1.145517711707336 loss: 0.35221511162788877\n",
            "Round: 1493 Weight: [2.34682078 1.15661611] Bias: -1.1455313511274265 loss: 0.35221509349961033\n",
            "Round: 1494 Weight: [2.34685654 1.15663431] Bias: -1.1455449509776743 loss: 0.352215075476106\n",
            "Round: 1495 Weight: [2.34689219 1.15665245] Bias: -1.1455585113745408 loss: 0.35221505755676663\n",
            "Round: 1496 Weight: [2.34692774 1.15667054] Bias: -1.1455720324341354 loss: 0.3522150397409865\n",
            "Round: 1497 Weight: [2.34696318 1.15668858] Bias: -1.1455855142722162 loss: 0.3522150220281638\n",
            "Round: 1498 Weight: [2.34699853 1.15670657] Bias: -1.1455989570041907 loss: 0.3522150044176998\n",
            "Round: 1499 Weight: [2.34703377 1.1567245 ] Bias: -1.1456123607451176 loss: 0.35221498690899944\n",
            "Round: 1500 Weight: [2.34706891 1.15674239] Bias: -1.1456257256097075 loss: 0.35221496950147135\n",
            "Round: 1501 Weight: [2.34710395 1.15676022] Bias: -1.1456390517123245 loss: 0.3522149521945274\n",
            "Round: 1502 Weight: [2.34713888 1.156778  ] Bias: -1.1456523391669862 loss: 0.35221493498758294\n",
            "Round: 1503 Weight: [2.34717372 1.15679573] Bias: -1.145665588087366 loss: 0.35221491788005677\n",
            "Round: 1504 Weight: [2.34720845 1.1568134 ] Bias: -1.1456787985867942 loss: 0.35221490087137125\n",
            "Round: 1505 Weight: [2.34724309 1.15683103] Bias: -1.1456919707782576 loss: 0.3522148839609518\n",
            "Round: 1506 Weight: [2.34727762 1.1568486 ] Bias: -1.1457051047744022 loss: 0.35221486714822753\n",
            "Round: 1507 Weight: [2.34731205 1.15686613] Bias: -1.145718200687534 loss: 0.35221485043263073\n",
            "Round: 1508 Weight: [2.34734639 1.1568836 ] Bias: -1.1457312586296189 loss: 0.352214833813597\n",
            "Round: 1509 Weight: [2.34738062 1.15690103] Bias: -1.1457442787122853 loss: 0.3522148172905654\n",
            "Round: 1510 Weight: [2.34741476 1.1569184 ] Bias: -1.1457572610468247 loss: 0.352214800862978\n",
            "Round: 1511 Weight: [2.3474488  1.15693572] Bias: -1.145770205744192 loss: 0.35221478453028054\n",
            "Round: 1512 Weight: [2.34748274 1.15695299] Bias: -1.1457831129150076 loss: 0.3522147682919216\n",
            "Round: 1513 Weight: [2.34751658 1.15697022] Bias: -1.1457959826695576 loss: 0.35221475214735326\n",
            "Round: 1514 Weight: [2.34755032 1.15698739] Bias: -1.1458088151177959 loss: 0.3522147360960307\n",
            "Round: 1515 Weight: [2.34758397 1.15700451] Bias: -1.145821610369344 loss: 0.3522147201374123\n",
            "Round: 1516 Weight: [2.34761751 1.15702159] Bias: -1.145834368533493 loss: 0.3522147042709596\n",
            "Round: 1517 Weight: [2.34765097 1.15703861] Bias: -1.1458470897192048 loss: 0.3522146884961374\n",
            "Round: 1518 Weight: [2.34768432 1.15705559] Bias: -1.1458597740351117 loss: 0.35221467281241337\n",
            "Round: 1519 Weight: [2.34771758 1.15707251] Bias: -1.145872421589519 loss: 0.3522146572192586\n",
            "Round: 1520 Weight: [2.34775074 1.15708939] Bias: -1.1458850324904057 loss: 0.35221464171614725\n",
            "Round: 1521 Weight: [2.34778381 1.15710622] Bias: -1.1458976068454247 loss: 0.35221462630255634\n",
            "Round: 1522 Weight: [2.34781678 1.157123  ] Bias: -1.1459101447619047 loss: 0.35221461097796614\n",
            "Round: 1523 Weight: [2.34784965 1.15713973] Bias: -1.145922646346851 loss: 0.35221459574185987\n",
            "Round: 1524 Weight: [2.34788243 1.15715641] Bias: -1.1459351117069465 loss: 0.35221458059372374\n",
            "Round: 1525 Weight: [2.34791512 1.15717305] Bias: -1.1459475409485527 loss: 0.35221456553304714\n",
            "Round: 1526 Weight: [2.34794771 1.15718963] Bias: -1.1459599341777105 loss: 0.3522145505593224\n",
            "Round: 1527 Weight: [2.34798021 1.15720617] Bias: -1.1459722915001413 loss: 0.35221453567204447\n",
            "Round: 1528 Weight: [2.34801261 1.15722266] Bias: -1.1459846130212488 loss: 0.3522145208707118\n",
            "Round: 1529 Weight: [2.34804492 1.15723911] Bias: -1.1459968988461187 loss: 0.3522145061548254\n",
            "Round: 1530 Weight: [2.34807713 1.1572555 ] Bias: -1.1460091490795206 loss: 0.3522144915238895\n",
            "Round: 1531 Weight: [2.34810926 1.15727185] Bias: -1.1460213638259087 loss: 0.3522144769774109\n",
            "Round: 1532 Weight: [2.34814129 1.15728815] Bias: -1.1460335431894226 loss: 0.35221446251489946\n",
            "Round: 1533 Weight: [2.34817322 1.15730441] Bias: -1.1460456872738891 loss: 0.35221444813586783\n",
            "Round: 1534 Weight: [2.34820507 1.15732061] Bias: -1.146057796182822 loss: 0.3522144338398317\n",
            "Round: 1535 Weight: [2.34823682 1.15733677] Bias: -1.1460698700194238 loss: 0.3522144196263094\n",
            "Round: 1536 Weight: [2.34826848 1.15735289] Bias: -1.146081908886587 loss: 0.352214405494822\n",
            "Round: 1537 Weight: [2.34830005 1.15736895] Bias: -1.146093912886894 loss: 0.3522143914448938\n",
            "Round: 1538 Weight: [2.34833153 1.15738497] Bias: -1.1461058821226193 loss: 0.3522143774760514\n",
            "Round: 1539 Weight: [2.34836292 1.15740095] Bias: -1.1461178166957298 loss: 0.3522143635878242\n",
            "Round: 1540 Weight: [2.34839422 1.15741688] Bias: -1.1461297167078854 loss: 0.35221434977974486\n",
            "Round: 1541 Weight: [2.34842542 1.15743276] Bias: -1.146141582260441 loss: 0.3522143360513482\n",
            "Round: 1542 Weight: [2.34845654 1.1574486 ] Bias: -1.1461534134544467 loss: 0.352214322402172\n",
            "Round: 1543 Weight: [2.34848757 1.15746439] Bias: -1.1461652103906488 loss: 0.35221430883175675\n",
            "Round: 1544 Weight: [2.3485185  1.15748013] Bias: -1.146176973169491 loss: 0.35221429533964566\n",
            "Round: 1545 Weight: [2.34854935 1.15749583] Bias: -1.1461887018911154 loss: 0.3522142819253845\n",
            "Round: 1546 Weight: [2.34858011 1.15751149] Bias: -1.1462003966553633 loss: 0.3522142685885218\n",
            "Round: 1547 Weight: [2.34861078 1.1575271 ] Bias: -1.1462120575617758 loss: 0.3522142553286085\n",
            "Round: 1548 Weight: [2.34864136 1.15754266] Bias: -1.1462236847095955 loss: 0.3522142421451984\n",
            "Round: 1549 Weight: [2.34867185 1.15755818] Bias: -1.1462352781977667 loss: 0.352214229037848\n",
            "Round: 1550 Weight: [2.34870226 1.15757365] Bias: -1.146246838124937 loss: 0.35221421600611613\n",
            "Round: 1551 Weight: [2.34873257 1.15758908] Bias: -1.146258364589458 loss: 0.3522142030495643\n",
            "Round: 1552 Weight: [2.3487628  1.15760447] Bias: -1.1462698576893853 loss: 0.3522141901677566\n",
            "Round: 1553 Weight: [2.34879294 1.15761981] Bias: -1.146281317522481 loss: 0.35221417736025956\n",
            "Round: 1554 Weight: [2.348823   1.15763511] Bias: -1.146292744186214 loss: 0.3522141646266425\n",
            "Round: 1555 Weight: [2.34885297 1.15765036] Bias: -1.1463041377777603 loss: 0.35221415196647704\n",
            "Round: 1556 Weight: [2.34888285 1.15766557] Bias: -1.1463154983940047 loss: 0.35221413937933727\n",
            "Round: 1557 Weight: [2.34891264 1.15768073] Bias: -1.1463268261315414 loss: 0.3522141268647999\n",
            "Round: 1558 Weight: [2.34894235 1.15769585] Bias: -1.1463381210866745 loss: 0.3522141144224442\n",
            "Round: 1559 Weight: [2.34897198 1.15771093] Bias: -1.1463493833554204 loss: 0.35221410205185155\n",
            "Round: 1560 Weight: [2.34900151 1.15772596] Bias: -1.1463606130335064 loss: 0.35221408975260604\n",
            "Round: 1561 Weight: [2.34903097 1.15774095] Bias: -1.1463718102163738 loss: 0.3522140775242942\n",
            "Round: 1562 Weight: [2.34906034 1.1577559 ] Bias: -1.1463829749991774 loss: 0.3522140653665048\n",
            "Round: 1563 Weight: [2.34908962 1.1577708 ] Bias: -1.146394107476787 loss: 0.35221405327882926\n",
            "Round: 1564 Weight: [2.34911882 1.15778566] Bias: -1.146405207743788 loss: 0.35221404126086114\n",
            "Round: 1565 Weight: [2.34914793 1.15780048] Bias: -1.1464162758944827 loss: 0.35221402931219664\n",
            "Round: 1566 Weight: [2.34917696 1.15781526] Bias: -1.1464273120228907 loss: 0.3522140174324338\n",
            "Round: 1567 Weight: [2.34920591 1.15782999] Bias: -1.14643831622275 loss: 0.35221400562117366\n",
            "Round: 1568 Weight: [2.34923477 1.15784468] Bias: -1.146449288587518 loss: 0.35221399387801927\n",
            "Round: 1569 Weight: [2.34926355 1.15785932] Bias: -1.1464602292103718 loss: 0.35221398220257605\n",
            "Round: 1570 Weight: [2.34929224 1.15787393] Bias: -1.1464711381842103 loss: 0.35221397059445136\n",
            "Round: 1571 Weight: [2.34932086 1.15788849] Bias: -1.146482015601654 loss: 0.35221395905325553\n",
            "Round: 1572 Weight: [2.34934939 1.15790301] Bias: -1.1464928615550458 loss: 0.35221394757860075\n",
            "Round: 1573 Weight: [2.34937784 1.15791749] Bias: -1.1465036761364527 loss: 0.3522139361701014\n",
            "Round: 1574 Weight: [2.3494062  1.15793193] Bias: -1.1465144594376657 loss: 0.3522139248273743\n",
            "Round: 1575 Weight: [2.34943449 1.15794633] Bias: -1.1465252115502018 loss: 0.35221391355003856\n",
            "Round: 1576 Weight: [2.34946269 1.15796068] Bias: -1.146535932565304 loss: 0.3522139023377153\n",
            "Round: 1577 Weight: [2.34949081 1.15797499] Bias: -1.1465466225739418 loss: 0.35221389119002805\n",
            "Round: 1578 Weight: [2.34951885 1.15798926] Bias: -1.1465572816668135 loss: 0.3522138801066022\n",
            "Round: 1579 Weight: [2.34954681 1.15800349] Bias: -1.1465679099343455 loss: 0.3522138690870658\n",
            "Round: 1580 Weight: [2.34957469 1.15801768] Bias: -1.1465785074666943 loss: 0.3522138581310488\n",
            "Round: 1581 Weight: [2.34960249 1.15803183] Bias: -1.1465890743537466 loss: 0.3522138472381833\n",
            "Round: 1582 Weight: [2.34963021 1.15804594] Bias: -1.1465996106851204 loss: 0.3522138364081036\n",
            "Round: 1583 Weight: [2.34965784 1.15806001] Bias: -1.1466101165501659 loss: 0.3522138256404461\n",
            "Round: 1584 Weight: [2.3496854  1.15807403] Bias: -1.1466205920379662 loss: 0.35221381493484927\n",
            "Round: 1585 Weight: [2.34971288 1.15808802] Bias: -1.1466310372373383 loss: 0.3522138042909539\n",
            "Round: 1586 Weight: [2.34974028 1.15810196] Bias: -1.1466414522368336 loss: 0.35221379370840267\n",
            "Round: 1587 Weight: [2.3497676  1.15811587] Bias: -1.1466518371247392 loss: 0.35221378318684043\n",
            "Round: 1588 Weight: [2.34979484 1.15812973] Bias: -1.1466621919890785 loss: 0.35221377272591403\n",
            "Round: 1589 Weight: [2.34982201 1.15814356] Bias: -1.1466725169176117 loss: 0.3522137623252725\n",
            "Round: 1590 Weight: [2.34984909 1.15815734] Bias: -1.1466828119978374 loss: 0.3522137519845667\n",
            "Round: 1591 Weight: [2.3498761  1.15817109] Bias: -1.1466930773169923 loss: 0.3522137417034499\n",
            "Round: 1592 Weight: [2.34990303 1.15818479] Bias: -1.1467033129620534 loss: 0.3522137314815769\n",
            "Round: 1593 Weight: [2.34992988 1.15819846] Bias: -1.1467135190197373 loss: 0.35221372131860484\n",
            "Round: 1594 Weight: [2.34995665 1.15821209] Bias: -1.1467236955765021 loss: 0.3522137112141928\n",
            "Round: 1595 Weight: [2.34998335 1.15822568] Bias: -1.146733842718548 loss: 0.35221370116800194\n",
            "Round: 1596 Weight: [2.35000997 1.15823922] Bias: -1.146743960531818 loss: 0.35221369117969514\n",
            "Round: 1597 Weight: [2.35003651 1.15825273] Bias: -1.1467540491019983 loss: 0.3522136812489375\n",
            "Round: 1598 Weight: [2.35006297 1.1582662 ] Bias: -1.1467641085145197 loss: 0.3522136713753959\n",
            "Round: 1599 Weight: [2.35008936 1.15827963] Bias: -1.146774138854558 loss: 0.35221366155873907\n",
            "Round: 1600 Weight: [2.35011568 1.15829303] Bias: -1.1467841402070351 loss: 0.3522136517986381\n",
            "Round: 1601 Weight: [2.35014191 1.15830638] Bias: -1.1467941126566197 loss: 0.3522136420947657\n",
            "Round: 1602 Weight: [2.35016808 1.1583197 ] Bias: -1.1468040562877277 loss: 0.3522136324467963\n",
            "Round: 1603 Weight: [2.35019416 1.15833297] Bias: -1.1468139711845238 loss: 0.35221362285440655\n",
            "Round: 1604 Weight: [2.35022017 1.15834621] Bias: -1.1468238574309213 loss: 0.3522136133172749\n",
            "Round: 1605 Weight: [2.35024611 1.15835941] Bias: -1.1468337151105834 loss: 0.3522136038350815\n",
            "Round: 1606 Weight: [2.35027197 1.15837258] Bias: -1.1468435443069243 loss: 0.3522135944075087\n",
            "Round: 1607 Weight: [2.35029776 1.1583857 ] Bias: -1.1468533451031093 loss: 0.35221358503424016\n",
            "Round: 1608 Weight: [2.35032347 1.15839879] Bias: -1.146863117582056 loss: 0.3522135757149622\n",
            "Round: 1609 Weight: [2.35034911 1.15841184] Bias: -1.146872861826435 loss: 0.3522135664493621\n",
            "Round: 1610 Weight: [2.35037467 1.15842485] Bias: -1.1468825779186702 loss: 0.35221355723712944\n",
            "Round: 1611 Weight: [2.35040016 1.15843782] Bias: -1.1468922659409404 loss: 0.35221354807795563\n",
            "Round: 1612 Weight: [2.35042558 1.15845076] Bias: -1.1469019259751796 loss: 0.3522135389715337\n",
            "Round: 1613 Weight: [2.35045092 1.15846366] Bias: -1.1469115581030778 loss: 0.3522135299175584\n",
            "Round: 1614 Weight: [2.3504762  1.15847652] Bias: -1.1469211624060813 loss: 0.3522135209157266\n",
            "Round: 1615 Weight: [2.35050139 1.15848935] Bias: -1.1469307389653947 loss: 0.35221351196573664\n",
            "Round: 1616 Weight: [2.35052652 1.15850214] Bias: -1.1469402878619799 loss: 0.3522135030672886\n",
            "Round: 1617 Weight: [2.35055157 1.15851489] Bias: -1.1469498091765584 loss: 0.35221349422008447\n",
            "Round: 1618 Weight: [2.35057655 1.1585276 ] Bias: -1.1469593029896117 loss: 0.35221348542382797\n",
            "Round: 1619 Weight: [2.35060146 1.15854028] Bias: -1.146968769381381 loss: 0.3522134766782244\n",
            "Round: 1620 Weight: [2.3506263  1.15855292] Bias: -1.1469782084318692 loss: 0.3522134679829809\n",
            "Round: 1621 Weight: [2.35065106 1.15856553] Bias: -1.1469876202208409 loss: 0.3522134593378062\n",
            "Round: 1622 Weight: [2.35067576 1.15857809] Bias: -1.146997004827824 loss: 0.3522134507424108\n",
            "Round: 1623 Weight: [2.35070038 1.15859063] Bias: -1.147006362332109 loss: 0.35221344219650697\n",
            "Round: 1624 Weight: [2.35072493 1.15860312] Bias: -1.147015692812751 loss: 0.35221343369980845\n",
            "Round: 1625 Weight: [2.35074941 1.15861558] Bias: -1.1470249963485701 loss: 0.3522134252520308\n",
            "Round: 1626 Weight: [2.35077382 1.15862801] Bias: -1.1470342730181518 loss: 0.3522134168528913\n",
            "Round: 1627 Weight: [2.35079816 1.1586404 ] Bias: -1.1470435228998477 loss: 0.3522134085021086\n",
            "Round: 1628 Weight: [2.35082243 1.15865275] Bias: -1.1470527460717768 loss: 0.35221340019940317\n",
            "Round: 1629 Weight: [2.35084663 1.15866507] Bias: -1.1470619426118258 loss: 0.3522133919444972\n",
            "Round: 1630 Weight: [2.35087076 1.15867735] Bias: -1.14707111259765 loss: 0.3522133837371143\n",
            "Round: 1631 Weight: [2.35089482 1.15868959] Bias: -1.1470802561066737 loss: 0.35221337557697985\n",
            "Round: 1632 Weight: [2.35091881 1.15870181] Bias: -1.1470893732160914 loss: 0.3522133674638206\n",
            "Round: 1633 Weight: [2.35094274 1.15871398] Bias: -1.1470984640028676 loss: 0.3522133593973651\n",
            "Round: 1634 Weight: [2.35096659 1.15872612] Bias: -1.1471075285437389 loss: 0.3522133513773435\n",
            "Round: 1635 Weight: [2.35099037 1.15873823] Bias: -1.1471165669152132 loss: 0.35221334340348737\n",
            "Round: 1636 Weight: [2.35101409 1.1587503 ] Bias: -1.1471255791935717 loss: 0.3522133354755299\n",
            "Round: 1637 Weight: [2.35103774 1.15876234] Bias: -1.1471345654548688 loss: 0.35221332759320584\n",
            "Round: 1638 Weight: [2.35106132 1.15877434] Bias: -1.1471435257749332 loss: 0.3522133197562514\n",
            "Round: 1639 Weight: [2.35108483 1.1587863 ] Bias: -1.147152460229368 loss: 0.35221331196440464\n",
            "Round: 1640 Weight: [2.35110827 1.15879824] Bias: -1.1471613688935522 loss: 0.35221330421740465\n",
            "Round: 1641 Weight: [2.35113165 1.15881013] Bias: -1.147170251842641 loss: 0.3522132965149924\n",
            "Round: 1642 Weight: [2.35115496 1.158822  ] Bias: -1.1471791091515664 loss: 0.3522132888569103\n",
            "Round: 1643 Weight: [2.3511782  1.15883383] Bias: -1.1471879408950378 loss: 0.3522132812429021\n",
            "Round: 1644 Weight: [2.35120137 1.15884562] Bias: -1.1471967471475433 loss: 0.3522132736727132\n",
            "Round: 1645 Weight: [2.35122448 1.15885738] Bias: -1.1472055279833495 loss: 0.35221326614609044\n",
            "Round: 1646 Weight: [2.35124752 1.15886911] Bias: -1.147214283476503 loss: 0.3522132586627822\n",
            "Round: 1647 Weight: [2.3512705  1.15888081] Bias: -1.1472230137008301 loss: 0.352213251222538\n",
            "Round: 1648 Weight: [2.3512934  1.15889247] Bias: -1.147231718729939 loss: 0.35221324382510943\n",
            "Round: 1649 Weight: [2.35131625 1.15890409] Bias: -1.1472403986372188 loss: 0.3522132364702489\n",
            "Round: 1650 Weight: [2.35133902 1.15891569] Bias: -1.1472490534958413 loss: 0.3522132291577104\n",
            "Round: 1651 Weight: [2.35136173 1.15892725] Bias: -1.147257683378761 loss: 0.3522132218872498\n",
            "Round: 1652 Weight: [2.35138438 1.15893877] Bias: -1.1472662883587166 loss: 0.3522132146586238\n",
            "Round: 1653 Weight: [2.35140696 1.15895027] Bias: -1.1472748685082303 loss: 0.3522132074715909\n",
            "Round: 1654 Weight: [2.35142948 1.15896173] Bias: -1.1472834238996101 loss: 0.35221320032591075\n",
            "Round: 1655 Weight: [2.35145193 1.15897315] Bias: -1.147291954604949 loss: 0.3522131932213446\n",
            "Round: 1656 Weight: [2.35147431 1.15898455] Bias: -1.1473004606961266 loss: 0.352213186157655\n",
            "Round: 1657 Weight: [2.35149664 1.15899591] Bias: -1.1473089422448095 loss: 0.35221317913460576\n",
            "Round: 1658 Weight: [2.35151889 1.15900724] Bias: -1.147317399322452 loss: 0.3522131721519623\n",
            "Round: 1659 Weight: [2.35154109 1.15901853] Bias: -1.1473258320002961 loss: 0.3522131652094913\n",
            "Round: 1660 Weight: [2.35156321 1.1590298 ] Bias: -1.1473342403493734 loss: 0.35221315830696065\n",
            "Round: 1661 Weight: [2.35158528 1.15904103] Bias: -1.1473426244405045 loss: 0.35221315144413984\n",
            "Round: 1662 Weight: [2.35160728 1.15905223] Bias: -1.1473509843443006 loss: 0.35221314462079945\n",
            "Round: 1663 Weight: [2.35162922 1.15906339] Bias: -1.1473593201311636 loss: 0.3522131378367117\n",
            "Round: 1664 Weight: [2.3516511  1.15907453] Bias: -1.1473676318712869 loss: 0.3522131310916497\n",
            "Round: 1665 Weight: [2.35167291 1.15908563] Bias: -1.1473759196346558 loss: 0.3522131243853884\n",
            "Round: 1666 Weight: [2.35169466 1.1590967 ] Bias: -1.1473841834910488 loss: 0.3522131177177035\n",
            "Round: 1667 Weight: [2.35171634 1.15910774] Bias: -1.1473924235100372 loss: 0.35221311108837255\n",
            "Round: 1668 Weight: [2.35173797 1.15911875] Bias: -1.147400639760987 loss: 0.3522131044971739\n",
            "Round: 1669 Weight: [2.35175953 1.15912972] Bias: -1.1474088323130585 loss: 0.3522130979438876\n",
            "Round: 1670 Weight: [2.35178103 1.15914067] Bias: -1.147417001235207 loss: 0.35221309142829466\n",
            "Round: 1671 Weight: [2.35180247 1.15915158] Bias: -1.1474251465961842 loss: 0.3522130849501775\n",
            "Round: 1672 Weight: [2.35182385 1.15916246] Bias: -1.147433268464538 loss: 0.35221307850931977\n",
            "Round: 1673 Weight: [2.35184516 1.15917331] Bias: -1.1474413669086139 loss: 0.3522130721055065\n",
            "Round: 1674 Weight: [2.35186641 1.15918413] Bias: -1.1474494419965544 loss: 0.3522130657385239\n",
            "Round: 1675 Weight: [2.35188761 1.15919491] Bias: -1.1474574937963011 loss: 0.3522130594081592\n",
            "Round: 1676 Weight: [2.35190874 1.15920567] Bias: -1.1474655223755945 loss: 0.3522130531142011\n",
            "Round: 1677 Weight: [2.35192981 1.15921639] Bias: -1.1474735278019743 loss: 0.35221304685643967\n",
            "Round: 1678 Weight: [2.35195082 1.15922709] Bias: -1.1474815101427809 loss: 0.3522130406346657\n",
            "Round: 1679 Weight: [2.35197177 1.15923775] Bias: -1.1474894694651552 loss: 0.35221303444867175\n",
            "Round: 1680 Weight: [2.35199266 1.15924838] Bias: -1.1474974058360397 loss: 0.35221302829825124\n",
            "Round: 1681 Weight: [2.35201349 1.15925898] Bias: -1.147505319322179 loss: 0.35221302218319883\n",
            "Round: 1682 Weight: [2.35203425 1.15926956] Bias: -1.1475132099901204 loss: 0.3522130161033105\n",
            "Round: 1683 Weight: [2.35205496 1.1592801 ] Bias: -1.1475210779062144 loss: 0.35221301005838324\n",
            "Round: 1684 Weight: [2.35207561 1.15929061] Bias: -1.1475289231366153 loss: 0.3522130040482155\n",
            "Round: 1685 Weight: [2.3520962  1.15930109] Bias: -1.1475367457472818 loss: 0.3522129980726065\n",
            "Round: 1686 Weight: [2.35211673 1.15931154] Bias: -1.147544545803978 loss: 0.35221299213135693\n",
            "Round: 1687 Weight: [2.35213721 1.15932196] Bias: -1.147552323372273 loss: 0.35221298622426855\n",
            "Round: 1688 Weight: [2.35215762 1.15933235] Bias: -1.147560078517543 loss: 0.35221298035114423\n",
            "Round: 1689 Weight: [2.35217797 1.15934271] Bias: -1.1475678113049705 loss: 0.352212974511788\n",
            "Round: 1690 Weight: [2.35219827 1.15935304] Bias: -1.1475755217995454 loss: 0.3522129687060051\n",
            "Round: 1691 Weight: [2.35221851 1.15936334] Bias: -1.1475832100660657 loss: 0.3522129629336018\n",
            "Round: 1692 Weight: [2.35223868 1.15937361] Bias: -1.1475908761691382 loss: 0.35221295719438567\n",
            "Round: 1693 Weight: [2.3522588  1.15938385] Bias: -1.1475985201731789 loss: 0.35221295148816495\n",
            "Round: 1694 Weight: [2.35227887 1.15939406] Bias: -1.1476061421424129 loss: 0.3522129458147496\n",
            "Round: 1695 Weight: [2.35229887 1.15940425] Bias: -1.1476137421408763 loss: 0.3522129401739502\n",
            "Round: 1696 Weight: [2.35231882 1.1594144 ] Bias: -1.1476213202324161 loss: 0.35221293456557873\n",
            "Round: 1697 Weight: [2.35233871 1.15942452] Bias: -1.1476288764806906 loss: 0.3522129289894481\n",
            "Round: 1698 Weight: [2.35235854 1.15943462] Bias: -1.14763641094917 loss: 0.35221292344537225\n",
            "Round: 1699 Weight: [2.35237832 1.15944469] Bias: -1.1476439237011373 loss: 0.3522129179331665\n",
            "Round: 1700 Weight: [2.35239804 1.15945472] Bias: -1.147651414799689 loss: 0.35221291245264685\n",
            "Round: 1701 Weight: [2.3524177  1.15946473] Bias: -1.1476588843077349 loss: 0.35221290700363067\n",
            "Round: 1702 Weight: [2.3524373  1.15947471] Bias: -1.1476663322879994 loss: 0.35221290158593616\n",
            "Round: 1703 Weight: [2.35245685 1.15948466] Bias: -1.147673758803022 loss: 0.35221289619938273\n",
            "Round: 1704 Weight: [2.35247635 1.15949458] Bias: -1.147681163915157 loss: 0.35221289084379087\n",
            "Round: 1705 Weight: [2.35249578 1.15950448] Bias: -1.1476885476865755 loss: 0.3522128855189819\n",
            "Round: 1706 Weight: [2.35251516 1.15951434] Bias: -1.1476959101792648 loss: 0.3522128802247785\n",
            "Round: 1707 Weight: [2.35253449 1.15952418] Bias: -1.1477032514550294 loss: 0.3522128749610039\n",
            "Round: 1708 Weight: [2.35255376 1.15953399] Bias: -1.1477105715754914 loss: 0.35221286972748284\n",
            "Round: 1709 Weight: [2.35257297 1.15954377] Bias: -1.1477178706020914 loss: 0.3522128645240408\n",
            "Round: 1710 Weight: [2.35259213 1.15955352] Bias: -1.1477251485960887 loss: 0.3522128593505044\n",
            "Round: 1711 Weight: [2.35261123 1.15956324] Bias: -1.1477324056185616 loss: 0.35221285420670123\n",
            "Round: 1712 Weight: [2.35263028 1.15957294] Bias: -1.147739641730409 loss: 0.35221284909245976\n",
            "Round: 1713 Weight: [2.35264928 1.15958261] Bias: -1.14774685699235 loss: 0.35221284400760955\n",
            "Round: 1714 Weight: [2.35266821 1.15959225] Bias: -1.147754051464924 loss: 0.35221283895198124\n",
            "Round: 1715 Weight: [2.3526871  1.15960186] Bias: -1.147761225208493 loss: 0.3522128339254063\n",
            "Round: 1716 Weight: [2.35270593 1.15961144] Bias: -1.1477683782832406 loss: 0.3522128289277173\n",
            "Round: 1717 Weight: [2.35272471 1.159621  ] Bias: -1.147775510749173 loss: 0.35221282395874765\n",
            "Round: 1718 Weight: [2.35274343 1.15963053] Bias: -1.1477826226661194 loss: 0.3522128190183318\n",
            "Round: 1719 Weight: [2.3527621  1.15964003] Bias: -1.1477897140937332 loss: 0.35221281410630517\n",
            "Round: 1720 Weight: [2.35278071 1.15964951] Bias: -1.1477967850914916 loss: 0.35221280922250414\n",
            "Round: 1721 Weight: [2.35279927 1.15965895] Bias: -1.1478038357186968 loss: 0.3522128043667659\n",
            "Round: 1722 Weight: [2.35281778 1.15966838] Bias: -1.1478108660344761 loss: 0.3522127995389288\n",
            "Round: 1723 Weight: [2.35283623 1.15967777] Bias: -1.1478178760977826 loss: 0.352212794738832\n",
            "Round: 1724 Weight: [2.35285463 1.15968714] Bias: -1.1478248659673962 loss: 0.3522127899663156\n",
            "Round: 1725 Weight: [2.35287298 1.15969647] Bias: -1.147831835701923 loss: 0.3522127852212207\n",
            "Round: 1726 Weight: [2.35289128 1.15970579] Bias: -1.147838785359797 loss: 0.35221278050338906\n",
            "Round: 1727 Weight: [2.35290952 1.15971507] Bias: -1.1478457149992802 loss: 0.3522127758126638\n",
            "Round: 1728 Weight: [2.35292771 1.15972433] Bias: -1.1478526246784626 loss: 0.35221277114888855\n",
            "Round: 1729 Weight: [2.35294585 1.15973357] Bias: -1.1478595144552635 loss: 0.35221276651190797\n",
            "Round: 1730 Weight: [2.35296394 1.15974277] Bias: -1.1478663843874315 loss: 0.3522127619015678\n",
            "Round: 1731 Weight: [2.35298197 1.15975195] Bias: -1.1478732345325453 loss: 0.3522127573177144\n",
            "Round: 1732 Weight: [2.35299995 1.1597611 ] Bias: -1.1478800649480143 loss: 0.35221275276019515\n",
            "Round: 1733 Weight: [2.35301788 1.15977023] Bias: -1.1478868756910785 loss: 0.35221274822885834\n",
            "Round: 1734 Weight: [2.35303576 1.15977933] Bias: -1.1478936668188098 loss: 0.3522127437235531\n",
            "Round: 1735 Weight: [2.35305359 1.15978841] Bias: -1.147900438388112 loss: 0.3522127392441294\n",
            "Round: 1736 Weight: [2.35307136 1.15979745] Bias: -1.1479071904557214 loss: 0.35221273479043813\n",
            "Round: 1737 Weight: [2.35308909 1.15980648] Bias: -1.1479139230782076 loss: 0.35221273036233103\n",
            "Round: 1738 Weight: [2.35310676 1.15981547] Bias: -1.1479206363119736 loss: 0.35221272595966063\n",
            "Round: 1739 Weight: [2.35312439 1.15982444] Bias: -1.1479273302132564 loss: 0.3522127215822805\n",
            "Round: 1740 Weight: [2.35314196 1.15983339] Bias: -1.1479340048381277 loss: 0.3522127172300448\n",
            "Round: 1741 Weight: [2.35315948 1.15984231] Bias: -1.1479406602424942 loss: 0.35221271290280887\n",
            "Round: 1742 Weight: [2.35317695 1.1598512 ] Bias: -1.1479472964820983 loss: 0.35221270860042836\n",
            "Round: 1743 Weight: [2.35319437 1.15986007] Bias: -1.1479539136125183 loss: 0.35221270432276036\n",
            "Round: 1744 Weight: [2.35321174 1.15986891] Bias: -1.1479605116891691 loss: 0.3522127000696624\n",
            "Round: 1745 Weight: [2.35322906 1.15987773] Bias: -1.1479670907673027 loss: 0.35221269584099296\n",
            "Round: 1746 Weight: [2.35324634 1.15988652] Bias: -1.1479736509020089 loss: 0.3522126916366113\n",
            "Round: 1747 Weight: [2.35326356 1.15989528] Bias: -1.147980192148215 loss: 0.35221268745637757\n",
            "Round: 1748 Weight: [2.35328073 1.15990403] Bias: -1.147986714560687 loss: 0.3522126833001527\n",
            "Round: 1749 Weight: [2.35329785 1.15991274] Bias: -1.1479932181940304 loss: 0.3522126791677982\n",
            "Round: 1750 Weight: [2.35331493 1.15992143] Bias: -1.1479997031026896 loss: 0.35221267505917675\n",
            "Round: 1751 Weight: [2.35333195 1.1599301 ] Bias: -1.1480061693409493 loss: 0.3522126709741515\n",
            "Round: 1752 Weight: [2.35334893 1.15993874] Bias: -1.1480126169629348 loss: 0.35221266691258696\n",
            "Round: 1753 Weight: [2.35336585 1.15994735] Bias: -1.1480190460226116 loss: 0.3522126628743474\n",
            "Round: 1754 Weight: [2.35338273 1.15995595] Bias: -1.1480254565737877 loss: 0.3522126588592989\n",
            "Round: 1755 Weight: [2.35339956 1.15996451] Bias: -1.1480318486701122 loss: 0.35221265486730785\n",
            "Round: 1756 Weight: [2.35341634 1.15997305] Bias: -1.148038222365077 loss: 0.3522126508982414\n",
            "Round: 1757 Weight: [2.35343307 1.15998157] Bias: -1.1480445777120165 loss: 0.35221264695196747\n",
            "Round: 1758 Weight: [2.35344976 1.15999006] Bias: -1.148050914764109 loss: 0.35221264302835487\n",
            "Round: 1759 Weight: [2.3534664  1.15999853] Bias: -1.148057233574376 loss: 0.3522126391272732\n",
            "Round: 1760 Weight: [2.35348299 1.16000698] Bias: -1.1480635341956835 loss: 0.3522126352485925\n",
            "Round: 1761 Weight: [2.35349953 1.1600154 ] Bias: -1.1480698166807424 loss: 0.35221263139218384\n",
            "Round: 1762 Weight: [2.35351602 1.16002379] Bias: -1.1480760810821087 loss: 0.3522126275579192\n",
            "Round: 1763 Weight: [2.35353247 1.16003216] Bias: -1.148082327452184 loss: 0.35221262374567075\n",
            "Round: 1764 Weight: [2.35354887 1.16004051] Bias: -1.1480885558432163 loss: 0.35221261995531195\n",
            "Round: 1765 Weight: [2.35356522 1.16004884] Bias: -1.1480947663072998 loss: 0.3522126161867166\n",
            "Round: 1766 Weight: [2.35358152 1.16005714] Bias: -1.1481009588963762 loss: 0.3522126124397596\n",
            "Round: 1767 Weight: [2.35359778 1.16006541] Bias: -1.1481071336622344 loss: 0.3522126087143161\n",
            "Round: 1768 Weight: [2.35361399 1.16007366] Bias: -1.1481132906565115 loss: 0.3522126050102625\n",
            "Round: 1769 Weight: [2.35363016 1.16008189] Bias: -1.1481194299306927 loss: 0.3522126013274755\n",
            "Round: 1770 Weight: [2.35364627 1.1600901 ] Bias: -1.1481255515361128 loss: 0.35221259766583274\n",
            "Round: 1771 Weight: [2.35366235 1.16009828] Bias: -1.1481316555239554 loss: 0.3522125940252123\n",
            "Round: 1772 Weight: [2.35367837 1.16010643] Bias: -1.1481377419452539 loss: 0.3522125904054935\n",
            "Round: 1773 Weight: [2.35369435 1.16011457] Bias: -1.1481438108508921 loss: 0.35221258680655576\n",
            "Round: 1774 Weight: [2.35371029 1.16012268] Bias: -1.1481498622916047 loss: 0.3522125832282795\n",
            "Round: 1775 Weight: [2.35372617 1.16013077] Bias: -1.148155896317977 loss: 0.3522125796705458\n",
            "Round: 1776 Weight: [2.35374202 1.16013883] Bias: -1.1481619129804466 loss: 0.3522125761332364\n",
            "Round: 1777 Weight: [2.35375781 1.16014687] Bias: -1.1481679123293027 loss: 0.35221257261623384\n",
            "Round: 1778 Weight: [2.35377356 1.16015489] Bias: -1.1481738944146873 loss: 0.35221256911942117\n",
            "Round: 1779 Weight: [2.35378927 1.16016288] Bias: -1.148179859286595 loss: 0.352212565642682\n",
            "Round: 1780 Weight: [2.35380493 1.16017086] Bias: -1.148185806994874 loss: 0.352212562185901\n",
            "Round: 1781 Weight: [2.35382055 1.1601788 ] Bias: -1.1481917375892265 loss: 0.35221255874896334\n",
            "Round: 1782 Weight: [2.35383612 1.16018673] Bias: -1.1481976511192085 loss: 0.35221255533175455\n",
            "Round: 1783 Weight: [2.35385164 1.16019463] Bias: -1.148203547634231 loss: 0.35221255193416134\n",
            "Round: 1784 Weight: [2.35386713 1.16020251] Bias: -1.1482094271835601 loss: 0.3522125485560708\n",
            "Round: 1785 Weight: [2.35388256 1.16021037] Bias: -1.1482152898163176 loss: 0.35221254519737055\n",
            "Round: 1786 Weight: [2.35389796 1.16021821] Bias: -1.148221135581481 loss: 0.352212541857949\n",
            "Round: 1787 Weight: [2.3539133  1.16022602] Bias: -1.1482269645278846 loss: 0.35221253853769535\n",
            "Round: 1788 Weight: [2.35392861 1.16023381] Bias: -1.1482327767042193 loss: 0.35221253523649915\n",
            "Round: 1789 Weight: [2.35394387 1.16024158] Bias: -1.1482385721590334 loss: 0.35221253195425084\n",
            "Round: 1790 Weight: [2.35395908 1.16024932] Bias: -1.1482443509407327 loss: 0.3522125286908413\n",
            "Round: 1791 Weight: [2.35397426 1.16025705] Bias: -1.1482501130975815 loss: 0.3522125254461622\n",
            "Round: 1792 Weight: [2.35398939 1.16026475] Bias: -1.1482558586777027 loss: 0.3522125222201057\n",
            "Round: 1793 Weight: [2.35400447 1.16027243] Bias: -1.148261587729078 loss: 0.3522125190125647\n",
            "Round: 1794 Weight: [2.35401952 1.16028009] Bias: -1.1482673002995485 loss: 0.35221251582343266\n",
            "Round: 1795 Weight: [2.35403451 1.16028772] Bias: -1.1482729964368152 loss: 0.3522125126526035\n",
            "Round: 1796 Weight: [2.35404947 1.16029533] Bias: -1.1482786761884396 loss: 0.3522125094999722\n",
            "Round: 1797 Weight: [2.35406438 1.16030293] Bias: -1.1482843396018434 loss: 0.3522125063654338\n",
            "Round: 1798 Weight: [2.35407925 1.16031049] Bias: -1.14828998672431 loss: 0.35221250324888437\n",
            "Round: 1799 Weight: [2.35409408 1.16031804] Bias: -1.1482956176029837 loss: 0.35221250015022015\n",
            "Round: 1800 Weight: [2.35410887 1.16032557] Bias: -1.1483012322848714 loss: 0.3522124970693386\n",
            "Round: 1801 Weight: [2.35412361 1.16033307] Bias: -1.1483068308168418 loss: 0.35221249400613736\n",
            "Round: 1802 Weight: [2.35413831 1.16034056] Bias: -1.1483124132456266 loss: 0.3522124909605144\n",
            "Round: 1803 Weight: [2.35415297 1.16034802] Bias: -1.1483179796178207 loss: 0.352212487932369\n",
            "Round: 1804 Weight: [2.35416758 1.16035546] Bias: -1.1483235299798824 loss: 0.35221248492160023\n",
            "Round: 1805 Weight: [2.35418216 1.16036288] Bias: -1.1483290643781343 loss: 0.35221248192810845\n",
            "Round: 1806 Weight: [2.35419669 1.16037027] Bias: -1.148334582858763 loss: 0.35221247895179403\n",
            "Round: 1807 Weight: [2.35421118 1.16037765] Bias: -1.1483400854678203 loss: 0.3522124759925584\n",
            "Round: 1808 Weight: [2.35422563 1.160385  ] Bias: -1.148345572251223 loss: 0.35221247305030307\n",
            "Round: 1809 Weight: [2.35424003 1.16039234] Bias: -1.1483510432547537 loss: 0.35221247012493057\n",
            "Round: 1810 Weight: [2.3542544  1.16039965] Bias: -1.1483564985240606 loss: 0.35221246721634375\n",
            "Round: 1811 Weight: [2.35426872 1.16040694] Bias: -1.1483619381046588 loss: 0.35221246432444586\n",
            "Round: 1812 Weight: [2.35428301 1.16041421] Bias: -1.14836736204193 loss: 0.35221246144914126\n",
            "Round: 1813 Weight: [2.35429725 1.16042146] Bias: -1.1483727703811228 loss: 0.3522124585903342\n",
            "Round: 1814 Weight: [2.35431145 1.16042869] Bias: -1.1483781631673542 loss: 0.35221245574793\n",
            "Round: 1815 Weight: [2.35432561 1.1604359 ] Bias: -1.1483835404456084 loss: 0.3522124529218342\n",
            "Round: 1816 Weight: [2.35433973 1.16044309] Bias: -1.1483889022607385 loss: 0.35221245011195296\n",
            "Round: 1817 Weight: [2.35435381 1.16045025] Bias: -1.1483942486574663 loss: 0.35221244731819323\n",
            "Round: 1818 Weight: [2.35436785 1.1604574 ] Bias: -1.1483995796803825 loss: 0.3522124445404622\n",
            "Round: 1819 Weight: [2.35438185 1.16046453] Bias: -1.1484048953739479 loss: 0.35221244177866756\n",
            "Round: 1820 Weight: [2.35439581 1.16047163] Bias: -1.1484101957824928 loss: 0.35221243903271787\n",
            "Round: 1821 Weight: [2.35440972 1.16047872] Bias: -1.148415480950218 loss: 0.3522124363025218\n",
            "Round: 1822 Weight: [2.3544236  1.16048578] Bias: -1.1484207509211952 loss: 0.35221243358798887\n",
            "Round: 1823 Weight: [2.35443744 1.16049282] Bias: -1.1484260057393672 loss: 0.35221243088902915\n",
            "Round: 1824 Weight: [2.35445124 1.16049985] Bias: -1.1484312454485481 loss: 0.3522124282055528\n",
            "Round: 1825 Weight: [2.354465   1.16050685] Bias: -1.148436470092424 loss: 0.352212425537471\n",
            "Round: 1826 Weight: [2.35447872 1.16051384] Bias: -1.1484416797145536 loss: 0.35221242288469523\n",
            "Round: 1827 Weight: [2.3544924 1.1605208] Bias: -1.1484468743583678 loss: 0.35221242024713734\n",
            "Round: 1828 Weight: [2.35450604 1.16052774] Bias: -1.1484520540671708 loss: 0.3522124176247099\n",
            "Round: 1829 Weight: [2.35451964 1.16053467] Bias: -1.14845721888414 loss: 0.352212415017326\n",
            "Round: 1830 Weight: [2.3545332  1.16054157] Bias: -1.148462368852327 loss: 0.352212412424899\n",
            "Round: 1831 Weight: [2.35454673 1.16054845] Bias: -1.1484675040146572 loss: 0.3522124098473429\n",
            "Round: 1832 Weight: [2.35456021 1.16055532] Bias: -1.1484726244139307 loss: 0.3522124072845725\n",
            "Round: 1833 Weight: [2.35457366 1.16056216] Bias: -1.1484777300928226 loss: 0.35221240473650234\n",
            "Round: 1834 Weight: [2.35458706 1.16056899] Bias: -1.148482821093883 loss: 0.35221240220304834\n",
            "Round: 1835 Weight: [2.35460043 1.16057579] Bias: -1.1484878974595385 loss: 0.352212399684126\n",
            "Round: 1836 Weight: [2.35461376 1.16058258] Bias: -1.1484929592320905 loss: 0.3522123971796522\n",
            "Round: 1837 Weight: [2.35462706 1.16058935] Bias: -1.1484980064537178 loss: 0.3522123946895437\n",
            "Round: 1838 Weight: [2.35464031 1.16059609] Bias: -1.1485030391664757 loss: 0.3522123922137179\n",
            "Round: 1839 Weight: [2.35465353 1.16060282] Bias: -1.1485080574122963 loss: 0.35221238975209274\n",
            "Round: 1840 Weight: [2.3546667  1.16060953] Bias: -1.14851306123299 loss: 0.35221238730458654\n",
            "Round: 1841 Weight: [2.35467984 1.16061622] Bias: -1.148518050670244 loss: 0.3522123848711182\n",
            "Round: 1842 Weight: [2.35469295 1.16062289] Bias: -1.1485230257656247 loss: 0.352212382451607\n",
            "Round: 1843 Weight: [2.35470601 1.16062954] Bias: -1.1485279865605769 loss: 0.3522123800459728\n",
            "Round: 1844 Weight: [2.35471904 1.16063617] Bias: -1.148532933096424 loss: 0.35221237765413566\n",
            "Round: 1845 Weight: [2.35473203 1.16064278] Bias: -1.1485378654143692 loss: 0.35221237527601634\n",
            "Round: 1846 Weight: [2.35474498 1.16064937] Bias: -1.1485427835554949 loss: 0.35221237291153606\n",
            "Round: 1847 Weight: [2.3547579  1.16065595] Bias: -1.1485476875607639 loss: 0.35221237056061633\n",
            "Round: 1848 Weight: [2.35477077 1.1606625 ] Bias: -1.1485525774710192 loss: 0.35221236822317936\n",
            "Round: 1849 Weight: [2.35478362 1.16066904] Bias: -1.148557453326985 loss: 0.35221236589914745\n",
            "Round: 1850 Weight: [2.35479642 1.16067556] Bias: -1.1485623151692659 loss: 0.3522123635884437\n",
            "Round: 1851 Weight: [2.35480919 1.16068206] Bias: -1.1485671630383487 loss: 0.3522123612909915\n",
            "Round: 1852 Weight: [2.35482192 1.16068854] Bias: -1.1485719969746018 loss: 0.3522123590067147\n",
            "Round: 1853 Weight: [2.35483461 1.160695  ] Bias: -1.1485768170182753 loss: 0.35221235673553747\n",
            "Round: 1854 Weight: [2.35484727 1.16070144] Bias: -1.1485816232095025 loss: 0.3522123544773846\n",
            "Round: 1855 Weight: [2.35485989 1.16070787] Bias: -1.1485864155882992 loss: 0.3522123522321813\n",
            "Round: 1856 Weight: [2.35487248 1.16071428] Bias: -1.1485911941945643 loss: 0.35221234999985296\n",
            "Round: 1857 Weight: [2.35488503 1.16072066] Bias: -1.1485959590680808 loss: 0.35221234778032584\n",
            "Round: 1858 Weight: [2.35489754 1.16072703] Bias: -1.1486007102485152 loss: 0.3522123455735262\n",
            "Round: 1859 Weight: [2.35491002 1.16073339] Bias: -1.1486054477754184 loss: 0.352212343379381\n",
            "Round: 1860 Weight: [2.35492246 1.16073972] Bias: -1.1486101716882258 loss: 0.35221234119781747\n",
            "Round: 1861 Weight: [2.35493487 1.16074603] Bias: -1.148614882026258 loss: 0.35221233902876337\n",
            "Round: 1862 Weight: [2.35494724 1.16075233] Bias: -1.1486195788287208 loss: 0.35221233687214676\n",
            "Round: 1863 Weight: [2.35495957 1.16075861] Bias: -1.1486242621347051 loss: 0.35221233472789604\n",
            "Round: 1864 Weight: [2.35497187 1.16076487] Bias: -1.1486289319831888 loss: 0.3522123325959404\n",
            "Round: 1865 Weight: [2.35498413 1.16077111] Bias: -1.1486335884130354 loss: 0.3522123304762092\n",
            "Round: 1866 Weight: [2.35499636 1.16077734] Bias: -1.148638231462995 loss: 0.3522123283686321\n",
            "Round: 1867 Weight: [2.35500856 1.16078355] Bias: -1.1486428611717052 loss: 0.35221232627313914\n",
            "Round: 1868 Weight: [2.35502071 1.16078974] Bias: -1.1486474775776905 loss: 0.3522123241896611\n",
            "Round: 1869 Weight: [2.35503284 1.16079591] Bias: -1.1486520807193632 loss: 0.3522123221181288\n",
            "Round: 1870 Weight: [2.35504493 1.16080206] Bias: -1.1486566706350239 loss: 0.35221232005847375\n",
            "Round: 1871 Weight: [2.35505698 1.1608082 ] Bias: -1.1486612473628608 loss: 0.35221231801062763\n",
            "Round: 1872 Weight: [2.355069   1.16081432] Bias: -1.1486658109409515 loss: 0.35221231597452257\n",
            "Round: 1873 Weight: [2.35508099 1.16082042] Bias: -1.1486703614072622 loss: 0.3522123139500911\n",
            "Round: 1874 Weight: [2.35509294 1.1608265 ] Bias: -1.1486748987996485 loss: 0.3522123119372663\n",
            "Round: 1875 Weight: [2.35510485 1.16083257] Bias: -1.1486794231558555 loss: 0.35221230993598146\n",
            "Round: 1876 Weight: [2.35511674 1.16083861] Bias: -1.1486839345135187 loss: 0.35221230794617014\n",
            "Round: 1877 Weight: [2.35512858 1.16084465] Bias: -1.1486884329101634 loss: 0.3522123059677665\n",
            "Round: 1878 Weight: [2.3551404  1.16085066] Bias: -1.148692918383206 loss: 0.352212304000705\n",
            "Round: 1879 Weight: [2.35515218 1.16085666] Bias: -1.1486973909699536 loss: 0.3522123020449206\n",
            "Round: 1880 Weight: [2.35516392 1.16086264] Bias: -1.1487018507076046 loss: 0.3522123001003484\n",
            "Round: 1881 Weight: [2.35517564 1.1608686 ] Bias: -1.1487062976332487 loss: 0.35221229816692395\n",
            "Round: 1882 Weight: [2.35518732 1.16087454] Bias: -1.1487107317838683 loss: 0.35221229624458333\n",
            "Round: 1883 Weight: [2.35519896 1.16088047] Bias: -1.1487151531963373 loss: 0.3522122943332629\n",
            "Round: 1884 Weight: [2.35521057 1.16088638] Bias: -1.1487195619074224 loss: 0.3522122924328992\n",
            "Round: 1885 Weight: [2.35522215 1.16089228] Bias: -1.1487239579537833 loss: 0.35221229054342945\n",
            "Round: 1886 Weight: [2.3552337  1.16089815] Bias: -1.1487283413719729 loss: 0.35221228866479104\n",
            "Round: 1887 Weight: [2.35524521 1.16090401] Bias: -1.1487327121984374 loss: 0.3522122867969217\n",
            "Round: 1888 Weight: [2.35525669 1.16090986] Bias: -1.1487370704695172 loss: 0.35221228493975965\n",
            "Round: 1889 Weight: [2.35526814 1.16091568] Bias: -1.1487414162214464 loss: 0.3522122830932434\n",
            "Round: 1890 Weight: [2.35527955 1.16092149] Bias: -1.148745749490354 loss: 0.3522122812573117\n",
            "Round: 1891 Weight: [2.35529093 1.16092729] Bias: -1.148750070312263 loss: 0.35221227943190375\n",
            "Round: 1892 Weight: [2.35530228 1.16093307] Bias: -1.1487543787230927 loss: 0.35221227761695934\n",
            "Round: 1893 Weight: [2.35531359 1.16093883] Bias: -1.148758674758657 loss: 0.3522122758124181\n",
            "Round: 1894 Weight: [2.35532488 1.16094457] Bias: -1.1487629584546655 loss: 0.3522122740182205\n",
            "Round: 1895 Weight: [2.35533613 1.1609503 ] Bias: -1.148767229846724 loss: 0.3522122722343069\n",
            "Round: 1896 Weight: [2.35534735 1.16095601] Bias: -1.1487714889703347 loss: 0.3522122704606186\n",
            "Round: 1897 Weight: [2.35535853 1.1609617 ] Bias: -1.148775735860896 loss: 0.35221226869709654\n",
            "Round: 1898 Weight: [2.35536969 1.16096738] Bias: -1.148779970553704 loss: 0.3522122669436825\n",
            "Round: 1899 Weight: [2.35538081 1.16097304] Bias: -1.1487841930839515 loss: 0.35221226520031845\n",
            "Round: 1900 Weight: [2.3553919  1.16097869] Bias: -1.1487884034867288 loss: 0.35221226346694656\n",
            "Round: 1901 Weight: [2.35540296 1.16098432] Bias: -1.1487926017970242 loss: 0.35221226174350956\n",
            "Round: 1902 Weight: [2.35541398 1.16098993] Bias: -1.1487967880497243 loss: 0.3522122600299503\n",
            "Round: 1903 Weight: [2.35542498 1.16099553] Bias: -1.148800962279614 loss: 0.35221225832621217\n",
            "Round: 1904 Weight: [2.35543594 1.16100111] Bias: -1.1488051245213768 loss: 0.3522122566322387\n",
            "Round: 1905 Weight: [2.35544687 1.16100667] Bias: -1.1488092748095957 loss: 0.3522122549479739\n",
            "Round: 1906 Weight: [2.35545777 1.16101222] Bias: -1.1488134131787526 loss: 0.352212253273362\n",
            "Round: 1907 Weight: [2.35546864 1.16101775] Bias: -1.1488175396632294 loss: 0.35221225160834746\n",
            "Round: 1908 Weight: [2.35547948 1.16102327] Bias: -1.1488216542973078 loss: 0.35221224995287526\n",
            "Round: 1909 Weight: [2.35549029 1.16102877] Bias: -1.1488257571151694 loss: 0.3522122483068908\n",
            "Round: 1910 Weight: [2.35550107 1.16103426] Bias: -1.1488298481508972 loss: 0.3522122466703393\n",
            "Round: 1911 Weight: [2.35551181 1.16103973] Bias: -1.148833927438474 loss: 0.35221224504316667\n",
            "Round: 1912 Weight: [2.35552252 1.16104518] Bias: -1.1488379950117846 loss: 0.3522122434253192\n",
            "Round: 1913 Weight: [2.35553321 1.16105062] Bias: -1.1488420509046149 loss: 0.35221224181674327\n",
            "Round: 1914 Weight: [2.35554386 1.16105604] Bias: -1.1488460951506523 loss: 0.3522122402173856\n",
            "Round: 1915 Weight: [2.35555448 1.16106145] Bias: -1.1488501277834864 loss: 0.3522122386271934\n",
            "Round: 1916 Weight: [2.35556508 1.16106684] Bias: -1.1488541488366093 loss: 0.35221223704611393\n",
            "Round: 1917 Weight: [2.35557564 1.16107222] Bias: -1.1488581583434152 loss: 0.3522122354740949\n",
            "Round: 1918 Weight: [2.35558617 1.16107758] Bias: -1.1488621563372017 loss: 0.35221223391108436\n",
            "Round: 1919 Weight: [2.35559667 1.16108293] Bias: -1.148866142851169 loss: 0.35221223235703053\n",
            "Round: 1920 Weight: [2.35560714 1.16108826] Bias: -1.1488701179184213 loss: 0.35221223081188197\n",
            "Round: 1921 Weight: [2.35561758 1.16109357] Bias: -1.1488740815719662 loss: 0.3522122292755877\n",
            "Round: 1922 Weight: [2.35562799 1.16109887] Bias: -1.1488780338447153 loss: 0.35221222774809674\n",
            "Round: 1923 Weight: [2.35563837 1.16110415] Bias: -1.1488819747694847 loss: 0.35221222622935866\n",
            "Round: 1924 Weight: [2.35564872 1.16110942] Bias: -1.148885904378995 loss: 0.352212224719323\n",
            "Round: 1925 Weight: [2.35565904 1.16111468] Bias: -1.1488898227058715 loss: 0.35221222321794016\n",
            "Round: 1926 Weight: [2.35566934 1.16111992] Bias: -1.148893729782645 loss: 0.35221222172516015\n",
            "Round: 1927 Weight: [2.3556796  1.16112514] Bias: -1.1488976256417514 loss: 0.3522122202409339\n",
            "Round: 1928 Weight: [2.35568983 1.16113035] Bias: -1.1489015103155322 loss: 0.3522122187652119\n",
            "Round: 1929 Weight: [2.35570004 1.16113554] Bias: -1.1489053838362355 loss: 0.3522122172979458\n",
            "Round: 1930 Weight: [2.35571021 1.16114072] Bias: -1.148909246236015 loss: 0.3522122158390868\n",
            "Round: 1931 Weight: [2.35572035 1.16114589] Bias: -1.1489130975469313 loss: 0.3522122143885865\n",
            "Round: 1932 Weight: [2.35573047 1.16115104] Bias: -1.1489169378009516 loss: 0.35221221294639726\n",
            "Round: 1933 Weight: [2.35574056 1.16115617] Bias: -1.1489207670299504 loss: 0.35221221151247123\n",
            "Round: 1934 Weight: [2.35575062 1.16116129] Bias: -1.1489245852657093 loss: 0.35221221008676096\n",
            "Round: 1935 Weight: [2.35576064 1.1611664 ] Bias: -1.1489283925399179 loss: 0.3522122086692193\n",
            "Round: 1936 Weight: [2.35577064 1.16117149] Bias: -1.1489321888841735 loss: 0.3522122072597994\n",
            "Round: 1937 Weight: [2.35578062 1.16117657] Bias: -1.1489359743299814 loss: 0.3522122058584547\n",
            "Round: 1938 Weight: [2.35579056 1.16118163] Bias: -1.1489397489087558 loss: 0.35221220446513885\n",
            "Round: 1939 Weight: [2.35580047 1.16118667] Bias: -1.1489435126518193 loss: 0.35221220307980555\n",
            "Round: 1940 Weight: [2.35581036 1.16119171] Bias: -1.1489472655904034 loss: 0.3522122017024092\n",
            "Round: 1941 Weight: [2.35582022 1.16119672] Bias: -1.1489510077556493 loss: 0.3522122003329042\n",
            "Round: 1942 Weight: [2.35583005 1.16120173] Bias: -1.1489547391786072 loss: 0.3522121989712454\n",
            "Round: 1943 Weight: [2.35583985 1.16120672] Bias: -1.1489584598902376 loss: 0.3522121976173874\n",
            "Round: 1944 Weight: [2.35584962 1.16121169] Bias: -1.1489621699214105 loss: 0.3522121962712859\n",
            "Round: 1945 Weight: [2.35585937 1.16121665] Bias: -1.1489658693029068 loss: 0.35221219493289607\n",
            "Round: 1946 Weight: [2.35586908 1.1612216 ] Bias: -1.1489695580654176 loss: 0.3522121936021738\n",
            "Round: 1947 Weight: [2.35587877 1.16122653] Bias: -1.1489732362395448 loss: 0.352212192279075\n",
            "Round: 1948 Weight: [2.35588844 1.16123145] Bias: -1.148976903855802 loss: 0.352212190963556\n",
            "Round: 1949 Weight: [2.35589807 1.16123636] Bias: -1.1489805609446135 loss: 0.3522121896555732\n",
            "Round: 1950 Weight: [2.35590768 1.16124125] Bias: -1.1489842075363157 loss: 0.3522121883550836\n",
            "Round: 1951 Weight: [2.35591725 1.16124612] Bias: -1.1489878436611565 loss: 0.3522121870620438\n",
            "Round: 1952 Weight: [2.35592681 1.16125098] Bias: -1.1489914693492964 loss: 0.35221218577641156\n",
            "Round: 1953 Weight: [2.35593633 1.16125583] Bias: -1.1489950846308081 loss: 0.3522121844981439\n",
            "Round: 1954 Weight: [2.35594583 1.16126067] Bias: -1.148998689535677 loss: 0.3522121832271989\n",
            "Round: 1955 Weight: [2.35595529 1.16126549] Bias: -1.1490022840938012 loss: 0.3522121819635344\n",
            "Round: 1956 Weight: [2.35596474 1.16127029] Bias: -1.1490058683349924 loss: 0.35221218070710864\n",
            "Round: 1957 Weight: [2.35597415 1.16127509] Bias: -1.1490094422889756 loss: 0.3522121794578801\n",
            "Round: 1958 Weight: [2.35598354 1.16127987] Bias: -1.1490130059853894 loss: 0.35221217821580736\n",
            "Round: 1959 Weight: [2.3559929  1.16128463] Bias: -1.1490165594537864 loss: 0.35221217698084956\n",
            "Round: 1960 Weight: [2.35600223 1.16128938] Bias: -1.1490201027236335 loss: 0.3522121757529659\n",
            "Round: 1961 Weight: [2.35601154 1.16129412] Bias: -1.149023635824312 loss: 0.35221217453211556\n",
            "Round: 1962 Weight: [2.35602082 1.16129884] Bias: -1.149027158785118 loss: 0.3522121733182584\n",
            "Round: 1963 Weight: [2.35603008 1.16130356] Bias: -1.1490306716352625 loss: 0.3522121721113542\n",
            "Round: 1964 Weight: [2.3560393  1.16130825] Bias: -1.1490341744038717 loss: 0.3522121709113631\n",
            "Round: 1965 Weight: [2.35604851 1.16131294] Bias: -1.1490376671199871 loss: 0.3522121697182454\n",
            "Round: 1966 Weight: [2.35605768 1.16131761] Bias: -1.1490411498125663 loss: 0.3522121685319618\n",
            "Round: 1967 Weight: [2.35606683 1.16132226] Bias: -1.1490446225104824 loss: 0.35221216735247296\n",
            "Round: 1968 Weight: [2.35607595 1.16132691] Bias: -1.1490480852425253 loss: 0.3522121661797399\n",
            "Round: 1969 Weight: [2.35608505 1.16133154] Bias: -1.149051538037401 loss: 0.352212165013724\n",
            "Round: 1970 Weight: [2.35609412 1.16133616] Bias: -1.1490549809237318 loss: 0.35221216385438653\n",
            "Round: 1971 Weight: [2.35610316 1.16134076] Bias: -1.149058413930058 loss: 0.3522121627016893\n",
            "Round: 1972 Weight: [2.35611218 1.16134535] Bias: -1.149061837084836 loss: 0.3522121615555943\n",
            "Round: 1973 Weight: [2.35612117 1.16134993] Bias: -1.1490652504164405 loss: 0.35221216041606346\n",
            "Round: 1974 Weight: [2.35613014 1.16135449] Bias: -1.1490686539531632 loss: 0.3522121592830592\n",
            "Round: 1975 Weight: [2.35613908 1.16135904] Bias: -1.1490720477232141 loss: 0.35221215815654416\n",
            "Round: 1976 Weight: [2.35614799 1.16136358] Bias: -1.1490754317547216 loss: 0.35221215703648107\n",
            "Round: 1977 Weight: [2.35615688 1.16136811] Bias: -1.1490788060757318 loss: 0.352212155922833\n",
            "Round: 1978 Weight: [2.35616575 1.16137262] Bias: -1.14908217071421 loss: 0.3522121548155629\n",
            "Round: 1979 Weight: [2.35617458 1.16137712] Bias: -1.1490855256980403 loss: 0.35221215371463443\n",
            "Round: 1980 Weight: [2.3561834  1.16138161] Bias: -1.1490888710550258 loss: 0.3522121526200112\n",
            "Round: 1981 Weight: [2.35619219 1.16138608] Bias: -1.1490922068128888 loss: 0.352212151531657\n",
            "Round: 1982 Weight: [2.35620095 1.16139054] Bias: -1.1490955329992718 loss: 0.35221215044953574\n",
            "Round: 1983 Weight: [2.35620969 1.16139499] Bias: -1.1490988496417365 loss: 0.35221214937361195\n",
            "Round: 1984 Weight: [2.3562184  1.16139942] Bias: -1.1491021567677648 loss: 0.3522121483038498\n",
            "Round: 1985 Weight: [2.35622709 1.16140385] Bias: -1.1491054544047594 loss: 0.3522121472402141\n",
            "Round: 1986 Weight: [2.35623575 1.16140826] Bias: -1.1491087425800428 loss: 0.35221214618266977\n",
            "Round: 1987 Weight: [2.35624439 1.16141265] Bias: -1.149112021320859 loss: 0.3522121451311818\n",
            "Round: 1988 Weight: [2.356253   1.16141704] Bias: -1.1491152906543725 loss: 0.3522121440857155\n",
            "Round: 1989 Weight: [2.35626159 1.16142141] Bias: -1.1491185506076689 loss: 0.35221214304623616\n",
            "Round: 1990 Weight: [2.35627015 1.16142577] Bias: -1.149121801207756 loss: 0.3522121420127096\n",
            "Round: 1991 Weight: [2.35627869 1.16143012] Bias: -1.1491250424815624 loss: 0.3522121409851016\n",
            "Round: 1992 Weight: [2.35628721 1.16143445] Bias: -1.1491282744559397 loss: 0.35221213996337836\n",
            "Round: 1993 Weight: [2.3562957  1.16143877] Bias: -1.1491314971576605 loss: 0.352212138947506\n",
            "Round: 1994 Weight: [2.35630416 1.16144308] Bias: -1.1491347106134207 loss: 0.3522121379374511\n",
            "Round: 1995 Weight: [2.3563126  1.16144738] Bias: -1.1491379148498382 loss: 0.3522121369331802\n",
            "Round: 1996 Weight: [2.35632102 1.16145166] Bias: -1.149141109893454 loss: 0.35221213593466\n",
            "Round: 1997 Weight: [2.35632941 1.16145594] Bias: -1.1491442957707325 loss: 0.3522121349418578\n",
            "Round: 1998 Weight: [2.35633778 1.1614602 ] Bias: -1.1491474725080608 loss: 0.3522121339547406\n",
            "Round: 1999 Weight: [2.35634613 1.16146445] Bias: -1.1491506401317497 loss: 0.35221213297327597\n",
            "Round: 2000 Weight: [2.35635445 1.16146868] Bias: -1.149153798668034 loss: 0.3522121319974313\n",
            "Round: 2001 Weight: [2.35636275 1.16147291] Bias: -1.1491569481430723 loss: 0.35221213102717447\n",
            "Round: 2002 Weight: [2.35637102 1.16147712] Bias: -1.1491600885829476 loss: 0.3522121300624734\n",
            "Round: 2003 Weight: [2.35637927 1.16148132] Bias: -1.1491632200136668 loss: 0.35221212910329636\n",
            "Round: 2004 Weight: [2.3563875  1.16148551] Bias: -1.149166342461162 loss: 0.35221212814961156\n",
            "Round: 2005 Weight: [2.3563957  1.16148968] Bias: -1.1491694559512897 loss: 0.35221212720138745\n",
            "Round: 2006 Weight: [2.35640388 1.16149384] Bias: -1.149172560509832 loss: 0.35221212625859283\n",
            "Round: 2007 Weight: [2.35641203 1.161498  ] Bias: -1.1491756561624957 loss: 0.3522121253211966\n",
            "Round: 2008 Weight: [2.35642017 1.16150214] Bias: -1.1491787429349136 loss: 0.35221212438916766\n",
            "Round: 2009 Weight: [2.35642828 1.16150626] Bias: -1.149181820852644 loss: 0.3522121234624754\n",
            "Round: 2010 Weight: [2.35643636 1.16151038] Bias: -1.1491848899411714 loss: 0.3522121225410891\n",
            "Round: 2011 Weight: [2.35644442 1.16151449] Bias: -1.1491879502259061 loss: 0.3522121216249783\n",
            "Round: 2012 Weight: [2.35645246 1.16151858] Bias: -1.1491910017321851 loss: 0.35221212071411295\n",
            "Round: 2013 Weight: [2.35646048 1.16152266] Bias: -1.149194044485272 loss: 0.35221211980846284\n",
            "Round: 2014 Weight: [2.35646847 1.16152673] Bias: -1.149197078510357 loss: 0.352212118907998\n",
            "Round: 2015 Weight: [2.35647644 1.16153079] Bias: -1.1492001038325572 loss: 0.3522121180126888\n",
            "Round: 2016 Weight: [2.35648439 1.16153483] Bias: -1.1492031204769175 loss: 0.3522121171225057\n",
            "Round: 2017 Weight: [2.35649232 1.16153887] Bias: -1.1492061284684099 loss: 0.35221211623741927\n",
            "Round: 2018 Weight: [2.35650022 1.16154289] Bias: -1.149209127831934 loss: 0.3522121153574003\n",
            "Round: 2019 Weight: [2.3565081 1.1615469] Bias: -1.1492121185923176 loss: 0.35221211448241974\n",
            "Round: 2020 Weight: [2.35651596 1.1615509 ] Bias: -1.1492151007743165 loss: 0.35221211361244875\n",
            "Round: 2021 Weight: [2.35652379 1.16155489] Bias: -1.1492180744026146 loss: 0.35221211274745856\n",
            "Round: 2022 Weight: [2.3565316  1.16155886] Bias: -1.1492210395018245 loss: 0.35221211188742046\n",
            "Round: 2023 Weight: [2.35653939 1.16156283] Bias: -1.1492239960964874 loss: 0.3522121110323063\n",
            "Round: 2024 Weight: [2.35654716 1.16156678] Bias: -1.1492269442110736 loss: 0.3522121101820879\n",
            "Round: 2025 Weight: [2.3565549  1.16157073] Bias: -1.1492298838699826 loss: 0.3522121093367369\n",
            "Round: 2026 Weight: [2.35656263 1.16157466] Bias: -1.149232815097543 loss: 0.3522121084962256\n",
            "Round: 2027 Weight: [2.35657033 1.16157858] Bias: -1.1492357379180134 loss: 0.3522121076605263\n",
            "Round: 2028 Weight: [2.35657801 1.16158249] Bias: -1.1492386523555815 loss: 0.3522121068296113\n",
            "Round: 2029 Weight: [2.35658566 1.16158639] Bias: -1.1492415584343654 loss: 0.35221210600345315\n",
            "Round: 2030 Weight: [2.3565933  1.16159027] Bias: -1.1492444561784134 loss: 0.35221210518202467\n",
            "Round: 2031 Weight: [2.35660091 1.16159415] Bias: -1.1492473456117043 loss: 0.3522121043652988\n",
            "Round: 2032 Weight: [2.3566085  1.16159801] Bias: -1.149250226758147 loss: 0.3522121035532484\n",
            "Round: 2033 Weight: [2.35661607 1.16160186] Bias: -1.1492530996415815 loss: 0.3522121027458468\n",
            "Round: 2034 Weight: [2.35662362 1.16160571] Bias: -1.149255964285779 loss: 0.35221210194306724\n",
            "Round: 2035 Weight: [2.35663114 1.16160954] Bias: -1.1492588207144414 loss: 0.3522121011448835\n",
            "Round: 2036 Weight: [2.35663865 1.16161336] Bias: -1.1492616689512027 loss: 0.35221210035126893\n",
            "Round: 2037 Weight: [2.35664613 1.16161717] Bias: -1.1492645090196278 loss: 0.35221209956219757\n",
            "Round: 2038 Weight: [2.35665359 1.16162097] Bias: -1.1492673409432137 loss: 0.35221209877764315\n",
            "Round: 2039 Weight: [2.35666103 1.16162475] Bias: -1.1492701647453893 loss: 0.35221209799757996\n",
            "Round: 2040 Weight: [2.35666845 1.16162853] Bias: -1.149272980449516 loss: 0.3522120972219821\n",
            "Round: 2041 Weight: [2.35667585 1.1616323 ] Bias: -1.1492757880788875 loss: 0.3522120964508242\n",
            "Round: 2042 Weight: [2.35668322 1.16163605] Bias: -1.1492785876567295 loss: 0.3522120956840806\n",
            "Round: 2043 Weight: [2.35669058 1.1616398 ] Bias: -1.1492813792062013 loss: 0.3522120949217261\n",
            "Round: 2044 Weight: [2.35669791 1.16164353] Bias: -1.149284162750395 loss: 0.3522120941637355\n",
            "Round: 2045 Weight: [2.35670523 1.16164725] Bias: -1.1492869383123352 loss: 0.3522120934100839\n",
            "Round: 2046 Weight: [2.35671252 1.16165096] Bias: -1.149289705914981 loss: 0.35221209266074627\n",
            "Round: 2047 Weight: [2.35671979 1.16165466] Bias: -1.149292465581224 loss: 0.352212091915698\n",
            "Round: 2048 Weight: [2.35672704 1.16165836] Bias: -1.1492952173338904 loss: 0.3522120911749145\n",
            "Round: 2049 Weight: [2.35673427 1.16166204] Bias: -1.14929796119574 loss: 0.3522120904383713\n",
            "Round: 2050 Weight: [2.35674148 1.16166571] Bias: -1.1493006971894666 loss: 0.35221208970604406\n",
            "Round: 2051 Weight: [2.35674866 1.16166937] Bias: -1.1493034253376988 loss: 0.3522120889779087\n",
            "Round: 2052 Weight: [2.35675583 1.16167301] Bias: -1.1493061456629994 loss: 0.3522120882539411\n",
            "Round: 2053 Weight: [2.35676298 1.16167665] Bias: -1.1493088581878659 loss: 0.3522120875341174\n",
            "Round: 2054 Weight: [2.35677011 1.16168028] Bias: -1.149311562934731 loss: 0.352212086818414\n",
            "Round: 2055 Weight: [2.35677721 1.1616839 ] Bias: -1.1493142599259625 loss: 0.3522120861068072\n",
            "Round: 2056 Weight: [2.3567843 1.1616875] Bias: -1.149316949183863 loss: 0.3522120853992733\n",
            "Round: 2057 Weight: [2.35679136 1.1616911 ] Bias: -1.1493196307306712 loss: 0.35221208469578924\n",
            "Round: 2058 Weight: [2.35679841 1.16169469] Bias: -1.1493223045885612 loss: 0.35221208399633175\n",
            "Round: 2059 Weight: [2.35680543 1.16169826] Bias: -1.149324970779643 loss: 0.3522120833008776\n",
            "Round: 2060 Weight: [2.35681244 1.16170183] Bias: -1.1493276293259624 loss: 0.3522120826094042\n",
            "Round: 2061 Weight: [2.35681942 1.16170539] Bias: -1.1493302802495022 loss: 0.35221208192188835\n",
            "Round: 2062 Weight: [2.35682639 1.16170893] Bias: -1.149332923572181 loss: 0.35221208123830755\n",
            "Round: 2063 Weight: [2.35683333 1.16171247] Bias: -1.149335559315854 loss: 0.35221208055863934\n",
            "Round: 2064 Weight: [2.35684026 1.16171599] Bias: -1.1493381875023136 loss: 0.3522120798828611\n",
            "Round: 2065 Weight: [2.35684716 1.16171951] Bias: -1.1493408081532888 loss: 0.3522120792109507\n",
            "Round: 2066 Weight: [2.35685405 1.16172301] Bias: -1.1493434212904459 loss: 0.35221207854288594\n",
            "Round: 2067 Weight: [2.35686091 1.16172651] Bias: -1.1493460269353886 loss: 0.3522120778786447\n",
            "Round: 2068 Weight: [2.35686776 1.16172999] Bias: -1.1493486251096583 loss: 0.3522120772182051\n",
            "Round: 2069 Weight: [2.35687458 1.16173347] Bias: -1.1493512158347339 loss: 0.3522120765615454\n",
            "Round: 2070 Weight: [2.35688139 1.16173693] Bias: -1.149353799132032 loss: 0.35221207590864406\n",
            "Round: 2071 Weight: [2.35688818 1.16174039] Bias: -1.1493563750229077 loss: 0.35221207525947934\n",
            "Round: 2072 Weight: [2.35689494 1.16174383] Bias: -1.1493589435286544 loss: 0.3522120746140298\n",
            "Round: 2073 Weight: [2.35690169 1.16174727] Bias: -1.1493615046705035 loss: 0.35221207397227433\n",
            "Round: 2074 Weight: [2.35690842 1.16175069] Bias: -1.1493640584696254 loss: 0.3522120733341917\n",
            "Round: 2075 Weight: [2.35691513 1.16175411] Bias: -1.1493666049471292 loss: 0.35221207269976085\n",
            "Round: 2076 Weight: [2.35692182 1.16175751] Bias: -1.1493691441240628 loss: 0.3522120720689608\n",
            "Round: 2077 Weight: [2.35692849 1.16176091] Bias: -1.1493716760214137 loss: 0.352212071441771\n",
            "Round: 2078 Weight: [2.35693515 1.1617643 ] Bias: -1.1493742006601082 loss: 0.35221207081817046\n",
            "Round: 2079 Weight: [2.35694178 1.16176767] Bias: -1.1493767180610126 loss: 0.35221207019813877\n",
            "Round: 2080 Weight: [2.35694839 1.16177104] Bias: -1.1493792282449327 loss: 0.3522120695816553\n",
            "Round: 2081 Weight: [2.35695499 1.1617744 ] Bias: -1.149381731232614 loss: 0.3522120689687\n",
            "Round: 2082 Weight: [2.35696156 1.16177775] Bias: -1.1493842270447423 loss: 0.35221206835925256\n",
            "Round: 2083 Weight: [2.35696812 1.16178108] Bias: -1.1493867157019435 loss: 0.3522120677532927\n",
            "Round: 2084 Weight: [2.35697466 1.16178441] Bias: -1.1493891972247838 loss: 0.3522120671508007\n",
            "Round: 2085 Weight: [2.35698118 1.16178773] Bias: -1.1493916716337702 loss: 0.3522120665517566\n",
            "Round: 2086 Weight: [2.35698768 1.16179104] Bias: -1.1493941389493503 loss: 0.3522120659561405\n",
            "Round: 2087 Weight: [2.35699416 1.16179434] Bias: -1.1493965991919126 loss: 0.35221206536393296\n",
            "Round: 2088 Weight: [2.35700063 1.16179763] Bias: -1.149399052381787 loss: 0.35221206477511446\n",
            "Round: 2089 Weight: [2.35700707 1.16180091] Bias: -1.149401498539244 loss: 0.3522120641896654\n",
            "Round: 2090 Weight: [2.3570135  1.16180419] Bias: -1.1494039376844962 loss: 0.3522120636075666\n",
            "Round: 2091 Weight: [2.35701991 1.16180745] Bias: -1.1494063698376975 loss: 0.3522120630287989\n",
            "Round: 2092 Weight: [2.3570263 1.1618107] Bias: -1.1494087950189436 loss: 0.35221206245334313\n",
            "Round: 2093 Weight: [2.35703267 1.16181394] Bias: -1.1494112132482721 loss: 0.3522120618811803\n",
            "Round: 2094 Weight: [2.35703902 1.16181718] Bias: -1.1494136245456628 loss: 0.35221206131229166\n",
            "Round: 2095 Weight: [2.35704536 1.1618204 ] Bias: -1.1494160289310378 loss: 0.3522120607466584\n",
            "Round: 2096 Weight: [2.35705168 1.16182362] Bias: -1.1494184264242615 loss: 0.3522120601842618\n",
            "Round: 2097 Weight: [2.35705798 1.16182683] Bias: -1.149420817045141 loss: 0.3522120596250834\n",
            "Round: 2098 Weight: [2.35706426 1.16183002] Bias: -1.1494232008134262 loss: 0.3522120590691048\n",
            "Round: 2099 Weight: [2.35707052 1.16183321] Bias: -1.14942557774881 loss: 0.35221205851630755\n",
            "Round: 2100 Weight: [2.35707676 1.16183639] Bias: -1.1494279478709286 loss: 0.3522120579666736\n",
            "Round: 2101 Weight: [2.35708299 1.16183956] Bias: -1.149430311199361 loss: 0.3522120574201847\n",
            "Round: 2102 Weight: [2.3570892  1.16184272] Bias: -1.1494326677536297 loss: 0.3522120568768227\n",
            "Round: 2103 Weight: [2.35709539 1.16184588] Bias: -1.1494350175532015 loss: 0.35221205633657\n",
            "Round: 2104 Weight: [2.35710157 1.16184902] Bias: -1.1494373606174864 loss: 0.3522120557994087\n",
            "Round: 2105 Weight: [2.35710772 1.16185215] Bias: -1.1494396969658383 loss: 0.3522120552653209\n",
            "Round: 2106 Weight: [2.35711386 1.16185528] Bias: -1.1494420266175551 loss: 0.35221205473428907\n",
            "Round: 2107 Weight: [2.35711998 1.16185839] Bias: -1.1494443495918798 loss: 0.352212054206296\n",
            "Round: 2108 Weight: [2.35712609 1.1618615 ] Bias: -1.149446665907999 loss: 0.3522120536813238\n",
            "Round: 2109 Weight: [2.35713217 1.1618646 ] Bias: -1.1494489755850439 loss: 0.35221205315935555\n",
            "Round: 2110 Weight: [2.35713824 1.16186769] Bias: -1.149451278642091 loss: 0.35221205264037386\n",
            "Round: 2111 Weight: [2.35714429 1.16187077] Bias: -1.1494535750981614 loss: 0.3522120521243617\n",
            "Round: 2112 Weight: [2.35715033 1.16187384] Bias: -1.1494558649722213 loss: 0.352212051611302\n",
            "Round: 2113 Weight: [2.35715634 1.1618769 ] Bias: -1.149458148283182 loss: 0.3522120511011778\n",
            "Round: 2114 Weight: [2.35716234 1.16187996] Bias: -1.1494604250499008 loss: 0.3522120505939725\n",
            "Round: 2115 Weight: [2.35716832 1.161883  ] Bias: -1.1494626952911795 loss: 0.3522120500896692\n",
            "Round: 2116 Weight: [2.35717429 1.16188604] Bias: -1.1494649590257666 loss: 0.3522120495882515\n",
            "Round: 2117 Weight: [2.35718024 1.16188907] Bias: -1.149467216272356 loss: 0.35221204908970244\n",
            "Round: 2118 Weight: [2.35718617 1.16189209] Bias: -1.1494694670495877 loss: 0.35221204859400596\n",
            "Round: 2119 Weight: [2.35719208 1.1618951 ] Bias: -1.149471711376048 loss: 0.3522120481011456\n",
            "Round: 2120 Weight: [2.35719798 1.1618981 ] Bias: -1.1494739492702692 loss: 0.3522120476111052\n",
            "Round: 2121 Weight: [2.35720386 1.16190109] Bias: -1.1494761807507308 loss: 0.3522120471238685\n",
            "Round: 2122 Weight: [2.35720972 1.16190408] Bias: -1.1494784058358583 loss: 0.3522120466394195\n",
            "Round: 2123 Weight: [2.35721557 1.16190705] Bias: -1.149480624544024 loss: 0.35221204615774215\n",
            "Round: 2124 Weight: [2.3572214  1.16191002] Bias: -1.149482836893548 loss: 0.3522120456788207\n",
            "Round: 2125 Weight: [2.35722721 1.16191298] Bias: -1.1494850429026962 loss: 0.3522120452026393\n",
            "Round: 2126 Weight: [2.35723301 1.16191593] Bias: -1.149487242589683 loss: 0.3522120447291823\n",
            "Round: 2127 Weight: [2.35723879 1.16191887] Bias: -1.1494894359726695 loss: 0.35221204425843405\n",
            "Round: 2128 Weight: [2.35724455 1.16192181] Bias: -1.1494916230697647 loss: 0.35221204379037907\n",
            "Round: 2129 Weight: [2.3572503  1.16192473] Bias: -1.1494938038990252 loss: 0.35221204332500194\n",
            "Round: 2130 Weight: [2.35725603 1.16192765] Bias: -1.1494959784784557 loss: 0.35221204286228724\n",
            "Round: 2131 Weight: [2.35726174 1.16193056] Bias: -1.1494981468260086 loss: 0.3522120424022198\n",
            "Round: 2132 Weight: [2.35726744 1.16193346] Bias: -1.1495003089595848 loss: 0.35221204194478445\n",
            "Round: 2133 Weight: [2.35727312 1.16193635] Bias: -1.1495024648970333 loss: 0.35221204148996627\n",
            "Round: 2134 Weight: [2.35727878 1.16193924] Bias: -1.1495046146561518 loss: 0.35221204103774995\n",
            "Round: 2135 Weight: [2.35728443 1.16194211] Bias: -1.1495067582546867 loss: 0.3522120405881209\n",
            "Round: 2136 Weight: [2.35729006 1.16194498] Bias: -1.1495088957103328 loss: 0.35221204014106405\n",
            "Round: 2137 Weight: [2.35729568 1.16194784] Bias: -1.1495110270407343 loss: 0.35221203969656484\n",
            "Round: 2138 Weight: [2.35730128 1.16195069] Bias: -1.149513152263484 loss: 0.3522120392546085\n",
            "Round: 2139 Weight: [2.35730686 1.16195353] Bias: -1.1495152713961245 loss: 0.3522120388151805\n",
            "Round: 2140 Weight: [2.35731243 1.16195637] Bias: -1.1495173844561475 loss: 0.35221203837826653\n",
            "Round: 2141 Weight: [2.35731798 1.16195919] Bias: -1.149519491460994 loss: 0.352212037943852\n",
            "Round: 2142 Weight: [2.35732352 1.16196201] Bias: -1.1495215924280553 loss: 0.3522120375119227\n",
            "Round: 2143 Weight: [2.35732904 1.16196482] Bias: -1.1495236873746717 loss: 0.3522120370824643\n",
            "Round: 2144 Weight: [2.35733455 1.16196762] Bias: -1.1495257763181341 loss: 0.35221203665546275\n",
            "Round: 2145 Weight: [2.35734003 1.16197042] Bias: -1.1495278592756835 loss: 0.35221203623090397\n",
            "Round: 2146 Weight: [2.35734551 1.1619732 ] Bias: -1.1495299362645108 loss: 0.3522120358087739\n",
            "Round: 2147 Weight: [2.35735096 1.16197598] Bias: -1.1495320073017576 loss: 0.3522120353890587\n",
            "Round: 2148 Weight: [2.35735641 1.16197875] Bias: -1.149534072404516 loss: 0.35221203497174447\n",
            "Round: 2149 Weight: [2.35736183 1.16198151] Bias: -1.1495361315898287 loss: 0.3522120345568176\n",
            "Round: 2150 Weight: [2.35736724 1.16198427] Bias: -1.1495381848746895 loss: 0.35221203414426433\n",
            "Round: 2151 Weight: [2.35737264 1.16198702] Bias: -1.1495402322760429 loss: 0.352212033734071\n",
            "Round: 2152 Weight: [2.35737802 1.16198975] Bias: -1.1495422738107843 loss: 0.35221203332622425\n",
            "Round: 2153 Weight: [2.35738338 1.16199249] Bias: -1.1495443094957611 loss: 0.35221203292071046\n",
            "Round: 2154 Weight: [2.35738873 1.16199521] Bias: -1.1495463393477716 loss: 0.3522120325175165\n",
            "Round: 2155 Weight: [2.35739406 1.16199792] Bias: -1.1495483633835657 loss: 0.35221203211662894\n",
            "Round: 2156 Weight: [2.35739938 1.16200063] Bias: -1.149550381619845 loss: 0.3522120317180345\n",
            "Round: 2157 Weight: [2.35740469 1.16200333] Bias: -1.1495523940732628 loss: 0.3522120313217203\n",
            "Round: 2158 Weight: [2.35740997 1.16200602] Bias: -1.1495544007604248 loss: 0.35221203092767306\n",
            "Round: 2159 Weight: [2.35741525 1.16200871] Bias: -1.1495564016978885 loss: 0.3522120305358799\n",
            "Round: 2160 Weight: [2.3574205  1.16201138] Bias: -1.1495583969021637 loss: 0.35221203014632785\n",
            "Round: 2161 Weight: [2.35742575 1.16201405] Bias: -1.1495603863897126 loss: 0.35221202975900423\n",
            "Round: 2162 Weight: [2.35743097 1.16201671] Bias: -1.14956237017695 loss: 0.352212029373896\n",
            "Round: 2163 Weight: [2.35743619 1.16201937] Bias: -1.1495643482802431 loss: 0.3522120289909908\n",
            "Round: 2164 Weight: [2.35744139 1.16202201] Bias: -1.1495663207159124 loss: 0.35221202861027584\n",
            "Round: 2165 Weight: [2.35744657 1.16202465] Bias: -1.1495682875002307 loss: 0.3522120282317385\n",
            "Round: 2166 Weight: [2.35745174 1.16202728] Bias: -1.1495702486494244 loss: 0.35221202785536654\n",
            "Round: 2167 Weight: [2.35745689 1.16202991] Bias: -1.149572204179673 loss: 0.3522120274811474\n",
            "Round: 2168 Weight: [2.35746203 1.16203252] Bias: -1.1495741541071092 loss: 0.3522120271090688\n",
            "Round: 2169 Weight: [2.35746715 1.16203513] Bias: -1.1495760984478192 loss: 0.35221202673911844\n",
            "Round: 2170 Weight: [2.35747226 1.16203773] Bias: -1.149578037217843 loss: 0.3522120263712842\n",
            "Round: 2171 Weight: [2.35747735 1.16204033] Bias: -1.1495799704331744 loss: 0.35221202600555407\n",
            "Round: 2172 Weight: [2.35748243 1.16204291] Bias: -1.1495818981097607 loss: 0.35221202564191567\n",
            "Round: 2173 Weight: [2.3574875  1.16204549] Bias: -1.1495838202635036 loss: 0.3522120252803574\n",
            "Round: 2174 Weight: [2.35749255 1.16204806] Bias: -1.1495857369102587 loss: 0.352212024920867\n",
            "Round: 2175 Weight: [2.35749759 1.16205062] Bias: -1.149587648065836 loss: 0.35221202456343303\n",
            "Round: 2176 Weight: [2.35750261 1.16205318] Bias: -1.1495895537460004 loss: 0.3522120242080434\n",
            "Round: 2177 Weight: [2.35750762 1.16205573] Bias: -1.1495914539664704 loss: 0.3522120238546865\n",
            "Round: 2178 Weight: [2.35751261 1.16205827] Bias: -1.14959334874292 loss: 0.3522120235033507\n",
            "Round: 2179 Weight: [2.35751759 1.16206081] Bias: -1.1495952380909775 loss: 0.3522120231540245\n",
            "Round: 2180 Weight: [2.35752255 1.16206333] Bias: -1.1495971220262264 loss: 0.3522120228066962\n",
            "Round: 2181 Weight: [2.3575275  1.16206585] Bias: -1.1495990005642054 loss: 0.3522120224613547\n",
            "Round: 2182 Weight: [2.35753244 1.16206837] Bias: -1.1496008737204082 loss: 0.35221202211798824\n",
            "Round: 2183 Weight: [2.35753736 1.16207087] Bias: -1.1496027415102839 loss: 0.3522120217765858\n",
            "Round: 2184 Weight: [2.35754227 1.16207337] Bias: -1.149604603949237 loss: 0.3522120214371359\n",
            "Round: 2185 Weight: [2.35754716 1.16207586] Bias: -1.1496064610526278 loss: 0.3522120210996276\n",
            "Round: 2186 Weight: [2.35755204 1.16207835] Bias: -1.1496083128357721 loss: 0.3522120207640498\n",
            "Round: 2187 Weight: [2.35755691 1.16208082] Bias: -1.1496101593139418 loss: 0.35221202043039124\n",
            "Round: 2188 Weight: [2.35756176 1.16208329] Bias: -1.1496120005023647 loss: 0.3522120200986409\n",
            "Round: 2189 Weight: [2.3575666  1.16208576] Bias: -1.1496138364162247 loss: 0.35221201976878813\n",
            "Round: 2190 Weight: [2.35757142 1.16208821] Bias: -1.1496156670706619 loss: 0.3522120194408218\n",
            "Round: 2191 Weight: [2.35757623 1.16209066] Bias: -1.1496174924807727 loss: 0.35221201911473127\n",
            "Round: 2192 Weight: [2.35758103 1.1620931 ] Bias: -1.14961931266161 loss: 0.35221201879050584\n",
            "Round: 2193 Weight: [2.35758581 1.16209554] Bias: -1.1496211276281838 loss: 0.3522120184681347\n",
            "Round: 2194 Weight: [2.35759058 1.16209797] Bias: -1.1496229373954603 loss: 0.3522120181476073\n",
            "Round: 2195 Weight: [2.35759534 1.16210039] Bias: -1.1496247419783627 loss: 0.3522120178289131\n",
            "Round: 2196 Weight: [2.35760008 1.1621028 ] Bias: -1.1496265413917712 loss: 0.3522120175120415\n",
            "Round: 2197 Weight: [2.35760481 1.16210521] Bias: -1.1496283356505232 loss: 0.3522120171969823\n",
            "Round: 2198 Weight: [2.35760952 1.16210761] Bias: -1.1496301247694136 loss: 0.35221201688372494\n",
            "Round: 2199 Weight: [2.35761422 1.16211   ] Bias: -1.149631908763194 loss: 0.3522120165722591\n",
            "Round: 2200 Weight: [2.35761891 1.16211239] Bias: -1.1496336876465743 loss: 0.35221201626257453\n",
            "Round: 2201 Weight: [2.35762359 1.16211477] Bias: -1.1496354614342212 loss: 0.35221201595466123\n",
            "Round: 2202 Weight: [2.35762825 1.16211714] Bias: -1.1496372301407598 loss: 0.35221201564850885\n",
            "Round: 2203 Weight: [2.35763289 1.16211951] Bias: -1.149638993780773 loss: 0.3522120153441073\n",
            "Round: 2204 Weight: [2.35763753 1.16212187] Bias: -1.1496407523688013 loss: 0.3522120150414467\n",
            "Round: 2205 Weight: [2.35764215 1.16212422] Bias: -1.1496425059193434 loss: 0.35221201474051705\n",
            "Round: 2206 Weight: [2.35764676 1.16212657] Bias: -1.1496442544468566 loss: 0.35221201444130834\n",
            "Round: 2207 Weight: [2.35765135 1.1621289 ] Bias: -1.1496459979657563 loss: 0.3522120141438108\n",
            "Round: 2208 Weight: [2.35765593 1.16213124] Bias: -1.1496477364904163 loss: 0.35221201384801465\n",
            "Round: 2209 Weight: [2.3576605  1.16213356] Bias: -1.1496494700351692 loss: 0.35221201355391\n",
            "Round: 2210 Weight: [2.35766506 1.16213588] Bias: -1.149651198614306 loss: 0.3522120132614875\n",
            "Round: 2211 Weight: [2.3576696  1.16213819] Bias: -1.1496529222420773 loss: 0.3522120129707373\n",
            "Round: 2212 Weight: [2.35767413 1.1621405 ] Bias: -1.1496546409326915 loss: 0.35221201268164976\n",
            "Round: 2213 Weight: [2.35767865 1.1621428 ] Bias: -1.149656354700317 loss: 0.3522120123942154\n",
            "Round: 2214 Weight: [2.35768315 1.16214509] Bias: -1.1496580635590807 loss: 0.35221201210842495\n",
            "Round: 2215 Weight: [2.35768764 1.16214738] Bias: -1.1496597675230695 loss: 0.3522120118242688\n",
            "Round: 2216 Weight: [2.35769212 1.16214966] Bias: -1.1496614666063294 loss: 0.3522120115417377\n",
            "Round: 2217 Weight: [2.35769658 1.16215193] Bias: -1.149663160822866 loss: 0.35221201126082224\n",
            "Round: 2218 Weight: [2.35770103 1.1621542 ] Bias: -1.1496648501866444 loss: 0.3522120109815133\n",
            "Round: 2219 Weight: [2.35770547 1.16215646] Bias: -1.1496665347115895 loss: 0.35221201070380165\n",
            "Round: 2220 Weight: [2.3577099  1.16215871] Bias: -1.1496682144115864 loss: 0.35221201042767813\n",
            "Round: 2221 Weight: [2.35771431 1.16216096] Bias: -1.14966988930048 loss: 0.3522120101531335\n",
            "Round: 2222 Weight: [2.35771871 1.1621632 ] Bias: -1.1496715593920752 loss: 0.3522120098801591\n",
            "Round: 2223 Weight: [2.3577231  1.16216543] Bias: -1.1496732247001373 loss: 0.35221200960874566\n",
            "Round: 2224 Weight: [2.35772748 1.16216766] Bias: -1.149674885238392 loss: 0.3522120093388842\n",
            "Round: 2225 Weight: [2.35773184 1.16216988] Bias: -1.1496765410205254 loss: 0.35221200907056605\n",
            "Round: 2226 Weight: [2.35773619 1.1621721 ] Bias: -1.1496781920601844 loss: 0.3522120088037822\n",
            "Round: 2227 Weight: [2.35774053 1.1621743 ] Bias: -1.1496798383709763 loss: 0.3522120085385239\n",
            "Round: 2228 Weight: [2.35774486 1.16217651] Bias: -1.1496814799664692 loss: 0.3522120082747825\n",
            "Round: 2229 Weight: [2.35774917 1.1621787 ] Bias: -1.1496831168601924 loss: 0.3522120080125493\n",
            "Round: 2230 Weight: [2.35775347 1.16218089] Bias: -1.1496847490656361 loss: 0.3522120077518157\n",
            "Round: 2231 Weight: [2.35775776 1.16218308] Bias: -1.1496863765962517 loss: 0.35221200749257303\n",
            "Round: 2232 Weight: [2.35776204 1.16218525] Bias: -1.1496879994654519 loss: 0.35221200723481283\n",
            "Round: 2233 Weight: [2.3577663  1.16218743] Bias: -1.1496896176866105 loss: 0.3522120069785265\n",
            "Round: 2234 Weight: [2.35777056 1.16218959] Bias: -1.1496912312730632 loss: 0.3522120067237058\n",
            "Round: 2235 Weight: [2.3577748  1.16219175] Bias: -1.1496928402381072 loss: 0.3522120064703422\n",
            "Round: 2236 Weight: [2.35777902 1.1621939 ] Bias: -1.1496944445950013 loss: 0.35221200621842724\n",
            "Round: 2237 Weight: [2.35778324 1.16219605] Bias: -1.1496960443569662 loss: 0.35221200596795305\n",
            "Round: 2238 Weight: [2.35778744 1.16219819] Bias: -1.1496976395371843 loss: 0.3522120057189109\n",
            "Round: 2239 Weight: [2.35779164 1.16220032] Bias: -1.1496992301488005 loss: 0.3522120054712929\n",
            "Round: 2240 Weight: [2.35779582 1.16220245] Bias: -1.1497008162049216 loss: 0.3522120052250908\n",
            "Round: 2241 Weight: [2.35779998 1.16220457] Bias: -1.1497023977186167 loss: 0.35221200498029653\n",
            "Round: 2242 Weight: [2.35780414 1.16220669] Bias: -1.1497039747029174 loss: 0.352212004736902\n",
            "Round: 2243 Weight: [2.35780828 1.1622088 ] Bias: -1.1497055471708175 loss: 0.35221200449489926\n",
            "Round: 2244 Weight: [2.35781242 1.1622109 ] Bias: -1.1497071151352736 loss: 0.3522120042542803\n",
            "Round: 2245 Weight: [2.35781654 1.162213  ] Bias: -1.149708678609205 loss: 0.35221200401503716\n",
            "Round: 2246 Weight: [2.35782064 1.16221509] Bias: -1.1497102376054937 loss: 0.352212003777162\n",
            "Round: 2247 Weight: [2.35782474 1.16221717] Bias: -1.1497117921369848 loss: 0.3522120035406471\n",
            "Round: 2248 Weight: [2.35782883 1.16221925] Bias: -1.1497133422164865 loss: 0.3522120033054845\n",
            "Round: 2249 Weight: [2.3578329  1.16222133] Bias: -1.1497148878567698 loss: 0.3522120030716666\n",
            "Round: 2250 Weight: [2.35783696 1.1622234 ] Bias: -1.149716429070569 loss: 0.3522120028391857\n",
            "Round: 2251 Weight: [2.35784101 1.16222546] Bias: -1.149717965870582 loss: 0.3522120026080339\n",
            "Round: 2252 Weight: [2.35784505 1.16222751] Bias: -1.14971949826947 loss: 0.352212002378204\n",
            "Round: 2253 Weight: [2.35784908 1.16222956] Bias: -1.1497210262798578 loss: 0.3522120021496882\n",
            "Round: 2254 Weight: [2.35785309 1.16223161] Bias: -1.149722549914334 loss: 0.3522120019224789\n",
            "Round: 2255 Weight: [2.3578571  1.16223365] Bias: -1.1497240691854504 loss: 0.3522120016965688\n",
            "Round: 2256 Weight: [2.35786109 1.16223568] Bias: -1.1497255841057235 loss: 0.35221200147195036\n",
            "Round: 2257 Weight: [2.35786507 1.16223771] Bias: -1.1497270946876332 loss: 0.3522120012486164\n",
            "Round: 2258 Weight: [2.35786904 1.16223973] Bias: -1.1497286009436238 loss: 0.35221200102655925\n",
            "Round: 2259 Weight: [2.357873   1.16224174] Bias: -1.1497301028861036 loss: 0.3522120008057718\n",
            "Round: 2260 Weight: [2.35787694 1.16224375] Bias: -1.149731600527445 loss: 0.35221200058624674\n",
            "Round: 2261 Weight: [2.35788088 1.16224575] Bias: -1.1497330938799852 loss: 0.3522120003679769\n",
            "Round: 2262 Weight: [2.3578848  1.16224775] Bias: -1.149734582956026 loss: 0.352212000150955\n",
            "Round: 2263 Weight: [2.35788872 1.16224974] Bias: -1.1497360677678332 loss: 0.352211999935174\n",
            "Round: 2264 Weight: [2.35789262 1.16225173] Bias: -1.149737548327638 loss: 0.35221199972062667\n",
            "Round: 2265 Weight: [2.35789651 1.16225371] Bias: -1.1497390246476358 loss: 0.35221199950730614\n",
            "Round: 2266 Weight: [2.35790039 1.16225569] Bias: -1.1497404967399871 loss: 0.35221199929520525\n",
            "Round: 2267 Weight: [2.35790426 1.16225766] Bias: -1.1497419646168177 loss: 0.35221199908431705\n",
            "Round: 2268 Weight: [2.35790812 1.16225962] Bias: -1.1497434282902181 loss: 0.3522119988746345\n",
            "Round: 2269 Weight: [2.35791196 1.16226158] Bias: -1.1497448877722445 loss: 0.3522119986661509\n",
            "Round: 2270 Weight: [2.3579158  1.16226353] Bias: -1.1497463430749177 loss: 0.35221199845885937\n",
            "Round: 2271 Weight: [2.35791962 1.16226548] Bias: -1.1497477942102248 loss: 0.35221199825275296\n",
            "Round: 2272 Weight: [2.35792344 1.16226742] Bias: -1.1497492411901176 loss: 0.3522119980478249\n",
            "Round: 2273 Weight: [2.35792724 1.16226935] Bias: -1.149750684026514 loss: 0.3522119978440685\n",
            "Round: 2274 Weight: [2.35793103 1.16227128] Bias: -1.1497521227312975 loss: 0.3522119976414771\n",
            "Round: 2275 Weight: [2.35793481 1.16227321] Bias: -1.1497535573163173 loss: 0.35221199744004394\n",
            "Round: 2276 Weight: [2.35793858 1.16227513] Bias: -1.1497549877933888 loss: 0.35221199723976254\n",
            "Round: 2277 Weight: [2.35794234 1.16227704] Bias: -1.149756414174293 loss: 0.35221199704062617\n",
            "Round: 2278 Weight: [2.35794609 1.16227895] Bias: -1.1497578364707775 loss: 0.3522119968426283\n",
            "Round: 2279 Weight: [2.35794983 1.16228085] Bias: -1.1497592546945554 loss: 0.3522119966457624\n",
            "Round: 2280 Weight: [2.35795355 1.16228275] Bias: -1.149760668857307 loss: 0.3522119964500222\n",
            "Round: 2281 Weight: [2.35795727 1.16228464] Bias: -1.1497620789706782 loss: 0.35221199625540095\n",
            "Round: 2282 Weight: [2.35796097 1.16228653] Bias: -1.149763485046282 loss: 0.3522119960618924\n",
            "Round: 2283 Weight: [2.35796467 1.16228841] Bias: -1.1497648870956974 loss: 0.3522119958694903\n",
            "Round: 2284 Weight: [2.35796835 1.16229029] Bias: -1.1497662851304706 loss: 0.35221199567818806\n",
            "Round: 2285 Weight: [2.35797203 1.16229216] Bias: -1.1497676791621145 loss: 0.3522119954879796\n",
            "Round: 2286 Weight: [2.35797569 1.16229402] Bias: -1.149769069202109 loss: 0.3522119952988586\n",
            "Round: 2287 Weight: [2.35797934 1.16229588] Bias: -1.1497704552619004 loss: 0.35221199511081874\n",
            "Round: 2288 Weight: [2.35798299 1.16229774] Bias: -1.1497718373529027 loss: 0.352211994923854\n",
            "Round: 2289 Weight: [2.35798662 1.16229958] Bias: -1.1497732154864966 loss: 0.35221199473795817\n",
            "Round: 2290 Weight: [2.35799024 1.16230143] Bias: -1.1497745896740306 loss: 0.352211994553125\n",
            "Round: 2291 Weight: [2.35799385 1.16230327] Bias: -1.14977595992682 loss: 0.35221199436934864\n",
            "Round: 2292 Weight: [2.35799745 1.1623051 ] Bias: -1.149777326256148 loss: 0.3522119941866229\n",
            "Round: 2293 Weight: [2.35800104 1.16230693] Bias: -1.149778688673265 loss: 0.35221199400494174\n",
            "Round: 2294 Weight: [2.35800462 1.16230875] Bias: -1.1497800471893895 loss: 0.3522119938242994\n",
            "Round: 2295 Weight: [2.35800819 1.16231057] Bias: -1.1497814018157073 loss: 0.3522119936446897\n",
            "Round: 2296 Weight: [2.35801175 1.16231238] Bias: -1.1497827525633721 loss: 0.35221199346610677\n",
            "Round: 2297 Weight: [2.3580153  1.16231419] Bias: -1.1497840994435058 loss: 0.35221199328854486\n",
            "Round: 2298 Weight: [2.35801884 1.16231599] Bias: -1.1497854424671978 loss: 0.35221199311199797\n",
            "Round: 2299 Weight: [2.35802237 1.16231779] Bias: -1.1497867816455063 loss: 0.3522119929364605\n",
            "Round: 2300 Weight: [2.35802589 1.16231958] Bias: -1.1497881169894573 loss: 0.35221199276192644\n",
            "Round: 2301 Weight: [2.3580294  1.16232136] Bias: -1.1497894485100448 loss: 0.3522119925883902\n",
            "Round: 2302 Weight: [2.3580329  1.16232315] Bias: -1.149790776218232 loss: 0.3522119924158461\n",
            "Round: 2303 Weight: [2.35803639 1.16232492] Bias: -1.1497921001249498 loss: 0.3522119922442883\n",
            "Round: 2304 Weight: [2.35803987 1.16232669] Bias: -1.149793420241098 loss: 0.35221199207371134\n",
            "Round: 2305 Weight: [2.35804334 1.16232846] Bias: -1.1497947365775452 loss: 0.35221199190410946\n",
            "Round: 2306 Weight: [2.3580468  1.16233022] Bias: -1.1497960491451282 loss: 0.35221199173547724\n",
            "Round: 2307 Weight: [2.35805025 1.16233198] Bias: -1.1497973579546534 loss: 0.35221199156780897\n",
            "Round: 2308 Weight: [2.35805368 1.16233373] Bias: -1.1497986630168957 loss: 0.3522119914010992\n",
            "Round: 2309 Weight: [2.35805711 1.16233547] Bias: -1.149799964342599 loss: 0.3522119912353425\n",
            "Round: 2310 Weight: [2.35806053 1.16233721] Bias: -1.149801261942476 loss: 0.35221199107053336\n",
            "Round: 2311 Weight: [2.35806394 1.16233895] Bias: -1.1498025558272096 loss: 0.35221199090666644\n",
            "Round: 2312 Weight: [2.35806734 1.16234068] Bias: -1.149803846007451 loss: 0.35221199074373627\n",
            "Round: 2313 Weight: [2.35807074 1.16234241] Bias: -1.149805132493821 loss: 0.35221199058173747\n",
            "Round: 2314 Weight: [2.35807412 1.16234413] Bias: -1.1498064152969103 loss: 0.35221199042066476\n",
            "Round: 2315 Weight: [2.35807749 1.16234585] Bias: -1.1498076944272788 loss: 0.35221199026051275\n",
            "Round: 2316 Weight: [2.35808085 1.16234756] Bias: -1.1498089698954561 loss: 0.35221199010127635\n",
            "Round: 2317 Weight: [2.3580842  1.16234926] Bias: -1.1498102417119416 loss: 0.35221198994295017\n",
            "Round: 2318 Weight: [2.35808754 1.16235096] Bias: -1.1498115098872044 loss: 0.35221198978552914\n",
            "Round: 2319 Weight: [2.35809088 1.16235266] Bias: -1.1498127744316835 loss: 0.352211989629008\n",
            "Round: 2320 Weight: [2.3580942  1.16235435] Bias: -1.149814035355788 loss: 0.3522119894733816\n",
            "Round: 2321 Weight: [2.35809751 1.16235604] Bias: -1.1498152926698968 loss: 0.3522119893186448\n",
            "Round: 2322 Weight: [2.35810082 1.16235772] Bias: -1.1498165463843595 loss: 0.3522119891647926\n",
            "Round: 2323 Weight: [2.35810411 1.1623594 ] Bias: -1.1498177965094953 loss: 0.3522119890118199\n",
            "Round: 2324 Weight: [2.3581074  1.16236107] Bias: -1.1498190430555943 loss: 0.3522119888597216\n",
            "Round: 2325 Weight: [2.35811067 1.16236274] Bias: -1.149820286032917 loss: 0.3522119887084927\n",
            "Round: 2326 Weight: [2.35811394 1.1623644 ] Bias: -1.1498215254516937 loss: 0.35221198855812835\n",
            "Round: 2327 Weight: [2.3581172  1.16236606] Bias: -1.1498227613221261 loss: 0.35221198840862356\n",
            "Round: 2328 Weight: [2.35812044 1.16236771] Bias: -1.1498239936543861 loss: 0.3522119882599734\n",
            "Round: 2329 Weight: [2.35812368 1.16236936] Bias: -1.1498252224586167 loss: 0.3522119881121729\n",
            "Round: 2330 Weight: [2.35812691 1.16237101] Bias: -1.1498264477449316 loss: 0.35221198796521735\n",
            "Round: 2331 Weight: [2.35813013 1.16237265] Bias: -1.1498276695234153 loss: 0.3522119878191017\n",
            "Round: 2332 Weight: [2.35813334 1.16237428] Bias: -1.1498288878041234 loss: 0.3522119876738214\n",
            "Round: 2333 Weight: [2.35813654 1.16237591] Bias: -1.1498301025970827 loss: 0.35221198752937155\n",
            "Round: 2334 Weight: [2.35813974 1.16237754] Bias: -1.1498313139122913 loss: 0.3522119873857473\n",
            "Round: 2335 Weight: [2.35814292 1.16237916] Bias: -1.149832521759718 loss: 0.3522119872429442\n",
            "Round: 2336 Weight: [2.35814609 1.16238077] Bias: -1.1498337261493037 loss: 0.3522119871009573\n",
            "Round: 2337 Weight: [2.35814926 1.16238238] Bias: -1.14983492709096 loss: 0.35221198695978206\n",
            "Round: 2338 Weight: [2.35815242 1.16238399] Bias: -1.1498361245945705 loss: 0.3522119868194138\n",
            "Round: 2339 Weight: [2.35815556 1.16238559] Bias: -1.1498373186699904 loss: 0.3522119866798478\n",
            "Round: 2340 Weight: [2.3581587  1.16238719] Bias: -1.1498385093270462 loss: 0.35221198654107977\n",
            "Round: 2341 Weight: [2.35816183 1.16238878] Bias: -1.1498396965755366 loss: 0.3522119864031048\n",
            "Round: 2342 Weight: [2.35816495 1.16239037] Bias: -1.1498408804252318 loss: 0.35221198626591854\n",
            "Round: 2343 Weight: [2.35816806 1.16239196] Bias: -1.1498420608858742 loss: 0.35221198612951654\n",
            "Round: 2344 Weight: [2.35817116 1.16239354] Bias: -1.149843237967178 loss: 0.3522119859938941\n",
            "Round: 2345 Weight: [2.35817426 1.16239511] Bias: -1.1498444116788293 loss: 0.35221198585904695\n",
            "Round: 2346 Weight: [2.35817734 1.16239668] Bias: -1.1498455820304871 loss: 0.35221198572497053\n",
            "Round: 2347 Weight: [2.35818042 1.16239825] Bias: -1.149846749031782 loss: 0.35221198559166056\n",
            "Round: 2348 Weight: [2.35818348 1.16239981] Bias: -1.1498479126923171 loss: 0.35221198545911253\n",
            "Round: 2349 Weight: [2.35818654 1.16240136] Bias: -1.1498490730216677 loss: 0.3522119853273222\n",
            "Round: 2350 Weight: [2.35818959 1.16240292] Bias: -1.149850230029382 loss: 0.3522119851962851\n",
            "Round: 2351 Weight: [2.35819263 1.16240447] Bias: -1.1498513837249804 loss: 0.35221198506599705\n",
            "Round: 2352 Weight: [2.35819566 1.16240601] Bias: -1.1498525341179562 loss: 0.35221198493645367\n",
            "Round: 2353 Weight: [2.35819869 1.16240755] Bias: -1.1498536812177753 loss: 0.3522119848076508\n",
            "Round: 2354 Weight: [2.3582017  1.16240908] Bias: -1.1498548250338765 loss: 0.3522119846795842\n",
            "Round: 2355 Weight: [2.35820471 1.16241061] Bias: -1.1498559655756713 loss: 0.3522119845522495\n",
            "Round: 2356 Weight: [2.35820771 1.16241214] Bias: -1.1498571028525442 loss: 0.35221198442564267\n",
            "Round: 2357 Weight: [2.35821069 1.16241366] Bias: -1.149858236873853 loss: 0.35221198429975953\n",
            "Round: 2358 Weight: [2.35821368 1.16241518] Bias: -1.1498593676489284 loss: 0.35221198417459587\n",
            "Round: 2359 Weight: [2.35821665 1.16241669] Bias: -1.1498604951870741 loss: 0.35221198405014764\n",
            "Round: 2360 Weight: [2.35821961 1.1624182 ] Bias: -1.1498616194975675 loss: 0.35221198392641073\n",
            "Round: 2361 Weight: [2.35822256 1.1624197 ] Bias: -1.1498627405896589 loss: 0.3522119838033811\n",
            "Round: 2362 Weight: [2.35822551 1.1624212 ] Bias: -1.1498638584725722 loss: 0.3522119836810546\n",
            "Round: 2363 Weight: [2.35822845 1.1624227 ] Bias: -1.149864973155505 loss: 0.35221198355942734\n",
            "Round: 2364 Weight: [2.35823138 1.16242419] Bias: -1.1498660846476285 loss: 0.35221198343849525\n",
            "Round: 2365 Weight: [2.3582343  1.16242568] Bias: -1.1498671929580873 loss: 0.3522119833182544\n",
            "Round: 2366 Weight: [2.35823721 1.16242716] Bias: -1.1498682980959996 loss: 0.35221198319870084\n",
            "Round: 2367 Weight: [2.35824012 1.16242864] Bias: -1.1498694000704577 loss: 0.35221198307983054\n",
            "Round: 2368 Weight: [2.35824301 1.16243011] Bias: -1.1498704988905277 loss: 0.3522119829616397\n",
            "Round: 2369 Weight: [2.3582459  1.16243158] Bias: -1.1498715945652498 loss: 0.3522119828441244\n",
            "Round: 2370 Weight: [2.35824878 1.16243305] Bias: -1.1498726871036378 loss: 0.3522119827272807\n",
            "Round: 2371 Weight: [2.35825165 1.16243451] Bias: -1.14987377651468 loss: 0.3522119826111049\n",
            "Round: 2372 Weight: [2.35825451 1.16243597] Bias: -1.149874862807339 loss: 0.3522119824955931\n",
            "Round: 2373 Weight: [2.35825737 1.16243742] Bias: -1.149875945990551 loss: 0.3522119823807415\n",
            "Round: 2374 Weight: [2.35826022 1.16243887] Bias: -1.1498770260732272 loss: 0.3522119822665464\n",
            "Round: 2375 Weight: [2.35826305 1.16244032] Bias: -1.1498781030642529 loss: 0.35221198215300387\n",
            "Round: 2376 Weight: [2.35826588 1.16244176] Bias: -1.149879176972488 loss: 0.3522119820401104\n",
            "Round: 2377 Weight: [2.35826871 1.16244319] Bias: -1.1498802478067671 loss: 0.35221198192786213\n",
            "Round: 2378 Weight: [2.35827152 1.16244463] Bias: -1.149881315575899 loss: 0.35221198181625546\n",
            "Round: 2379 Weight: [2.35827433 1.16244606] Bias: -1.149882380288667 loss: 0.3522119817052866\n",
            "Round: 2380 Weight: [2.35827713 1.16244748] Bias: -1.1498834419538302 loss: 0.35221198159495204\n",
            "Round: 2381 Weight: [2.35827992 1.1624489 ] Bias: -1.1498845005801217 loss: 0.3522119814852481\n",
            "Round: 2382 Weight: [2.3582827  1.16245032] Bias: -1.1498855561762498 loss: 0.3522119813761711\n",
            "Round: 2383 Weight: [2.35828547 1.16245173] Bias: -1.1498866087508977 loss: 0.3522119812677175\n",
            "Round: 2384 Weight: [2.35828824 1.16245314] Bias: -1.1498876583127235 loss: 0.3522119811598839\n",
            "Round: 2385 Weight: [2.358291   1.16245454] Bias: -1.149888704870361 loss: 0.3522119810526665\n",
            "Round: 2386 Weight: [2.35829375 1.16245594] Bias: -1.1498897484324186 loss: 0.35221198094606193\n",
            "Round: 2387 Weight: [2.35829649 1.16245734] Bias: -1.1498907890074803 loss: 0.3522119808400666\n",
            "Round: 2388 Weight: [2.35829922 1.16245873] Bias: -1.1498918266041052 loss: 0.35221198073467713\n",
            "Round: 2389 Weight: [2.35830195 1.16246012] Bias: -1.1498928612308281 loss: 0.35221198062988995\n",
            "Round: 2390 Weight: [2.35830467 1.1624615 ] Bias: -1.149893892896159 loss: 0.35221198052570163\n",
            "Round: 2391 Weight: [2.35830738 1.16246288] Bias: -1.1498949216085839 loss: 0.3522119804221089\n",
            "Round: 2392 Weight: [2.35831009 1.16246426] Bias: -1.149895947376564 loss: 0.352211980319108\n",
            "Round: 2393 Weight: [2.35831278 1.16246563] Bias: -1.1498969702085364 loss: 0.352211980216696\n",
            "Round: 2394 Weight: [2.35831547 1.162467  ] Bias: -1.1498979901129138 loss: 0.3522119801148693\n",
            "Round: 2395 Weight: [2.35831815 1.16246837] Bias: -1.149899007098085 loss: 0.3522119800136244\n",
            "Round: 2396 Weight: [2.35832082 1.16246973] Bias: -1.1499000211724146 loss: 0.3522119799129583\n",
            "Round: 2397 Weight: [2.35832349 1.16247108] Bias: -1.1499010323442431 loss: 0.35221197981286745\n",
            "Round: 2398 Weight: [2.35832615 1.16247244] Bias: -1.1499020406218872 loss: 0.3522119797133486\n",
            "Round: 2399 Weight: [2.3583288  1.16247378] Bias: -1.1499030460136395 loss: 0.35221197961439865\n",
            "Round: 2400 Weight: [2.35833144 1.16247513] Bias: -1.149904048527769 loss: 0.3522119795160142\n",
            "Round: 2401 Weight: [2.35833407 1.16247647] Bias: -1.1499050481725208 loss: 0.3522119794181918\n",
            "Round: 2402 Weight: [2.3583367  1.16247781] Bias: -1.1499060449561165 loss: 0.3522119793209287\n",
            "Round: 2403 Weight: [2.35833932 1.16247914] Bias: -1.1499070388867538 loss: 0.35221197922422137\n",
            "Round: 2404 Weight: [2.35834193 1.16248047] Bias: -1.1499080299726072 loss: 0.35221197912806684\n",
            "Round: 2405 Weight: [2.35834454 1.1624818 ] Bias: -1.1499090182218277 loss: 0.35221197903246176\n",
            "Round: 2406 Weight: [2.35834713 1.16248312] Bias: -1.1499100036425425 loss: 0.352211978937403\n",
            "Round: 2407 Weight: [2.35834972 1.16248444] Bias: -1.1499109862428558 loss: 0.35221197884288763\n",
            "Round: 2408 Weight: [2.35835231 1.16248575] Bias: -1.1499119660308488 loss: 0.3522119787489123\n",
            "Round: 2409 Weight: [2.35835488 1.16248706] Bias: -1.1499129430145787 loss: 0.3522119786554742\n",
            "Round: 2410 Weight: [2.35835745 1.16248837] Bias: -1.1499139172020802 loss: 0.35221197856257\n",
            "Round: 2411 Weight: [2.35836001 1.16248968] Bias: -1.149914888601365 loss: 0.35221197847019675\n",
            "Round: 2412 Weight: [2.35836256 1.16249097] Bias: -1.1499158572204213 loss: 0.3522119783783514\n",
            "Round: 2413 Weight: [2.35836511 1.16249227] Bias: -1.1499168230672148 loss: 0.35221197828703105\n",
            "Round: 2414 Weight: [2.35836765 1.16249356] Bias: -1.1499177861496879 loss: 0.35221197819623246\n",
            "Round: 2415 Weight: [2.35837018 1.16249485] Bias: -1.1499187464757608 loss: 0.3522119781059528\n",
            "Round: 2416 Weight: [2.3583727  1.16249614] Bias: -1.1499197040533302 loss: 0.3522119780161892\n",
            "Round: 2417 Weight: [2.35837522 1.16249742] Bias: -1.149920658890271 loss: 0.35221197792693837\n",
            "Round: 2418 Weight: [2.35837773 1.1624987 ] Bias: -1.1499216109944348 loss: 0.35221197783819774\n",
            "Round: 2419 Weight: [2.35838023 1.16249997] Bias: -1.149922560373651 loss: 0.3522119777499644\n",
            "Round: 2420 Weight: [2.35838272 1.16250124] Bias: -1.1499235070357263 loss: 0.35221197766223505\n",
            "Round: 2421 Weight: [2.35838521 1.16250251] Bias: -1.1499244509884452 loss: 0.35221197757500716\n",
            "Round: 2422 Weight: [2.35838769 1.16250377] Bias: -1.1499253922395698 loss: 0.3522119774882778\n",
            "Round: 2423 Weight: [2.35839017 1.16250503] Bias: -1.1499263307968397 loss: 0.35221197740204396\n",
            "Round: 2424 Weight: [2.35839263 1.16250628] Bias: -1.1499272666679727 loss: 0.35221197731630305\n",
            "Round: 2425 Weight: [2.35839509 1.16250754] Bias: -1.149928199860664 loss: 0.35221197723105213\n",
            "Round: 2426 Weight: [2.35839755 1.16250879] Bias: -1.1499291303825872 loss: 0.3522119771462884\n",
            "Round: 2427 Weight: [2.35839999 1.16251003] Bias: -1.1499300582413932 loss: 0.352211977062009\n",
            "Round: 2428 Weight: [2.35840243 1.16251127] Bias: -1.1499309834447116 loss: 0.3522119769782113\n",
            "Round: 2429 Weight: [2.35840486 1.16251251] Bias: -1.1499319060001498 loss: 0.3522119768948925\n",
            "Round: 2430 Weight: [2.35840729 1.16251374] Bias: -1.1499328259152934 loss: 0.3522119768120498\n",
            "Round: 2431 Weight: [2.3584097  1.16251497] Bias: -1.1499337431977061 loss: 0.3522119767296805\n",
            "Round: 2432 Weight: [2.35841211 1.1625162 ] Bias: -1.1499346578549303 loss: 0.35221197664778203\n",
            "Round: 2433 Weight: [2.35841452 1.16251743] Bias: -1.1499355698944862 loss: 0.35221197656635145\n",
            "Round: 2434 Weight: [2.35841691 1.16251865] Bias: -1.1499364793238727 loss: 0.35221197648538627\n",
            "Round: 2435 Weight: [2.35841931 1.16251986] Bias: -1.149937386150567 loss: 0.35221197640488383\n",
            "Round: 2436 Weight: [2.35842169 1.16252108] Bias: -1.1499382903820254 loss: 0.3522119763248413\n",
            "Round: 2437 Weight: [2.35842406 1.16252229] Bias: -1.149939192025682 loss: 0.35221197624525624\n",
            "Round: 2438 Weight: [2.35842643 1.16252349] Bias: -1.1499400910889503 loss: 0.3522119761661261\n",
            "Round: 2439 Weight: [2.3584288 1.1625247] Bias: -1.149940987579222 loss: 0.35221197608744803\n",
            "Round: 2440 Weight: [2.35843115 1.1625259 ] Bias: -1.1499418815038676 loss: 0.35221197600921966\n",
            "Round: 2441 Weight: [2.3584335  1.16252709] Bias: -1.1499427728702367 loss: 0.3522119759314383\n",
            "Round: 2442 Weight: [2.35843585 1.16252828] Bias: -1.1499436616856578 loss: 0.35221197585410136\n",
            "Round: 2443 Weight: [2.35843818 1.16252947] Bias: -1.1499445479574382 loss: 0.3522119757772065\n",
            "Round: 2444 Weight: [2.35844051 1.16253066] Bias: -1.1499454316928643 loss: 0.35221197570075097\n",
            "Round: 2445 Weight: [2.35844283 1.16253184] Bias: -1.1499463128992016 loss: 0.3522119756247324\n",
            "Round: 2446 Weight: [2.35844515 1.16253302] Bias: -1.1499471915836947 loss: 0.3522119755491481\n",
            "Round: 2447 Weight: [2.35844746 1.1625342 ] Bias: -1.1499480677535676 loss: 0.3522119754739959\n",
            "Round: 2448 Weight: [2.35844976 1.16253537] Bias: -1.1499489414160233 loss: 0.352211975399273\n",
            "Round: 2449 Weight: [2.35845206 1.16253654] Bias: -1.1499498125782441 loss: 0.3522119753249773\n",
            "Round: 2450 Weight: [2.35845435 1.1625377 ] Bias: -1.149950681247392 loss: 0.35221197525110604\n",
            "Round: 2451 Weight: [2.35845663 1.16253887] Bias: -1.1499515474306083 loss: 0.35221197517765696\n",
            "Round: 2452 Weight: [2.35845891 1.16254002] Bias: -1.149952411135014 loss: 0.3522119751046275\n",
            "Round: 2453 Weight: [2.35846118 1.16254118] Bias: -1.1499532723677088 loss: 0.3522119750320154\n",
            "Round: 2454 Weight: [2.35846344 1.16254233] Bias: -1.1499541311357733 loss: 0.3522119749598183\n",
            "Round: 2455 Weight: [2.3584657  1.16254348] Bias: -1.149954987446267 loss: 0.3522119748880338\n",
            "Round: 2456 Weight: [2.35846795 1.16254463] Bias: -1.149955841306229 loss: 0.3522119748166594\n",
            "Round: 2457 Weight: [2.35847019 1.16254577] Bias: -1.1499566927226788 loss: 0.3522119747456929\n",
            "Round: 2458 Weight: [2.35847243 1.16254691] Bias: -1.1499575417026153 loss: 0.3522119746751319\n",
            "Round: 2459 Weight: [2.35847466 1.16254804] Bias: -1.1499583882530175 loss: 0.3522119746049741\n",
            "Round: 2460 Weight: [2.35847689 1.16254918] Bias: -1.1499592323808445 loss: 0.3522119745352173\n",
            "Round: 2461 Weight: [2.3584791  1.16255031] Bias: -1.1499600740930351 loss: 0.3522119744658591\n",
            "Round: 2462 Weight: [2.35848132 1.16255143] Bias: -1.1499609133965083 loss: 0.35221197439689717\n",
            "Round: 2463 Weight: [2.35848352 1.16255256] Bias: -1.1499617502981634 loss: 0.35221197432832935\n",
            "Round: 2464 Weight: [2.35848572 1.16255368] Bias: -1.14996258480488 loss: 0.3522119742601533\n",
            "Round: 2465 Weight: [2.35848792 1.16255479] Bias: -1.1499634169235176 loss: 0.3522119741923668\n",
            "Round: 2466 Weight: [2.3584901  1.16255591] Bias: -1.1499642466609161 loss: 0.35221197412496774\n",
            "Round: 2467 Weight: [2.35849228 1.16255702] Bias: -1.149965074023896 loss: 0.3522119740579538\n",
            "Round: 2468 Weight: [2.35849446 1.16255812] Bias: -1.149965899019258 loss: 0.3522119739913228\n",
            "Round: 2469 Weight: [2.35849663 1.16255923] Bias: -1.1499667216537834 loss: 0.35221197392507253\n",
            "Round: 2470 Weight: [2.35849879 1.16256033] Bias: -1.1499675419342341 loss: 0.3522119738592007\n",
            "Round: 2471 Weight: [2.35850094 1.16256143] Bias: -1.1499683598673525 loss: 0.35221197379370545\n",
            "Round: 2472 Weight: [2.35850309 1.16256252] Bias: -1.1499691754598618 loss: 0.3522119737285845\n",
            "Round: 2473 Weight: [2.35850524 1.16256361] Bias: -1.1499699887184656 loss: 0.35221197366383544\n",
            "Round: 2474 Weight: [2.35850737 1.1625647 ] Bias: -1.1499707996498485 loss: 0.3522119735994566\n",
            "Round: 2475 Weight: [2.35850951 1.16256578] Bias: -1.149971608260676 loss: 0.3522119735354455\n",
            "Round: 2476 Weight: [2.35851163 1.16256687] Bias: -1.149972414557594 loss: 0.35221197347180017\n",
            "Round: 2477 Weight: [2.35851375 1.16256794] Bias: -1.14997321854723 loss: 0.3522119734085185\n",
            "Round: 2478 Weight: [2.35851586 1.16256902] Bias: -1.149974020236192 loss: 0.3522119733455985\n",
            "Round: 2479 Weight: [2.35851797 1.16257009] Bias: -1.1499748196310695 loss: 0.352211973283038\n",
            "Round: 2480 Weight: [2.35852007 1.16257116] Bias: -1.1499756167384325 loss: 0.3522119732208351\n",
            "Round: 2481 Weight: [2.35852217 1.16257223] Bias: -1.1499764115648325 loss: 0.35221197315898745\n",
            "Round: 2482 Weight: [2.35852425 1.16257329] Bias: -1.1499772041168024 loss: 0.3522119730974932\n",
            "Round: 2483 Weight: [2.35852634 1.16257435] Bias: -1.149977994400856 loss: 0.35221197303635043\n",
            "Round: 2484 Weight: [2.35852842 1.16257541] Bias: -1.1499787824234882 loss: 0.35221197297555695\n",
            "Round: 2485 Weight: [2.35853049 1.16257647] Bias: -1.149979568191176 loss: 0.3522119729151109\n",
            "Round: 2486 Weight: [2.35853255 1.16257752] Bias: -1.1499803517103773 loss: 0.35221197285501027\n",
            "Round: 2487 Weight: [2.35853461 1.16257856] Bias: -1.1499811329875316 loss: 0.352211972795253\n",
            "Round: 2488 Weight: [2.35853666 1.16257961] Bias: -1.14998191202906 loss: 0.3522119727358373\n",
            "Round: 2489 Weight: [2.35853871 1.16258065] Bias: -1.149982688841365 loss: 0.35221197267676096\n",
            "Round: 2490 Weight: [2.35854075 1.16258169] Bias: -1.1499834634308306 loss: 0.3522119726180223\n",
            "Round: 2491 Weight: [2.35854279 1.16258273] Bias: -1.149984235803823 loss: 0.3522119725596192\n",
            "Round: 2492 Weight: [2.35854482 1.16258376] Bias: -1.14998500596669 loss: 0.35221197250154973\n",
            "Round: 2493 Weight: [2.35854684 1.16258479] Bias: -1.1499857739257608 loss: 0.3522119724438122\n",
            "Round: 2494 Weight: [2.35854886 1.16258582] Bias: -1.1499865396873468 loss: 0.3522119723864046\n",
            "Round: 2495 Weight: [2.35855087 1.16258684] Bias: -1.1499873032577412 loss: 0.35221197232932494\n",
            "Round: 2496 Weight: [2.35855288 1.16258787] Bias: -1.149988064643219 loss: 0.35221197227257145\n",
            "Round: 2497 Weight: [2.35855488 1.16258889] Bias: -1.1499888238500375 loss: 0.35221197221614226\n",
            "Round: 2498 Weight: [2.35855688 1.1625899 ] Bias: -1.1499895808844358 loss: 0.3522119721600354\n",
            "Round: 2499 Weight: [2.35855887 1.16259091] Bias: -1.1499903357526353 loss: 0.35221197210424926\n",
            "Round: 2500 Weight: [2.35856085 1.16259192] Bias: -1.1499910884608393 loss: 0.35221197204878185\n",
            "Round: 2501 Weight: [2.35856283 1.16259293] Bias: -1.1499918390152335 loss: 0.35221197199363136\n",
            "Round: 2502 Weight: [2.3585648  1.16259394] Bias: -1.1499925874219858 loss: 0.352211971938796\n",
            "Round: 2503 Weight: [2.35856677 1.16259494] Bias: -1.1499933336872465 loss: 0.35221197188427394\n",
            "Round: 2504 Weight: [2.35856873 1.16259594] Bias: -1.149994077817148 loss: 0.35221197183006336\n",
            "Round: 2505 Weight: [2.35857069 1.16259693] Bias: -1.1499948198178054 loss: 0.3522119717761626\n",
            "Round: 2506 Weight: [2.35857264 1.16259792] Bias: -1.1499955596953162 loss: 0.3522119717225698\n",
            "Round: 2507 Weight: [2.35857458 1.16259891] Bias: -1.1499962974557603 loss: 0.35221197166928325\n",
            "Round: 2508 Weight: [2.35857652 1.1625999 ] Bias: -1.1499970331052003 loss: 0.35221197161630113\n",
            "Round: 2509 Weight: [2.35857845 1.16260089] Bias: -1.1499977666496812 loss: 0.3522119715636218\n",
            "Round: 2510 Weight: [2.35858038 1.16260187] Bias: -1.149998498095231 loss: 0.3522119715112434\n",
            "Round: 2511 Weight: [2.3585823  1.16260285] Bias: -1.1499992274478599 loss: 0.35221197145916433\n",
            "Round: 2512 Weight: [2.35858422 1.16260382] Bias: -1.1499999547135613 loss: 0.35221197140738275\n",
            "Round: 2513 Weight: [2.35858613 1.16260479] Bias: -1.1500006798983113 loss: 0.3522119713558971\n",
            "Round: 2514 Weight: [2.35858804 1.16260576] Bias: -1.150001403008069 loss: 0.35221197130470555\n",
            "Round: 2515 Weight: [2.35858994 1.16260673] Bias: -1.1500021240487759 loss: 0.35221197125380654\n",
            "Round: 2516 Weight: [2.35859183 1.1626077 ] Bias: -1.1500028430263571 loss: 0.35221197120319847\n",
            "Round: 2517 Weight: [2.35859372 1.16260866] Bias: -1.1500035599467204 loss: 0.35221197115287933\n",
            "Round: 2518 Weight: [2.35859561 1.16260962] Bias: -1.1500042748157566 loss: 0.35221197110284785\n",
            "Round: 2519 Weight: [2.35859749 1.16261058] Bias: -1.1500049876393397 loss: 0.3522119710531022\n",
            "Round: 2520 Weight: [2.35859936 1.16261153] Bias: -1.1500056984233267 loss: 0.3522119710036408\n",
            "Round: 2521 Weight: [2.35860123 1.16261248] Bias: -1.150006407173558 loss: 0.352211970954462\n",
            "Round: 2522 Weight: [2.35860309 1.16261343] Bias: -1.1500071138958572 loss: 0.3522119709055641\n",
            "Round: 2523 Weight: [2.35860495 1.16261437] Bias: -1.1500078185960312 loss: 0.3522119708569458\n",
            "Round: 2524 Weight: [2.3586068  1.16261532] Bias: -1.1500085212798703 loss: 0.3522119708086051\n",
            "Round: 2525 Weight: [2.35860865 1.16261626] Bias: -1.150009221953148 loss: 0.35221197076054056\n",
            "Round: 2526 Weight: [2.35861049 1.16261719] Bias: -1.1500099206216212 loss: 0.35221197071275073\n",
            "Round: 2527 Weight: [2.35861233 1.16261813] Bias: -1.150010617291031 loss: 0.35221197066523396\n",
            "Round: 2528 Weight: [2.35861416 1.16261906] Bias: -1.150011311967101 loss: 0.35221197061798876\n",
            "Round: 2529 Weight: [2.35861598 1.16261999] Bias: -1.150012004655539 loss: 0.35221197057101333\n",
            "Round: 2530 Weight: [2.3586178  1.16262092] Bias: -1.1500126953620367 loss: 0.3522119705243064\n",
            "Round: 2531 Weight: [2.35861962 1.16262184] Bias: -1.1500133840922686 loss: 0.3522119704778665\n",
            "Round: 2532 Weight: [2.35862143 1.16262276] Bias: -1.1500140708518936 loss: 0.35221197043169167\n",
            "Round: 2533 Weight: [2.35862323 1.16262368] Bias: -1.150014755646554 loss: 0.3522119703857806\n",
            "Round: 2534 Weight: [2.35862503 1.1626246 ] Bias: -1.1500154384818766 loss: 0.3522119703401321\n",
            "Round: 2535 Weight: [2.35862683 1.16262551] Bias: -1.150016119363471 loss: 0.3522119702947442\n",
            "Round: 2536 Weight: [2.35862862 1.16262642] Bias: -1.1500167982969318 loss: 0.35221197024961576\n",
            "Round: 2537 Weight: [2.3586304  1.16262733] Bias: -1.1500174752878367 loss: 0.3522119702047451\n",
            "Round: 2538 Weight: [2.35863218 1.16262824] Bias: -1.150018150341748 loss: 0.3522119701601309\n",
            "Round: 2539 Weight: [2.35863396 1.16262914] Bias: -1.1500188234642115 loss: 0.3522119701157715\n",
            "Round: 2540 Weight: [2.35863572 1.16263004] Bias: -1.1500194946607576 loss: 0.3522119700716656\n",
            "Round: 2541 Weight: [2.35863749 1.16263094] Bias: -1.1500201639369008 loss: 0.3522119700278116\n",
            "Round: 2542 Weight: [2.35863925 1.16263184] Bias: -1.1500208312981395 loss: 0.35221196998420834\n",
            "Round: 2543 Weight: [2.358641   1.16263273] Bias: -1.1500214967499562 loss: 0.3522119699408541\n",
            "Round: 2544 Weight: [2.35864275 1.16263362] Bias: -1.1500221602978185 loss: 0.35221196989774756\n",
            "Round: 2545 Weight: [2.35864449 1.16263451] Bias: -1.1500228219471773 loss: 0.3522119698548873\n",
            "Round: 2546 Weight: [2.35864623 1.16263539] Bias: -1.1500234817034685 loss: 0.35221196981227193\n",
            "Round: 2547 Weight: [2.35864797 1.16263628] Bias: -1.1500241395721122 loss: 0.35221196976989994\n",
            "Round: 2548 Weight: [2.3586497  1.16263716] Bias: -1.1500247955585132 loss: 0.3522119697277702\n",
            "Round: 2549 Weight: [2.35865142 1.16263803] Bias: -1.1500254496680606 loss: 0.3522119696858811\n",
            "Round: 2550 Weight: [2.35865314 1.16263891] Bias: -1.150026101906128 loss: 0.35221196964423135\n",
            "Round: 2551 Weight: [2.35865485 1.16263978] Bias: -1.1500267522780736 loss: 0.3522119696028195\n",
            "Round: 2552 Weight: [2.35865656 1.16264065] Bias: -1.1500274007892404 loss: 0.35221196956164436\n",
            "Round: 2553 Weight: [2.35865827 1.16264152] Bias: -1.1500280474449558 loss: 0.35221196952070427\n",
            "Round: 2554 Weight: [2.35865997 1.16264238] Bias: -1.1500286922505323 loss: 0.3522119694799982\n",
            "Round: 2555 Weight: [2.35866166 1.16264325] Bias: -1.150029335211267 loss: 0.3522119694395247\n",
            "Round: 2556 Weight: [2.35866335 1.16264411] Bias: -1.1500299763324415 loss: 0.35221196939928245\n",
            "Round: 2557 Weight: [2.35866504 1.16264497] Bias: -1.150030615619323 loss: 0.3522119693592702\n",
            "Round: 2558 Weight: [2.35866672 1.16264582] Bias: -1.1500312530771628 loss: 0.3522119693194863\n",
            "Round: 2559 Weight: [2.35866839 1.16264667] Bias: -1.1500318887111975 loss: 0.3522119692799299\n",
            "Round: 2560 Weight: [2.35867006 1.16264752] Bias: -1.150032522526649 loss: 0.3522119692405995\n",
            "Round: 2561 Weight: [2.35867173 1.16264837] Bias: -1.1500331545287237 loss: 0.35221196920149367\n",
            "Round: 2562 Weight: [2.35867339 1.16264922] Bias: -1.1500337847226132 loss: 0.3522119691626114\n",
            "Round: 2563 Weight: [2.35867505 1.16265006] Bias: -1.1500344131134943 loss: 0.3522119691239513\n",
            "Round: 2564 Weight: [2.3586767 1.1626509] Bias: -1.150035039706529 loss: 0.35221196908551194\n",
            "Round: 2565 Weight: [2.35867835 1.16265174] Bias: -1.1500356645068646 loss: 0.3522119690472922\n",
            "Round: 2566 Weight: [2.35867999 1.16265258] Bias: -1.1500362875196333 loss: 0.3522119690092908\n",
            "Round: 2567 Weight: [2.35868163 1.16265341] Bias: -1.1500369087499527 loss: 0.35221196897150664\n",
            "Round: 2568 Weight: [2.35868326 1.16265424] Bias: -1.150037528202926 loss: 0.35221196893393836\n",
            "Round: 2569 Weight: [2.35868489 1.16265507] Bias: -1.1500381458836417 loss: 0.35221196889658457\n",
            "Round: 2570 Weight: [2.35868651 1.1626559 ] Bias: -1.1500387617971735 loss: 0.3522119688594442\n",
            "Round: 2571 Weight: [2.35868813 1.16265672] Bias: -1.1500393759485805 loss: 0.3522119688225162\n",
            "Round: 2572 Weight: [2.35868974 1.16265754] Bias: -1.1500399883429075 loss: 0.35221196878579897\n",
            "Round: 2573 Weight: [2.35869135 1.16265836] Bias: -1.150040598985185 loss: 0.35221196874929156\n",
            "Round: 2574 Weight: [2.35869296 1.16265918] Bias: -1.1500412078804287 loss: 0.3522119687129928\n",
            "Round: 2575 Weight: [2.35869456 1.16265999] Bias: -1.1500418150336402 loss: 0.3522119686769013\n",
            "Round: 2576 Weight: [2.35869615 1.16266081] Bias: -1.1500424204498065 loss: 0.35221196864101606\n",
            "Round: 2577 Weight: [2.35869774 1.16266162] Bias: -1.1500430241339006 loss: 0.35221196860533593\n",
            "Round: 2578 Weight: [2.35869933 1.16266242] Bias: -1.150043626090881 loss: 0.3522119685698596\n",
            "Round: 2579 Weight: [2.35870091 1.16266323] Bias: -1.1500442263256923 loss: 0.35221196853458586\n",
            "Round: 2580 Weight: [2.35870249 1.16266403] Bias: -1.1500448248432644 loss: 0.35221196849951364\n",
            "Round: 2581 Weight: [2.35870406 1.16266483] Bias: -1.1500454216485136 loss: 0.3522119684646419\n",
            "Round: 2582 Weight: [2.35870563 1.16266563] Bias: -1.150046016746342 loss: 0.3522119684299693\n",
            "Round: 2583 Weight: [2.3587072  1.16266643] Bias: -1.1500466101416373 loss: 0.3522119683954948\n",
            "Round: 2584 Weight: [2.35870876 1.16266722] Bias: -1.1500472018392736 loss: 0.35221196836121726\n",
            "Round: 2585 Weight: [2.35871031 1.16266801] Bias: -1.1500477918441105 loss: 0.3522119683271356\n",
            "Round: 2586 Weight: [2.35871186 1.1626688 ] Bias: -1.1500483801609944 loss: 0.35221196829324863\n",
            "Round: 2587 Weight: [2.35871341 1.16266959] Bias: -1.1500489667947575 loss: 0.3522119682595552\n",
            "Round: 2588 Weight: [2.35871495 1.16267038] Bias: -1.1500495517502178 loss: 0.3522119682260543\n",
            "Round: 2589 Weight: [2.35871649 1.16267116] Bias: -1.1500501350321801 loss: 0.35221196819274475\n",
            "Round: 2590 Weight: [2.35871802 1.16267194] Bias: -1.1500507166454348 loss: 0.3522119681596256\n",
            "Round: 2591 Weight: [2.35871955 1.16267272] Bias: -1.1500512965947591 loss: 0.3522119681266956\n",
            "Round: 2592 Weight: [2.35872107 1.16267349] Bias: -1.1500518748849162 loss: 0.35221196809395366\n",
            "Round: 2593 Weight: [2.35872259 1.16267427] Bias: -1.1500524515206556 loss: 0.3522119680613989\n",
            "Round: 2594 Weight: [2.35872411 1.16267504] Bias: -1.1500530265067135 loss: 0.35221196802903004\n",
            "Round: 2595 Weight: [2.35872562 1.16267581] Bias: -1.1500535998478123 loss: 0.3522119679968462\n",
            "Round: 2596 Weight: [2.35872713 1.16267658] Bias: -1.150054171548661 loss: 0.352211967964846\n",
            "Round: 2597 Weight: [2.35872863 1.16267734] Bias: -1.1500547416139548 loss: 0.3522119679330288\n",
            "Round: 2598 Weight: [2.35873013 1.1626781 ] Bias: -1.1500553100483757 loss: 0.3522119679013933\n",
            "Round: 2599 Weight: [2.35873162 1.16267886] Bias: -1.1500558768565923 loss: 0.35221196786993864\n",
            "Round: 2600 Weight: [2.35873311 1.16267962] Bias: -1.1500564420432597 loss: 0.35221196783866354\n",
            "Round: 2601 Weight: [2.3587346  1.16268038] Bias: -1.15005700561302 loss: 0.35221196780756725\n",
            "Round: 2602 Weight: [2.35873608 1.16268113] Bias: -1.1500575675705011 loss: 0.3522119677766486\n",
            "Round: 2603 Weight: [2.35873756 1.16268188] Bias: -1.1500581279203188 loss: 0.3522119677459064\n",
            "Round: 2604 Weight: [2.35873903 1.16268263] Bias: -1.150058686667075 loss: 0.35221196771533997\n",
            "Round: 2605 Weight: [2.3587405  1.16268338] Bias: -1.1500592438153585 loss: 0.3522119676849481\n",
            "Round: 2606 Weight: [2.35874196 1.16268413] Bias: -1.1500597993697448 loss: 0.35221196765472995\n",
            "Round: 2607 Weight: [2.35874342 1.16268487] Bias: -1.1500603533347966 loss: 0.3522119676246844\n",
            "Round: 2608 Weight: [2.35874488 1.16268561] Bias: -1.1500609057150635 loss: 0.35221196759481044\n",
            "Round: 2609 Weight: [2.35874633 1.16268635] Bias: -1.1500614565150817 loss: 0.35221196756510714\n",
            "Round: 2610 Weight: [2.35874778 1.16268709] Bias: -1.150062005739375 loss: 0.3522119675355736\n",
            "Round: 2611 Weight: [2.35874922 1.16268782] Bias: -1.1500625533924536 loss: 0.35221196750620876\n",
            "Round: 2612 Weight: [2.35875066 1.16268856] Bias: -1.150063099478815 loss: 0.3522119674770116\n",
            "Round: 2613 Weight: [2.3587521  1.16268929] Bias: -1.1500636440029441 loss: 0.35221196744798133\n",
            "Round: 2614 Weight: [2.35875353 1.16269002] Bias: -1.1500641869693127 loss: 0.35221196741911687\n",
            "Round: 2615 Weight: [2.35875495 1.16269074] Bias: -1.1500647283823795 loss: 0.3522119673904173\n",
            "Round: 2616 Weight: [2.35875638 1.16269147] Bias: -1.150065268246591 loss: 0.35221196736188176\n",
            "Round: 2617 Weight: [2.3587578  1.16269219] Bias: -1.1500658065663807 loss: 0.3522119673335091\n",
            "Round: 2618 Weight: [2.35875921 1.16269291] Bias: -1.1500663433461693 loss: 0.35221196730529863\n",
            "Round: 2619 Weight: [2.35876062 1.16269363] Bias: -1.150066878590365 loss: 0.3522119672772493\n",
            "Round: 2620 Weight: [2.35876203 1.16269434] Bias: -1.150067412303363 loss: 0.3522119672493603\n",
            "Round: 2621 Weight: [2.35876343 1.16269506] Bias: -1.1500679444895463 loss: 0.35221196722163045\n",
            "Round: 2622 Weight: [2.35876483 1.16269577] Bias: -1.1500684751532853 loss: 0.3522119671940591\n",
            "Round: 2623 Weight: [2.35876623 1.16269648] Bias: -1.1500690042989377 loss: 0.3522119671666452\n",
            "Round: 2624 Weight: [2.35876762 1.16269719] Bias: -1.150069531930849 loss: 0.3522119671393879\n",
            "Round: 2625 Weight: [2.358769   1.16269789] Bias: -1.1500700580533518 loss: 0.3522119671122865\n",
            "Round: 2626 Weight: [2.35877039 1.1626986 ] Bias: -1.1500705826707667 loss: 0.35221196708533975\n",
            "Round: 2627 Weight: [2.35877177 1.1626993 ] Bias: -1.1500711057874018 loss: 0.35221196705854696\n",
            "Round: 2628 Weight: [2.35877314 1.1627    ] Bias: -1.1500716274075526 loss: 0.3522119670319072\n",
            "Round: 2629 Weight: [2.35877451 1.1627007 ] Bias: -1.1500721475355027 loss: 0.35221196700541973\n",
            "Round: 2630 Weight: [2.35877588 1.16270139] Bias: -1.1500726661755232 loss: 0.3522119669790835\n",
            "Round: 2631 Weight: [2.35877724 1.16270209] Bias: -1.150073183331873 loss: 0.35221196695289775\n",
            "Round: 2632 Weight: [2.3587786  1.16270278] Bias: -1.1500736990087985 loss: 0.3522119669268615\n",
            "Round: 2633 Weight: [2.35877996 1.16270347] Bias: -1.1500742132105346 loss: 0.3522119669009741\n",
            "Round: 2634 Weight: [2.35878131 1.16270416] Bias: -1.1500747259413036 loss: 0.35221196687523454\n",
            "Round: 2635 Weight: [2.35878266 1.16270484] Bias: -1.1500752372053156 loss: 0.3522119668496421\n",
            "Round: 2636 Weight: [2.358784   1.16270553] Bias: -1.150075747006769 loss: 0.3522119668241958\n",
            "Round: 2637 Weight: [2.35878534 1.16270621] Bias: -1.15007625534985 loss: 0.3522119667988948\n",
            "Round: 2638 Weight: [2.35878667 1.16270689] Bias: -1.1500767622387327 loss: 0.35221196677373845\n",
            "Round: 2639 Weight: [2.35878801 1.16270757] Bias: -1.1500772676775795 loss: 0.3522119667487257\n",
            "Round: 2640 Weight: [2.35878934 1.16270825] Bias: -1.1500777716705404 loss: 0.35221196672385596\n",
            "Round: 2641 Weight: [2.35879066 1.16270892] Bias: -1.1500782742217541 loss: 0.35221196669912813\n",
            "Round: 2642 Weight: [2.35879198 1.16270959] Bias: -1.150078775335347 loss: 0.35221196667454163\n",
            "Round: 2643 Weight: [2.3587933  1.16271026] Bias: -1.1500792750154338 loss: 0.35221196665009574\n",
            "Round: 2644 Weight: [2.35879461 1.16271093] Bias: -1.1500797732661177 loss: 0.3522119666257893\n",
            "Round: 2645 Weight: [2.35879592 1.1627116 ] Bias: -1.1500802700914896 loss: 0.3522119666016217\n",
            "Round: 2646 Weight: [2.35879723 1.16271226] Bias: -1.1500807654956293 loss: 0.3522119665775923\n",
            "Round: 2647 Weight: [2.35879853 1.16271293] Bias: -1.1500812594826044 loss: 0.3522119665537\n",
            "Round: 2648 Weight: [2.35879983 1.16271359] Bias: -1.150081752056471 loss: 0.3522119665299444\n",
            "Round: 2649 Weight: [2.35880112 1.16271425] Bias: -1.1500822432212736 loss: 0.35221196650632436\n",
            "Round: 2650 Weight: [2.35880241 1.1627149 ] Bias: -1.150082732981045 loss: 0.3522119664828393\n",
            "Round: 2651 Weight: [2.3588037  1.16271556] Bias: -1.150083221339807 loss: 0.3522119664594883\n",
            "Round: 2652 Weight: [2.35880498 1.16271621] Bias: -1.1500837083015687 loss: 0.35221196643627084\n",
            "Round: 2653 Weight: [2.35880626 1.16271686] Bias: -1.150084193870329 loss: 0.3522119664131859\n",
            "Round: 2654 Weight: [2.35880754 1.16271751] Bias: -1.1500846780500749 loss: 0.35221196639023283\n",
            "Round: 2655 Weight: [2.35880881 1.16271816] Bias: -1.1500851608447815 loss: 0.35221196636741103\n",
            "Round: 2656 Weight: [2.35881008 1.16271881] Bias: -1.1500856422584131 loss: 0.35221196634471946\n",
            "Round: 2657 Weight: [2.35881135 1.16271945] Bias: -1.1500861222949224 loss: 0.35221196632215757\n",
            "Round: 2658 Weight: [2.35881261 1.16272009] Bias: -1.1500866009582507 loss: 0.3522119662997245\n",
            "Round: 2659 Weight: [2.35881387 1.16272073] Bias: -1.150087078252328 loss: 0.3522119662774197\n",
            "Round: 2660 Weight: [2.35881512 1.16272137] Bias: -1.1500875541810736 loss: 0.35221196625524226\n",
            "Round: 2661 Weight: [2.35881637 1.16272201] Bias: -1.1500880287483946 loss: 0.35221196623319145\n",
            "Round: 2662 Weight: [2.35881762 1.16272265] Bias: -1.1500885019581877 loss: 0.35221196621126666\n",
            "Round: 2663 Weight: [2.35881886 1.16272328] Bias: -1.150088973814338 loss: 0.35221196618946704\n",
            "Round: 2664 Weight: [2.3588201  1.16272391] Bias: -1.15008944432072 loss: 0.35221196616779193\n",
            "Round: 2665 Weight: [2.35882134 1.16272454] Bias: -1.1500899134811964 loss: 0.35221196614624084\n",
            "Round: 2666 Weight: [2.35882257 1.16272517] Bias: -1.1500903812996193 loss: 0.35221196612481265\n",
            "Round: 2667 Weight: [2.3588238  1.16272579] Bias: -1.1500908477798295 loss: 0.35221196610350697\n",
            "Round: 2668 Weight: [2.35882503 1.16272642] Bias: -1.1500913129256571 loss: 0.352211966082323\n",
            "Round: 2669 Weight: [2.35882625 1.16272704] Bias: -1.150091776740921 loss: 0.35221196606126004\n",
            "Round: 2670 Weight: [2.35882747 1.16272766] Bias: -1.150092239229429 loss: 0.35221196604031735\n",
            "Round: 2671 Weight: [2.35882869 1.16272828] Bias: -1.1500927003949786 loss: 0.3522119660194944\n",
            "Round: 2672 Weight: [2.3588299 1.1627289] Bias: -1.1500931602413558 loss: 0.3522119659987903\n",
            "Round: 2673 Weight: [2.35883111 1.16272951] Bias: -1.1500936187723358 loss: 0.3522119659782044\n",
            "Round: 2674 Weight: [2.35883231 1.16273013] Bias: -1.1500940759916836 loss: 0.3522119659577363\n",
            "Round: 2675 Weight: [2.35883351 1.16273074] Bias: -1.1500945319031526 loss: 0.3522119659373849\n",
            "Round: 2676 Weight: [2.35883471 1.16273135] Bias: -1.150094986510486 loss: 0.3522119659171499\n",
            "Round: 2677 Weight: [2.35883591 1.16273196] Bias: -1.150095439817416 loss: 0.35221196589703035\n",
            "Round: 2678 Weight: [2.3588371  1.16273256] Bias: -1.1500958918276643 loss: 0.3522119658770259\n",
            "Round: 2679 Weight: [2.35883829 1.16273317] Bias: -1.1500963425449418 loss: 0.35221196585713566\n",
            "Round: 2680 Weight: [2.35883947 1.16273377] Bias: -1.150096791972949 loss: 0.352211965837359\n",
            "Round: 2681 Weight: [2.35884065 1.16273437] Bias: -1.1500972401153755 loss: 0.3522119658176953\n",
            "Round: 2682 Weight: [2.35884183 1.16273497] Bias: -1.1500976869759003 loss: 0.352211965798144\n",
            "Round: 2683 Weight: [2.35884301 1.16273557] Bias: -1.1500981325581923 loss: 0.3522119657787044\n",
            "Round: 2684 Weight: [2.35884418 1.16273617] Bias: -1.1500985768659093 loss: 0.35221196575937574\n",
            "Round: 2685 Weight: [2.35884534 1.16273676] Bias: -1.1500990199026992 loss: 0.35221196574015756\n",
            "Round: 2686 Weight: [2.35884651 1.16273735] Bias: -1.1500994616721991 loss: 0.3522119657210491\n",
            "Round: 2687 Weight: [2.35884767 1.16273794] Bias: -1.1500999021780356 loss: 0.3522119657020498\n",
            "Round: 2688 Weight: [2.35884883 1.16273853] Bias: -1.1501003414238251 loss: 0.35221196568315916\n",
            "Round: 2689 Weight: [2.35884998 1.16273912] Bias: -1.1501007794131737 loss: 0.3522119656643763\n",
            "Round: 2690 Weight: [2.35885113 1.16273971] Bias: -1.150101216149677 loss: 0.3522119656457008\n",
            "Round: 2691 Weight: [2.35885228 1.16274029] Bias: -1.1501016516369205 loss: 0.35221196562713186\n",
            "Round: 2692 Weight: [2.35885343 1.16274087] Bias: -1.1501020858784792 loss: 0.3522119656086691\n",
            "Round: 2693 Weight: [2.35885457 1.16274146] Bias: -1.150102518877918 loss: 0.3522119655903118\n",
            "Round: 2694 Weight: [2.35885571 1.16274204] Bias: -1.1501029506387914 loss: 0.3522119655720593\n",
            "Round: 2695 Weight: [2.35885684 1.16274261] Bias: -1.1501033811646442 loss: 0.3522119655539111\n",
            "Round: 2696 Weight: [2.35885797 1.16274319] Bias: -1.1501038104590104 loss: 0.35221196553586664\n",
            "Round: 2697 Weight: [2.3588591  1.16274376] Bias: -1.1501042385254145 loss: 0.3522119655179251\n",
            "Round: 2698 Weight: [2.35886023 1.16274434] Bias: -1.1501046653673705 loss: 0.3522119655000862\n",
            "Round: 2699 Weight: [2.35886135 1.16274491] Bias: -1.1501050909883823 loss: 0.3522119654823491\n",
            "Round: 2700 Weight: [2.35886247 1.16274548] Bias: -1.1501055153919442 loss: 0.3522119654647134\n",
            "Round: 2701 Weight: [2.35886358 1.16274604] Bias: -1.1501059385815398 loss: 0.3522119654471783\n",
            "Round: 2702 Weight: [2.35886469 1.16274661] Bias: -1.1501063605606434 loss: 0.3522119654297435\n",
            "Round: 2703 Weight: [2.3588658  1.16274718] Bias: -1.150106781332719 loss: 0.3522119654124082\n",
            "Round: 2704 Weight: [2.35886691 1.16274774] Bias: -1.1501072009012208 loss: 0.352211965395172\n",
            "Round: 2705 Weight: [2.35886801 1.1627483 ] Bias: -1.1501076192695927 loss: 0.35221196537803423\n",
            "Round: 2706 Weight: [2.35886911 1.16274886] Bias: -1.1501080364412695 loss: 0.3522119653609943\n",
            "Round: 2707 Weight: [2.35887021 1.16274942] Bias: -1.1501084524196754 loss: 0.35221196534405175\n",
            "Round: 2708 Weight: [2.3588713  1.16274997] Bias: -1.1501088672082254 loss: 0.352211965327206\n",
            "Round: 2709 Weight: [2.35887239 1.16275053] Bias: -1.1501092808103244 loss: 0.35221196531045645\n",
            "Round: 2710 Weight: [2.35887348 1.16275108] Bias: -1.1501096932293675 loss: 0.3522119652938026\n",
            "Round: 2711 Weight: [2.35887456 1.16275164] Bias: -1.1501101044687403 loss: 0.35221196527724385\n",
            "Round: 2712 Weight: [2.35887564 1.16275219] Bias: -1.1501105145318185 loss: 0.3522119652607797\n",
            "Round: 2713 Weight: [2.35887672 1.16275273] Bias: -1.1501109234219682 loss: 0.35221196524440956\n",
            "Round: 2714 Weight: [2.3588778  1.16275328] Bias: -1.150111331142546 loss: 0.3522119652281329\n",
            "Round: 2715 Weight: [2.35887887 1.16275383] Bias: -1.1501117376968986 loss: 0.3522119652119493\n",
            "Round: 2716 Weight: [2.35887994 1.16275437] Bias: -1.1501121430883634 loss: 0.35221196519585807\n",
            "Round: 2717 Weight: [2.358881   1.16275491] Bias: -1.1501125473202682 loss: 0.3522119651798588\n",
            "Round: 2718 Weight: [2.35888207 1.16275545] Bias: -1.150112950395931 loss: 0.352211965163951\n",
            "Round: 2719 Weight: [2.35888312 1.16275599] Bias: -1.1501133523186606 loss: 0.35221196514813397\n",
            "Round: 2720 Weight: [2.35888418 1.16275653] Bias: -1.150113753091756 loss: 0.35221196513240727\n",
            "Round: 2721 Weight: [2.35888523 1.16275707] Bias: -1.1501141527185073 loss: 0.35221196511677044\n",
            "Round: 2722 Weight: [2.35888628 1.1627576 ] Bias: -1.1501145512021944 loss: 0.3522119651012229\n",
            "Round: 2723 Weight: [2.35888733 1.16275814] Bias: -1.1501149485460886 loss: 0.3522119650857642\n",
            "Round: 2724 Weight: [2.35888838 1.16275867] Bias: -1.1501153447534513 loss: 0.3522119650703938\n",
            "Round: 2725 Weight: [2.35888942 1.1627592 ] Bias: -1.1501157398275348 loss: 0.3522119650551111\n",
            "Round: 2726 Weight: [2.35889046 1.16275973] Bias: -1.150116133771582 loss: 0.35221196503991586\n",
            "Round: 2727 Weight: [2.35889149 1.16276025] Bias: -1.1501165265888265 loss: 0.35221196502480734\n",
            "Round: 2728 Weight: [2.35889252 1.16276078] Bias: -1.1501169182824926 loss: 0.35221196500978513\n",
            "Round: 2729 Weight: [2.35889355 1.1627613 ] Bias: -1.1501173088557957 loss: 0.3522119649948487\n",
            "Round: 2730 Weight: [2.35889458 1.16276183] Bias: -1.1501176983119414 loss: 0.3522119649799977\n",
            "Round: 2731 Weight: [2.3588956  1.16276235] Bias: -1.1501180866541265 loss: 0.35221196496523133\n",
            "Round: 2732 Weight: [2.35889662 1.16276287] Bias: -1.1501184738855388 loss: 0.35221196495054935\n",
            "Round: 2733 Weight: [2.35889764 1.16276339] Bias: -1.1501188600093566 loss: 0.3522119649359514\n",
            "Round: 2734 Weight: [2.35889866 1.1627639 ] Bias: -1.1501192450287492 loss: 0.3522119649214367\n",
            "Round: 2735 Weight: [2.35889967 1.16276442] Bias: -1.150119628946877 loss: 0.3522119649070049\n",
            "Round: 2736 Weight: [2.35890068 1.16276493] Bias: -1.150120011766891 loss: 0.35221196489265555\n",
            "Round: 2737 Weight: [2.35890168 1.16276544] Bias: -1.1501203934919337 loss: 0.35221196487838813\n",
            "Round: 2738 Weight: [2.35890269 1.16276595] Bias: -1.1501207741251382 loss: 0.3522119648642023\n",
            "Round: 2739 Weight: [2.35890369 1.16276646] Bias: -1.150121153669629 loss: 0.3522119648500975\n",
            "Round: 2740 Weight: [2.35890469 1.16276697] Bias: -1.150121532128521 loss: 0.35221196483607314\n",
            "Round: 2741 Weight: [2.35890568 1.16276748] Bias: -1.1501219095049207 loss: 0.35221196482212896\n",
            "Round: 2742 Weight: [2.35890667 1.16276798] Bias: -1.1501222858019255 loss: 0.3522119648082646\n",
            "Round: 2743 Weight: [2.35890766 1.16276849] Bias: -1.150122661022624 loss: 0.35221196479447914\n",
            "Round: 2744 Weight: [2.35890865 1.16276899] Bias: -1.1501230351700962 loss: 0.35221196478077255\n",
            "Round: 2745 Weight: [2.35890963 1.16276949] Bias: -1.1501234082474128 loss: 0.3522119647671443\n",
            "Round: 2746 Weight: [2.35891061 1.16276999] Bias: -1.1501237802576358 loss: 0.35221196475359384\n",
            "Round: 2747 Weight: [2.35891159 1.16277049] Bias: -1.150124151203819 loss: 0.3522119647401208\n",
            "Round: 2748 Weight: [2.35891257 1.16277098] Bias: -1.1501245210890065 loss: 0.3522119647267247\n",
            "Round: 2749 Weight: [2.35891354 1.16277148] Bias: -1.1501248899162346 loss: 0.35221196471340505\n",
            "Round: 2750 Weight: [2.35891451 1.16277197] Bias: -1.1501252576885304 loss: 0.3522119647001616\n",
            "Round: 2751 Weight: [2.35891547 1.16277246] Bias: -1.1501256244089124 loss: 0.35221196468699373\n",
            "Round: 2752 Weight: [2.35891644 1.16277295] Bias: -1.1501259900803906 loss: 0.35221196467390103\n",
            "Round: 2753 Weight: [2.3589174  1.16277344] Bias: -1.1501263547059664 loss: 0.35221196466088317\n",
            "Round: 2754 Weight: [2.35891836 1.16277393] Bias: -1.150126718288632 loss: 0.35221196464793975\n",
            "Round: 2755 Weight: [2.35891931 1.16277442] Bias: -1.1501270808313722 loss: 0.35221196463507015\n",
            "Round: 2756 Weight: [2.35892027 1.1627749 ] Bias: -1.150127442337162 loss: 0.35221196462227405\n",
            "Round: 2757 Weight: [2.35892122 1.16277539] Bias: -1.1501278028089685 loss: 0.35221196460955106\n",
            "Round: 2758 Weight: [2.35892216 1.16277587] Bias: -1.1501281622497506 loss: 0.3522119645969008\n",
            "Round: 2759 Weight: [2.35892311 1.16277635] Bias: -1.150128520662458 loss: 0.35221196458432275\n",
            "Round: 2760 Weight: [2.35892405 1.16277683] Bias: -1.1501288780500327 loss: 0.3522119645718165\n",
            "Round: 2761 Weight: [2.35892499 1.16277731] Bias: -1.150129234415408 loss: 0.35221196455938186\n",
            "Round: 2762 Weight: [2.35892593 1.16277778] Bias: -1.1501295897615083 loss: 0.35221196454701803\n",
            "Round: 2763 Weight: [2.35892686 1.16277826] Bias: -1.15012994409125 loss: 0.352211964534725\n",
            "Round: 2764 Weight: [2.35892779 1.16277873] Bias: -1.1501302974075416 loss: 0.35221196452250203\n",
            "Round: 2765 Weight: [2.35892872 1.16277921] Bias: -1.1501306497132826 loss: 0.352211964510349\n",
            "Round: 2766 Weight: [2.35892965 1.16277968] Bias: -1.1501310010113646 loss: 0.3522119644982652\n",
            "Round: 2767 Weight: [2.35893057 1.16278015] Bias: -1.1501313513046707 loss: 0.35221196448625064\n",
            "Round: 2768 Weight: [2.35893149 1.16278062] Bias: -1.1501317005960758 loss: 0.3522119644743046\n",
            "Round: 2769 Weight: [2.35893241 1.16278108] Bias: -1.1501320488884466 loss: 0.3522119644624268\n",
            "Round: 2770 Weight: [2.35893332 1.16278155] Bias: -1.1501323961846415 loss: 0.3522119644506168\n",
            "Round: 2771 Weight: [2.35893424 1.16278202] Bias: -1.150132742487511 loss: 0.35221196443887437\n",
            "Round: 2772 Weight: [2.35893515 1.16278248] Bias: -1.150133087799897 loss: 0.35221196442719893\n",
            "Round: 2773 Weight: [2.35893605 1.16278294] Bias: -1.1501334321246337 loss: 0.3522119644155902\n",
            "Round: 2774 Weight: [2.35893696 1.1627834 ] Bias: -1.1501337754645469 loss: 0.35221196440404773\n",
            "Round: 2775 Weight: [2.35893786 1.16278386] Bias: -1.1501341178224542 loss: 0.3522119643925713\n",
            "Round: 2776 Weight: [2.35893876 1.16278432] Bias: -1.1501344592011657 loss: 0.3522119643811603\n",
            "Round: 2777 Weight: [2.35893966 1.16278478] Bias: -1.150134799603483 loss: 0.35221196436981456\n",
            "Round: 2778 Weight: [2.35894055 1.16278523] Bias: -1.1501351390321994 loss: 0.3522119643585336\n",
            "Round: 2779 Weight: [2.35894145 1.16278569] Bias: -1.150135477490101 loss: 0.35221196434731705\n",
            "Round: 2780 Weight: [2.35894234 1.16278614] Bias: -1.150135814979965 loss: 0.3522119643361646\n",
            "Round: 2781 Weight: [2.35894322 1.16278659] Bias: -1.1501361515045616 loss: 0.35221196432507584\n",
            "Round: 2782 Weight: [2.35894411 1.16278704] Bias: -1.1501364870666524 loss: 0.3522119643140504\n",
            "Round: 2783 Weight: [2.35894499 1.16278749] Bias: -1.1501368216689911 loss: 0.3522119643030879\n",
            "Round: 2784 Weight: [2.35894587 1.16278794] Bias: -1.150137155314324 loss: 0.3522119642921881\n",
            "Round: 2785 Weight: [2.35894675 1.16278838] Bias: -1.1501374880053892 loss: 0.35221196428135043\n",
            "Round: 2786 Weight: [2.35894762 1.16278883] Bias: -1.1501378197449168 loss: 0.35221196427057483\n",
            "Round: 2787 Weight: [2.35894849 1.16278927] Bias: -1.1501381505356296 loss: 0.3522119642598606\n",
            "Round: 2788 Weight: [2.35894936 1.16278972] Bias: -1.1501384803802421 loss: 0.3522119642492077\n",
            "Round: 2789 Weight: [2.35895023 1.16279016] Bias: -1.1501388092814613 loss: 0.35221196423861567\n",
            "Round: 2790 Weight: [2.35895109 1.1627906 ] Bias: -1.150139137241986 loss: 0.352211964228084\n",
            "Round: 2791 Weight: [2.35895196 1.16279104] Bias: -1.1501394642645082 loss: 0.35221196421761264\n",
            "Round: 2792 Weight: [2.35895282 1.16279147] Bias: -1.1501397903517112 loss: 0.35221196420720097\n",
            "Round: 2793 Weight: [2.35895367 1.16279191] Bias: -1.1501401155062714 loss: 0.35221196419684875\n",
            "Round: 2794 Weight: [2.35895453 1.16279235] Bias: -1.1501404397308568 loss: 0.3522119641865558\n",
            "Round: 2795 Weight: [2.35895538 1.16279278] Bias: -1.1501407630281284 loss: 0.3522119641763215\n",
            "Round: 2796 Weight: [2.35895623 1.16279321] Bias: -1.1501410854007392 loss: 0.3522119641661457\n",
            "Round: 2797 Weight: [2.35895708 1.16279364] Bias: -1.150141406851335 loss: 0.35221196415602807\n",
            "Round: 2798 Weight: [2.35895792 1.16279407] Bias: -1.1501417273825534 loss: 0.35221196414596817\n",
            "Round: 2799 Weight: [2.35895876 1.1627945 ] Bias: -1.150142046997025 loss: 0.3522119641359657\n",
            "Round: 2800 Weight: [2.3589596  1.16279493] Bias: -1.1501423656973726 loss: 0.3522119641260205\n",
            "Round: 2801 Weight: [2.35896044 1.16279536] Bias: -1.1501426834862116 loss: 0.35221196411613204\n",
            "Round: 2802 Weight: [2.35896128 1.16279578] Bias: -1.1501430003661501 loss: 0.3522119641063\n",
            "Round: 2803 Weight: [2.35896211 1.16279621] Bias: -1.1501433163397883 loss: 0.3522119640965241\n",
            "Round: 2804 Weight: [2.35896294 1.16279663] Bias: -1.150143631409719 loss: 0.3522119640868041\n",
            "Round: 2805 Weight: [2.35896377 1.16279705] Bias: -1.150143945578528 loss: 0.3522119640771396\n",
            "Round: 2806 Weight: [2.35896459 1.16279747] Bias: -1.1501442588487933 loss: 0.35221196406753025\n",
            "Round: 2807 Weight: [2.35896542 1.16279789] Bias: -1.1501445712230858 loss: 0.3522119640579759\n",
            "Round: 2808 Weight: [2.35896624 1.16279831] Bias: -1.1501448827039689 loss: 0.35221196404847616\n",
            "Round: 2809 Weight: [2.35896706 1.16279872] Bias: -1.1501451932939983 loss: 0.35221196403903043\n",
            "Round: 2810 Weight: [2.35896787 1.16279914] Bias: -1.1501455029957233 loss: 0.3522119640296388\n",
            "Round: 2811 Weight: [2.35896869 1.16279955] Bias: -1.150145811811685 loss: 0.3522119640203008\n",
            "Round: 2812 Weight: [2.3589695  1.16279997] Bias: -1.1501461197444176 loss: 0.3522119640110162\n",
            "Round: 2813 Weight: [2.35897031 1.16280038] Bias: -1.150146426796448 loss: 0.35221196400178456\n",
            "Round: 2814 Weight: [2.35897112 1.16280079] Bias: -1.150146732970296 loss: 0.3522119639926056\n",
            "Round: 2815 Weight: [2.35897192 1.1628012 ] Bias: -1.1501470382684738 loss: 0.3522119639834791\n",
            "Round: 2816 Weight: [2.35897272 1.16280161] Bias: -1.150147342693487 loss: 0.3522119639744049\n",
            "Round: 2817 Weight: [2.35897352 1.16280202] Bias: -1.1501476462478335 loss: 0.35221196396538235\n",
            "Round: 2818 Weight: [2.35897432 1.16280242] Bias: -1.1501479489340043 loss: 0.3522119639564113\n",
            "Round: 2819 Weight: [2.35897512 1.16280283] Bias: -1.1501482507544833 loss: 0.3522119639474916\n",
            "Round: 2820 Weight: [2.35897591 1.16280323] Bias: -1.1501485517117473 loss: 0.3522119639386228\n",
            "Round: 2821 Weight: [2.3589767  1.16280363] Bias: -1.1501488518082656 loss: 0.3522119639298047\n",
            "Round: 2822 Weight: [2.35897749 1.16280404] Bias: -1.150149151046501 loss: 0.3522119639210368\n",
            "Round: 2823 Weight: [2.35897828 1.16280444] Bias: -1.1501494494289088 loss: 0.3522119639123191\n",
            "Round: 2824 Weight: [2.35897906 1.16280484] Bias: -1.1501497469579378 loss: 0.35221196390365117\n",
            "Round: 2825 Weight: [2.35897984 1.16280523] Bias: -1.150150043636029 loss: 0.3522119638950328\n",
            "Round: 2826 Weight: [2.35898062 1.16280563] Bias: -1.1501503394656172 loss: 0.35221196388646364\n",
            "Round: 2827 Weight: [2.3589814  1.16280603] Bias: -1.15015063444913 loss: 0.3522119638779433\n",
            "Round: 2828 Weight: [2.35898218 1.16280642] Bias: -1.1501509285889875 loss: 0.35221196386947184\n",
            "Round: 2829 Weight: [2.35898295 1.16280681] Bias: -1.1501512218876038 loss: 0.3522119638610486\n",
            "Round: 2830 Weight: [2.35898372 1.16280721] Bias: -1.1501515143473853 loss: 0.3522119638526735\n",
            "Round: 2831 Weight: [2.35898449 1.1628076 ] Bias: -1.1501518059707319 loss: 0.3522119638443463\n",
            "Round: 2832 Weight: [2.35898526 1.16280799] Bias: -1.1501520967600365 loss: 0.35221196383606657\n",
            "Round: 2833 Weight: [2.35898602 1.16280838] Bias: -1.1501523867176853 loss: 0.3522119638278343\n",
            "Round: 2834 Weight: [2.35898678 1.16280877] Bias: -1.1501526758460576 loss: 0.35221196381964887\n",
            "Round: 2835 Weight: [2.35898754 1.16280915] Bias: -1.1501529641475259 loss: 0.3522119638115102\n",
            "Round: 2836 Weight: [2.3589883  1.16280954] Bias: -1.1501532516244557 loss: 0.35221196380341807\n",
            "Round: 2837 Weight: [2.35898905 1.16280992] Bias: -1.150153538279206 loss: 0.3522119637953722\n",
            "Round: 2838 Weight: [2.35898981 1.16281031] Bias: -1.150153824114129 loss: 0.35221196378737224\n",
            "Round: 2839 Weight: [2.35899056 1.16281069] Bias: -1.15015410913157 loss: 0.35221196377941794\n",
            "Round: 2840 Weight: [2.35899131 1.16281107] Bias: -1.1501543933338676 loss: 0.35221196377150915\n",
            "Round: 2841 Weight: [2.35899206 1.16281145] Bias: -1.150154676723354 loss: 0.3522119637636454\n",
            "Round: 2842 Weight: [2.3589928  1.16281183] Bias: -1.1501549593023543 loss: 0.3522119637558267\n",
            "Round: 2843 Weight: [2.35899354 1.16281221] Bias: -1.1501552410731875 loss: 0.3522119637480526\n",
            "Round: 2844 Weight: [2.35899428 1.16281259] Bias: -1.1501555220381654 loss: 0.35221196374032293\n",
            "Round: 2845 Weight: [2.35899502 1.16281296] Bias: -1.1501558021995935 loss: 0.3522119637326373\n",
            "Round: 2846 Weight: [2.35899576 1.16281334] Bias: -1.1501560815597707 loss: 0.3522119637249957\n",
            "Round: 2847 Weight: [2.35899649 1.16281371] Bias: -1.150156360120989 loss: 0.3522119637173976\n",
            "Round: 2848 Weight: [2.35899723 1.16281408] Bias: -1.1501566378855343 loss: 0.35221196370984303\n",
            "Round: 2849 Weight: [2.35899796 1.16281446] Bias: -1.1501569148556856 loss: 0.35221196370233154\n",
            "Round: 2850 Weight: [2.35899868 1.16281483] Bias: -1.1501571910337156 loss: 0.35221196369486296\n",
            "Round: 2851 Weight: [2.35899941 1.1628152 ] Bias: -1.1501574664218903 loss: 0.35221196368743707\n",
            "Round: 2852 Weight: [2.35900013 1.16281556] Bias: -1.1501577410224695 loss: 0.3522119636800536\n",
            "Round: 2853 Weight: [2.35900086 1.16281593] Bias: -1.150158014837706 loss: 0.35221196367271224\n",
            "Round: 2854 Weight: [2.35900158 1.1628163 ] Bias: -1.1501582878698466 loss: 0.35221196366541285\n",
            "Round: 2855 Weight: [2.35900229 1.16281666] Bias: -1.150158560121132 loss: 0.35221196365815516\n",
            "Round: 2856 Weight: [2.35900301 1.16281703] Bias: -1.1501588315937954 loss: 0.3522119636509388\n",
            "Round: 2857 Weight: [2.35900372 1.16281739] Bias: -1.1501591022900648 loss: 0.3522119636437639\n",
            "Round: 2858 Weight: [2.35900443 1.16281775] Bias: -1.150159372212161 loss: 0.3522119636366297\n",
            "Round: 2859 Weight: [2.35900514 1.16281811] Bias: -1.1501596413622988 loss: 0.35221196362953644\n",
            "Round: 2860 Weight: [2.35900585 1.16281847] Bias: -1.1501599097426864 loss: 0.3522119636224837\n",
            "Round: 2861 Weight: [2.35900656 1.16281883] Bias: -1.1501601773555263 loss: 0.35221196361547114\n",
            "Round: 2862 Weight: [2.35900726 1.16281919] Bias: -1.150160444203014 loss: 0.3522119636084987\n",
            "Round: 2863 Weight: [2.35900796 1.16281955] Bias: -1.1501607102873388 loss: 0.35221196360156604\n",
            "Round: 2864 Weight: [2.35900866 1.1628199 ] Bias: -1.150160975610684 loss: 0.35221196359467294\n",
            "Round: 2865 Weight: [2.35900936 1.16282026] Bias: -1.1501612401752268 loss: 0.35221196358781925\n",
            "Round: 2866 Weight: [2.35901005 1.16282061] Bias: -1.1501615039831379 loss: 0.3522119635810047\n",
            "Round: 2867 Weight: [2.35901075 1.16282097] Bias: -1.1501617670365816 loss: 0.3522119635742291\n",
            "Round: 2868 Weight: [2.35901144 1.16282132] Bias: -1.1501620293377162 loss: 0.35221196356749224\n",
            "Round: 2869 Weight: [2.35901213 1.16282167] Bias: -1.150162290888694 loss: 0.3522119635607937\n",
            "Round: 2870 Weight: [2.35901281 1.16282202] Bias: -1.150162551691661 loss: 0.35221196355413353\n",
            "Round: 2871 Weight: [2.3590135  1.16282237] Bias: -1.1501628117487568 loss: 0.35221196354751133\n",
            "Round: 2872 Weight: [2.35901418 1.16282272] Bias: -1.1501630710621153 loss: 0.35221196354092704\n",
            "Round: 2873 Weight: [2.35901487 1.16282306] Bias: -1.1501633296338643 loss: 0.3522119635343804\n",
            "Round: 2874 Weight: [2.35901555 1.16282341] Bias: -1.150163587466125 loss: 0.35221196352787104\n",
            "Round: 2875 Weight: [2.35901622 1.16282375] Bias: -1.150163844561013 loss: 0.3522119635213989\n",
            "Round: 2876 Weight: [2.3590169 1.1628241] Bias: -1.1501641009206376 loss: 0.35221196351496364\n",
            "Round: 2877 Weight: [2.35901757 1.16282444] Bias: -1.1501643565471023 loss: 0.3522119635085652\n",
            "Round: 2878 Weight: [2.35901824 1.16282478] Bias: -1.1501646114425041 loss: 0.3522119635022033\n",
            "Round: 2879 Weight: [2.35901891 1.16282513] Bias: -1.1501648656089347 loss: 0.35221196349587774\n",
            "Round: 2880 Weight: [2.35901958 1.16282547] Bias: -1.1501651190484792 loss: 0.35221196348958833\n",
            "Round: 2881 Weight: [2.35902025 1.1628258 ] Bias: -1.1501653717632172 loss: 0.3522119634833349\n",
            "Round: 2882 Weight: [2.35902091 1.16282614] Bias: -1.150165623755222 loss: 0.35221196347711703\n",
            "Round: 2883 Weight: [2.35902158 1.16282648] Bias: -1.150165875026561 loss: 0.35221196347093475\n",
            "Round: 2884 Weight: [2.35902224 1.16282682] Bias: -1.1501661255792959 loss: 0.35221196346478784\n",
            "Round: 2885 Weight: [2.35902289 1.16282715] Bias: -1.1501663754154823 loss: 0.3522119634586759\n",
            "Round: 2886 Weight: [2.35902355 1.16282749] Bias: -1.15016662453717 loss: 0.35221196345259886\n",
            "Round: 2887 Weight: [2.35902421 1.16282782] Bias: -1.150166872946403 loss: 0.3522119634465567\n",
            "Round: 2888 Weight: [2.35902486 1.16282815] Bias: -1.1501671206452193 loss: 0.35221196344054895\n",
            "Round: 2889 Weight: [2.35902551 1.16282848] Bias: -1.1501673676356512 loss: 0.35221196343457556\n",
            "Round: 2890 Weight: [2.35902616 1.16282881] Bias: -1.150167613919725 loss: 0.35221196342863614\n",
            "Round: 2891 Weight: [2.35902681 1.16282914] Bias: -1.1501678594994613 loss: 0.3522119634227308\n",
            "Round: 2892 Weight: [2.35902745 1.16282947] Bias: -1.150168104376875 loss: 0.3522119634168592\n",
            "Round: 2893 Weight: [2.3590281 1.1628298] Bias: -1.150168348553975 loss: 0.352211963411021\n",
            "Round: 2894 Weight: [2.35902874 1.16283013] Bias: -1.1501685920327651 loss: 0.3522119634052163\n",
            "Round: 2895 Weight: [2.35902938 1.16283045] Bias: -1.1501688348152426 loss: 0.3522119633994446\n",
            "Round: 2896 Weight: [2.35903002 1.16283078] Bias: -1.1501690769033992 loss: 0.35221196339370586\n",
            "Round: 2897 Weight: [2.35903065 1.1628311 ] Bias: -1.1501693182992212 loss: 0.3522119633879999\n",
            "Round: 2898 Weight: [2.35903129 1.16283142] Bias: -1.1501695590046892 loss: 0.35221196338232663\n",
            "Round: 2899 Weight: [2.35903192 1.16283175] Bias: -1.1501697990217779 loss: 0.35221196337668575\n",
            "Round: 2900 Weight: [2.35903255 1.16283207] Bias: -1.1501700383524565 loss: 0.352211963371077\n",
            "Round: 2901 Weight: [2.35903318 1.16283239] Bias: -1.1501702769986883 loss: 0.3522119633655005\n",
            "Round: 2902 Weight: [2.35903381 1.16283271] Bias: -1.1501705149624317 loss: 0.3522119633599556\n",
            "Round: 2903 Weight: [2.35903443 1.16283303] Bias: -1.1501707522456386 loss: 0.35221196335444255\n",
            "Round: 2904 Weight: [2.35903506 1.16283334] Bias: -1.1501709888502558 loss: 0.3522119633489608\n",
            "Round: 2905 Weight: [2.35903568 1.16283366] Bias: -1.1501712247782245 loss: 0.3522119633435105\n",
            "Round: 2906 Weight: [2.3590363  1.16283398] Bias: -1.1501714600314803 loss: 0.35221196333809124\n",
            "Round: 2907 Weight: [2.35903692 1.16283429] Bias: -1.1501716946119531 loss: 0.352211963332703\n",
            "Round: 2908 Weight: [2.35903753 1.1628346 ] Bias: -1.1501719285215677 loss: 0.3522119633273455\n",
            "Round: 2909 Weight: [2.35903815 1.16283492] Bias: -1.150172161762243 loss: 0.35221196332201854\n",
            "Round: 2910 Weight: [2.35903876 1.16283523] Bias: -1.1501723943358924 loss: 0.35221196331672205\n",
            "Round: 2911 Weight: [2.35903937 1.16283554] Bias: -1.150172626244424 loss: 0.3522119633114559\n",
            "Round: 2912 Weight: [2.35903998 1.16283585] Bias: -1.1501728574897405 loss: 0.3522119633062197\n",
            "Round: 2913 Weight: [2.35904059 1.16283616] Bias: -1.1501730880737389 loss: 0.3522119633010135\n",
            "Round: 2914 Weight: [2.3590412  1.16283647] Bias: -1.150173317998311 loss: 0.352211963295837\n",
            "Round: 2915 Weight: [2.3590418  1.16283678] Bias: -1.150173547265343 loss: 0.35221196329069004\n",
            "Round: 2916 Weight: [2.3590424  1.16283708] Bias: -1.1501737758767159 loss: 0.35221196328557247\n",
            "Round: 2917 Weight: [2.359043   1.16283739] Bias: -1.1501740038343053 loss: 0.3522119632804841\n",
            "Round: 2918 Weight: [2.3590436  1.16283769] Bias: -1.1501742311399812 loss: 0.3522119632754249\n",
            "Round: 2919 Weight: [2.3590442 1.162838 ] Bias: -1.1501744577956086 loss: 0.3522119632703945\n",
            "Round: 2920 Weight: [2.3590448 1.1628383] Bias: -1.1501746838030467 loss: 0.3522119632653929\n",
            "Round: 2921 Weight: [2.35904539 1.1628386 ] Bias: -1.1501749091641498 loss: 0.35221196326041976\n",
            "Round: 2922 Weight: [2.35904598 1.16283891] Bias: -1.1501751338807666 loss: 0.35221196325547516\n",
            "Round: 2923 Weight: [2.35904657 1.16283921] Bias: -1.1501753579547407 loss: 0.3522119632505587\n",
            "Round: 2924 Weight: [2.35904716 1.16283951] Bias: -1.1501755813879104 loss: 0.3522119632456704\n",
            "Round: 2925 Weight: [2.35904775 1.16283981] Bias: -1.1501758041821089 loss: 0.35221196324081\n",
            "Round: 2926 Weight: [2.35904833 1.1628401 ] Bias: -1.1501760263391636 loss: 0.3522119632359773\n",
            "Round: 2927 Weight: [2.35904892 1.1628404 ] Bias: -1.1501762478608972 loss: 0.35221196323117215\n",
            "Round: 2928 Weight: [2.3590495 1.1628407] Bias: -1.150176468749127 loss: 0.3522119632263945\n",
            "Round: 2929 Weight: [2.35905008 1.16284099] Bias: -1.150176689005665 loss: 0.3522119632216442\n",
            "Round: 2930 Weight: [2.35905066 1.16284129] Bias: -1.1501769086323184 loss: 0.35221196321692094\n",
            "Round: 2931 Weight: [2.35905124 1.16284158] Bias: -1.1501771276308888 loss: 0.3522119632122247\n",
            "Round: 2932 Weight: [2.35905181 1.16284187] Bias: -1.1501773460031726 loss: 0.35221196320755527\n",
            "Round: 2933 Weight: [2.35905239 1.16284217] Bias: -1.1501775637509615 loss: 0.35221196320291254\n",
            "Round: 2934 Weight: [2.35905296 1.16284246] Bias: -1.1501777808760418 loss: 0.3522119631982963\n",
            "Round: 2935 Weight: [2.35905353 1.16284275] Bias: -1.1501779973801949 loss: 0.35221196319370646\n",
            "Round: 2936 Weight: [2.3590541  1.16284304] Bias: -1.1501782132651965 loss: 0.35221196318914283\n",
            "Round: 2937 Weight: [2.35905467 1.16284333] Bias: -1.150178428532818 loss: 0.3522119631846053\n",
            "Round: 2938 Weight: [2.35905523 1.16284362] Bias: -1.150178643184825 loss: 0.35221196318009346\n",
            "Round: 2939 Weight: [2.3590558 1.1628439] Bias: -1.150178857222979 loss: 0.3522119631756076\n",
            "Round: 2940 Weight: [2.35905636 1.16284419] Bias: -1.1501790706490354 loss: 0.3522119631711472\n",
            "Round: 2941 Weight: [2.35905692 1.16284447] Bias: -1.150179283464745 loss: 0.35221196316671244\n",
            "Round: 2942 Weight: [2.35905748 1.16284476] Bias: -1.150179495671854 loss: 0.3522119631623031\n",
            "Round: 2943 Weight: [2.35905804 1.16284504] Bias: -1.1501797072721032 loss: 0.35221196315791864\n",
            "Round: 2944 Weight: [2.35905859 1.16284533] Bias: -1.150179918267228 loss: 0.3522119631535594\n",
            "Round: 2945 Weight: [2.35905915 1.16284561] Bias: -1.15018012865896 loss: 0.3522119631492249\n",
            "Round: 2946 Weight: [2.3590597  1.16284589] Bias: -1.1501803384490243 loss: 0.35221196314491543\n",
            "Round: 2947 Weight: [2.35906025 1.16284617] Bias: -1.1501805476391427 loss: 0.3522119631406303\n",
            "Round: 2948 Weight: [2.3590608  1.16284645] Bias: -1.1501807562310309 loss: 0.3522119631363699\n",
            "Round: 2949 Weight: [2.35906135 1.16284673] Bias: -1.1501809642264 loss: 0.3522119631321336\n",
            "Round: 2950 Weight: [2.3590619  1.16284701] Bias: -1.1501811716269565 loss: 0.3522119631279216\n",
            "Round: 2951 Weight: [2.35906244 1.16284729] Bias: -1.1501813784344017 loss: 0.3522119631237336\n",
            "Round: 2952 Weight: [2.35906299 1.16284756] Bias: -1.1501815846504322 loss: 0.3522119631195697\n",
            "Round: 2953 Weight: [2.35906353 1.16284784] Bias: -1.1501817902767395 loss: 0.3522119631154293\n",
            "Round: 2954 Weight: [2.35906407 1.16284811] Bias: -1.1501819953150105 loss: 0.3522119631113127\n",
            "Round: 2955 Weight: [2.35906461 1.16284839] Bias: -1.150182199766927 loss: 0.3522119631072196\n",
            "Round: 2956 Weight: [2.35906515 1.16284866] Bias: -1.1501824036341666 loss: 0.3522119631031499\n",
            "Round: 2957 Weight: [2.35906568 1.16284893] Bias: -1.1501826069184014 loss: 0.3522119630991034\n",
            "Round: 2958 Weight: [2.35906622 1.16284921] Bias: -1.150182809621299 loss: 0.35221196309508007\n",
            "Round: 2959 Weight: [2.35906675 1.16284948] Bias: -1.1501830117445222 loss: 0.35221196309107966\n",
            "Round: 2960 Weight: [2.35906728 1.16284975] Bias: -1.1501832132897292 loss: 0.35221196308710206\n",
            "Round: 2961 Weight: [2.35906781 1.16285002] Bias: -1.1501834142585732 loss: 0.3522119630831473\n",
            "Round: 2962 Weight: [2.35906834 1.16285029] Bias: -1.150183614652703 loss: 0.352211963079215\n",
            "Round: 2963 Weight: [2.35906886 1.16285056] Bias: -1.1501838144737622 loss: 0.35221196307530517\n",
            "Round: 2964 Weight: [2.35906939 1.16285082] Bias: -1.1501840137233903 loss: 0.3522119630714177\n",
            "Round: 2965 Weight: [2.35906991 1.16285109] Bias: -1.1501842124032216 loss: 0.3522119630675525\n",
            "Round: 2966 Weight: [2.35907044 1.16285136] Bias: -1.1501844105148857 loss: 0.3522119630637093\n",
            "Round: 2967 Weight: [2.35907096 1.16285162] Bias: -1.1501846080600082 loss: 0.35221196305988806\n",
            "Round: 2968 Weight: [2.35907148 1.16285188] Bias: -1.1501848050402093 loss: 0.35221196305608865\n",
            "Round: 2969 Weight: [2.35907199 1.16285215] Bias: -1.1501850014571047 loss: 0.35221196305231095\n",
            "Round: 2970 Weight: [2.35907251 1.16285241] Bias: -1.1501851973123058 loss: 0.3522119630485548\n",
            "Round: 2971 Weight: [2.35907302 1.16285267] Bias: -1.1501853926074193 loss: 0.3522119630448201\n",
            "Round: 2972 Weight: [2.35907354 1.16285293] Bias: -1.1501855873440472 loss: 0.35221196304110675\n",
            "Round: 2973 Weight: [2.35907405 1.1628532 ] Bias: -1.1501857815237868 loss: 0.35221196303741453\n",
            "Round: 2974 Weight: [2.35907456 1.16285346] Bias: -1.150185975148231 loss: 0.3522119630337435\n",
            "Round: 2975 Weight: [2.35907507 1.16285371] Bias: -1.1501861682189682 loss: 0.35221196303009344\n",
            "Round: 2976 Weight: [2.35907558 1.16285397] Bias: -1.1501863607375822 loss: 0.3522119630264641\n",
            "Round: 2977 Weight: [2.35907608 1.16285423] Bias: -1.150186552705652 loss: 0.3522119630228557\n",
            "Round: 2978 Weight: [2.35907659 1.16285449] Bias: -1.1501867441247526 loss: 0.3522119630192677\n",
            "Round: 2979 Weight: [2.35907709 1.16285474] Bias: -1.150186934996454 loss: 0.3522119630157003\n",
            "Round: 2980 Weight: [2.35907759 1.162855  ] Bias: -1.150187125322322 loss: 0.35221196301215324\n",
            "Round: 2981 Weight: [2.35907809 1.16285525] Bias: -1.1501873151039177 loss: 0.3522119630086264\n",
            "Round: 2982 Weight: [2.35907859 1.16285551] Bias: -1.150187504342798 loss: 0.3522119630051197\n",
            "Round: 2983 Weight: [2.35907909 1.16285576] Bias: -1.1501876930405153 loss: 0.35221196300163315\n",
            "Round: 2984 Weight: [2.35907959 1.16285601] Bias: -1.1501878811986173 loss: 0.3522119629981664\n",
            "Round: 2985 Weight: [2.35908008 1.16285626] Bias: -1.1501880688186474 loss: 0.3522119629947195\n",
            "Round: 2986 Weight: [2.35908057 1.16285652] Bias: -1.1501882559021448 loss: 0.35221196299129226\n",
            "Round: 2987 Weight: [2.35908106 1.16285677] Bias: -1.150188442450644 loss: 0.35221196298788454\n",
            "Round: 2988 Weight: [2.35908155 1.16285702] Bias: -1.1501886284656755 loss: 0.35221196298449636\n",
            "Round: 2989 Weight: [2.35908204 1.16285726] Bias: -1.1501888139487648 loss: 0.35221196298112756\n",
            "Round: 2990 Weight: [2.35908253 1.16285751] Bias: -1.1501889989014336 loss: 0.35221196297777796\n",
            "Round: 2991 Weight: [2.35908302 1.16285776] Bias: -1.1501891833251987 loss: 0.3522119629744475\n",
            "Round: 2992 Weight: [2.3590835  1.16285801] Bias: -1.1501893672215733 loss: 0.352211962971136\n",
            "Round: 2993 Weight: [2.35908399 1.16285825] Bias: -1.1501895505920656 loss: 0.3522119629678434\n",
            "Round: 2994 Weight: [2.35908447 1.1628585 ] Bias: -1.1501897334381799 loss: 0.3522119629645697\n",
            "Round: 2995 Weight: [2.35908495 1.16285874] Bias: -1.1501899157614157 loss: 0.3522119629613147\n",
            "Round: 2996 Weight: [2.35908543 1.16285899] Bias: -1.1501900975632688 loss: 0.3522119629580782\n",
            "Round: 2997 Weight: [2.35908591 1.16285923] Bias: -1.1501902788452307 loss: 0.3522119629548602\n",
            "Round: 2998 Weight: [2.35908638 1.16285947] Bias: -1.1501904596087882 loss: 0.3522119629516606\n",
            "Round: 2999 Weight: [2.35908686 1.16285972] Bias: -1.1501906398554238 loss: 0.3522119629484793\n"
          ]
        }
      ],
      "source": [
        "for i in range(3000):\n",
        "    z = np.dot(X_train, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    l = loss_func(y_train, y_pred)\n",
        "    dw = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
        "    db = np.mean(y_pred-y_train)\n",
        "    w = w - alpha * dw\n",
        "    b = b - alpha* db\n",
        "    print(\"Round:\",i,\"Weight:\",w,\"Bias:\",b,\"loss:\",l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKc9SvLVCKUg",
        "outputId": "cd451975-6b05-4672-ffb6-4077ec532e73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.95591499, -1.03853963],\n",
              "       [ 0.76240994, -0.28464395],\n",
              "       [ 0.47215235,  1.86105915],\n",
              "       [-0.78563054,  0.52724371],\n",
              "       [ 1.92344029,  0.93318754],\n",
              "       [-0.30186789, -1.32849951],\n",
              "       [ 1.53643017,  1.02017551],\n",
              "       [ 2.11694535, -1.00954364],\n",
              "       [-0.20511536,  0.17929186],\n",
              "       [ 0.37539982, -0.42962389],\n",
              "       [ 0.85916247, -1.1255276 ],\n",
              "       [-0.30186789,  0.81720359],\n",
              "       [-1.07588813, -0.31363994],\n",
              "       [-0.9791356 ,  0.29527581],\n",
              "       [-1.17264066,  1.42611934],\n",
              "       [ 0.76240994, -1.3574955 ],\n",
              "       [ 0.18189476,  0.17929186],\n",
              "       [ 0.18189476,  2.12202305],\n",
              "       [-0.88238307, -0.74857975],\n",
              "       [-1.17264066,  0.49824772],\n",
              "       [ 1.82668776, -1.03853963],\n",
              "       [ 1.43967764,  0.38226377],\n",
              "       [-0.78563054,  1.91905113],\n",
              "       [ 0.08514223,  0.23728383],\n",
              "       [-0.0116103 , -0.28464395],\n",
              "       [-0.49537295, -0.80657173],\n",
              "       [-1.17264066, -0.98054766],\n",
              "       [-0.49537295, -0.25564796],\n",
              "       [ 0.85916247,  1.2811394 ],\n",
              "       [-1.17264066,  0.3242718 ],\n",
              "       [-0.0116103 ,  1.2811394 ],\n",
              "       [-1.65640331, -1.53147143],\n",
              "       [ 0.18189476, -0.6325958 ],\n",
              "       [ 0.18189476,  0.17929186],\n",
              "       [ 0.27864729,  0.06330791],\n",
              "       [-0.68887801,  1.42611934],\n",
              "       [ 0.95591499, -0.98054766],\n",
              "       [ 0.85916247,  2.18001502],\n",
              "       [-0.78563054, -0.57460383],\n",
              "       [ 1.34292511,  2.35399095],\n",
              "       [-1.36614572, -1.32849951],\n",
              "       [-0.9791356 , -0.71958377],\n",
              "       [-1.07588813,  0.58523569],\n",
              "       [-0.68887801,  0.15029587],\n",
              "       [-1.17264066, -0.74857975],\n",
              "       [-0.10836283, -0.45861987],\n",
              "       [ 0.08514223,  0.12129988],\n",
              "       [-1.36614572, -0.4006279 ],\n",
              "       [-0.0116103 , -0.54560784],\n",
              "       [ 0.76240994, -1.06753562],\n",
              "       [ 1.92344029, -0.6325958 ],\n",
              "       [ 0.95591499,  0.15029587],\n",
              "       [ 0.08514223, -0.22665197],\n",
              "       [-0.10836283, -1.03853963],\n",
              "       [ 2.02019282,  0.20828785],\n",
              "       [-0.88238307,  0.17929186],\n",
              "       [-0.78563054,  0.3242718 ],\n",
              "       [-0.68887801,  0.58523569],\n",
              "       [ 0.85916247,  1.10716347],\n",
              "       [ 2.02019282,  2.15101903],\n",
              "       [-0.30186789,  0.09230389],\n",
              "       [-0.0116103 , -0.4006279 ],\n",
              "       [ 0.18189476,  0.09230389],\n",
              "       [-0.20511536,  2.18001502],\n",
              "       [ 0.37539982, -0.45861987],\n",
              "       [ 1.43967764, -1.00954364],\n",
              "       [ 0.66565741, -1.3574955 ],\n",
              "       [ 0.27864729, -0.16866   ],\n",
              "       [ 0.76240994, -0.80657173],\n",
              "       [ 0.27864729,  0.3242718 ],\n",
              "       [-0.78563054,  0.58523569],\n",
              "       [-0.59212548,  2.35399095],\n",
              "       [-1.36614572, -1.21251556],\n",
              "       [ 0.85916247,  1.04917149],\n",
              "       [-1.07588813,  1.97704311],\n",
              "       [ 0.95591499,  2.09302706],\n",
              "       [ 0.18189476, -0.25564796],\n",
              "       [ 2.11694535, -0.77757574],\n",
              "       [ 1.72993523,  1.86105915],\n",
              "       [ 1.05266752,  2.09302706],\n",
              "       [ 0.66565741, -0.69058778],\n",
              "       [-0.68887801,  0.06330791],\n",
              "       [-1.9466609 , -0.48761586],\n",
              "       [ 1.24617258,  1.89005514],\n",
              "       [ 2.11694535,  0.41125976],\n",
              "       [ 1.6331827 , -0.8645637 ],\n",
              "       [-1.46289825, -1.41548747],\n",
              "       [-0.30186789, -1.3574955 ],\n",
              "       [ 0.47215235,  1.25214341],\n",
              "       [-1.07588813, -1.09653161],\n",
              "       [-0.9791356 ,  1.57109928],\n",
              "       [-1.17264066, -1.53147143],\n",
              "       [-0.59212548,  0.49824772],\n",
              "       [-0.68887801, -0.31363994],\n",
              "       [ 0.76240994,  0.7882076 ],\n",
              "       [-0.88238307, -0.6325958 ],\n",
              "       [-0.30186789,  0.23728383],\n",
              "       [ 2.11694535,  1.13615946],\n",
              "       [-0.59212548, -1.47347945],\n",
              "       [-0.30186789,  0.09230389],\n",
              "       [ 0.18189476, -0.11066802],\n",
              "       [-0.88238307,  0.41125976],\n",
              "       [-0.20511536,  1.62909125],\n",
              "       [-0.30186789,  0.29527581],\n",
              "       [-0.59212548,  1.39712335],\n",
              "       [ 0.37539982,  0.29527581],\n",
              "       [ 1.34292511, -1.38649149],\n",
              "       [-1.36614572, -1.44448346],\n",
              "       [ 1.92344029, -1.32849951],\n",
              "       [ 0.95591499, -0.80657173],\n",
              "       [ 0.37539982, -0.42962389],\n",
              "       [-0.59212548,  1.91905113],\n",
              "       [ 0.76240994,  0.15029587],\n",
              "       [-0.59212548, -1.47347945],\n",
              "       [-1.9466609 ,  0.49824772],\n",
              "       [-1.84990837, -1.24151155],\n",
              "       [ 1.43967764,  2.15101903],\n",
              "       [ 1.14942005, -1.41548747],\n",
              "       [ 1.6331827 ,  1.77407119],\n",
              "       [ 0.08514223,  0.7882076 ],\n",
              "       [-0.0116103 ,  0.06330791],\n",
              "       [ 0.47215235,  1.7450752 ],\n",
              "       [-0.20511536,  1.65808724],\n",
              "       [ 0.37539982,  0.17929186],\n",
              "       [ 0.85916247, -1.32849951],\n",
              "       [-0.0116103 ,  0.3242718 ],\n",
              "       [ 0.85916247, -1.27050753],\n",
              "       [ 0.76240994,  0.5562397 ],\n",
              "       [-0.0116103 , -0.51661185],\n",
              "       [ 2.02019282,  0.41125976],\n",
              "       [-0.30186789,  0.17929186],\n",
              "       [-1.55965078, -1.21251556],\n",
              "       [ 0.95591499,  1.80306718],\n",
              "       [ 0.18189476, -0.22665197],\n",
              "       [ 0.95591499,  0.61423168],\n",
              "       [-0.39862042, -1.27050753],\n",
              "       [-0.30186789, -1.27050753],\n",
              "       [-0.10836283, -0.34263592],\n",
              "       [-1.17264066, -1.56046741],\n",
              "       [-0.9791356 , -0.4006279 ],\n",
              "       [-0.10836283, -0.48761586],\n",
              "       [-0.30186789, -0.34263592],\n",
              "       [ 1.34292511,  0.61423168],\n",
              "       [-0.88238307, -1.18351957],\n",
              "       [ 0.27864729, -0.25564796],\n",
              "       [ 1.05266752, -0.11066802],\n",
              "       [ 0.27864729, -0.48761586],\n",
              "       [ 0.66565741, -1.24151155],\n",
              "       [ 1.14942005, -0.71958377],\n",
              "       [-1.07588813,  0.44025575],\n",
              "       [ 0.37539982,  0.03431192],\n",
              "       [-1.84990837,  0.03431192],\n",
              "       [ 0.56890488,  2.03503508],\n",
              "       [ 2.11694535, -0.66159179],\n",
              "       [-1.75315584,  0.15029587],\n",
              "       [-0.68887801, -1.56046741],\n",
              "       [-1.75315584,  0.38226377],\n",
              "       [ 0.08514223, -0.77757574],\n",
              "       [-0.9791356 , -0.28464395],\n",
              "       [-0.49537295, -1.09653161],\n",
              "       [ 1.43967764,  1.02017551],\n",
              "       [ 1.14942005, -0.95155167],\n",
              "       [ 1.53643017,  1.13615946],\n",
              "       [-0.10836283,  0.29527581],\n",
              "       [-0.30186789, -0.25564796],\n",
              "       [-0.10836283,  0.15029587],\n",
              "       [-0.9791356 , -0.92255568],\n",
              "       [-1.55965078, -1.47347945],\n",
              "       [-1.84990837,  0.20828785],\n",
              "       [ 1.53643017,  0.03431192],\n",
              "       [-0.30186789, -1.41548747],\n",
              "       [-1.46289825, -0.16866   ],\n",
              "       [-0.68887801, -1.47347945],\n",
              "       [ 1.24617258,  2.238007  ],\n",
              "       [ 1.05266752,  0.15029587],\n",
              "       [-0.0116103 , -0.22665197],\n",
              "       [-1.84990837, -1.44448346],\n",
              "       [-0.39862042,  1.25214341],\n",
              "       [-1.17264066, -1.50247544],\n",
              "       [ 0.66565741,  0.29527581],\n",
              "       [-0.30186789,  1.13615946],\n",
              "       [-1.07588813, -0.34263592],\n",
              "       [ 1.05266752,  0.58523569],\n",
              "       [ 2.02019282, -1.15452358],\n",
              "       [-0.10836283,  0.3242718 ],\n",
              "       [-1.17264066,  0.09230389],\n",
              "       [-1.55965078,  0.35326779],\n",
              "       [ 0.37539982,  1.13615946],\n",
              "       [ 0.85916247, -0.74857975],\n",
              "       [ 0.27864729, -0.28464395],\n",
              "       [-0.59212548,  1.39712335],\n",
              "       [-1.07588813, -0.31363994],\n",
              "       [ 0.18189476, -0.28464395],\n",
              "       [-1.07588813, -1.50247544],\n",
              "       [-0.10836283,  0.06330791],\n",
              "       [-0.78563054, -0.19765598],\n",
              "       [ 0.08514223,  0.29527581],\n",
              "       [ 0.08514223, -0.28464395],\n",
              "       [-0.49537295, -0.51661185],\n",
              "       [-0.30186789, -0.4006279 ],\n",
              "       [-1.07588813, -0.42962389],\n",
              "       [-1.17264066, -1.1255276 ],\n",
              "       [ 0.37539982, -0.11066802],\n",
              "       [-0.88238307, -0.22665197],\n",
              "       [ 0.37539982,  0.12129988],\n",
              "       [ 1.24617258, -1.32849951],\n",
              "       [-1.36614572,  0.44025575],\n",
              "       [ 0.08514223,  0.17929186],\n",
              "       [-0.30186789, -0.54560784],\n",
              "       [ 1.43967764,  0.09230389],\n",
              "       [ 0.27864729, -0.69058778],\n",
              "       [-0.10836283,  0.3242718 ],\n",
              "       [-0.30186789,  0.64322766],\n",
              "       [ 0.27864729,  0.09230389],\n",
              "       [-0.20511536, -0.25564796],\n",
              "       [-0.88238307,  0.41125976],\n",
              "       [ 1.34292511, -0.89355969],\n",
              "       [-0.49537295, -0.74857975],\n",
              "       [-1.07588813,  0.5562397 ],\n",
              "       [ 2.02019282,  0.5562397 ],\n",
              "       [ 0.27864729,  0.09230389],\n",
              "       [-0.30186789, -0.11066802],\n",
              "       [ 1.05266752,  0.5562397 ],\n",
              "       [ 1.72993523, -0.25564796],\n",
              "       [-1.17264066, -0.48761586],\n",
              "       [-1.75315584,  0.38226377],\n",
              "       [ 1.92344029,  2.18001502],\n",
              "       [-0.10836283,  2.238007  ],\n",
              "       [-1.26939319,  0.3242718 ],\n",
              "       [-0.30186789, -0.8645637 ],\n",
              "       [-0.30186789, -0.31363994],\n",
              "       [-1.17264066,  0.44025575],\n",
              "       [ 0.08514223,  0.06330791],\n",
              "       [-0.68887801,  0.20828785],\n",
              "       [-1.55965078, -0.4006279 ],\n",
              "       [ 1.34292511,  1.31013539],\n",
              "       [ 0.18189476, -0.34263592],\n",
              "       [-1.07588813, -1.41548747],\n",
              "       [ 1.05266752, -0.95155167],\n",
              "       [-0.88238307,  2.29599897],\n",
              "       [-0.78563054, -1.56046741],\n",
              "       [-0.10836283, -0.4006279 ],\n",
              "       [ 0.37539982,  1.02017551],\n",
              "       [-0.0116103 , -0.22665197],\n",
              "       [ 0.18189476,  1.10716347],\n",
              "       [ 0.85916247, -1.41548747],\n",
              "       [ 0.27864729,  0.29527581],\n",
              "       [-0.20511536,  1.42611934],\n",
              "       [-0.0116103 ,  0.06330791],\n",
              "       [-0.30186789, -0.71958377],\n",
              "       [ 1.82668776, -1.24151155],\n",
              "       [-0.78563054,  0.29527581],\n",
              "       [-0.10836283,  0.03431192],\n",
              "       [ 0.27864729,  0.52724371],\n",
              "       [ 0.08514223, -0.77757574],\n",
              "       [-1.26939319, -1.3574955 ],\n",
              "       [ 0.85916247, -0.54560784],\n",
              "       [-0.49537295, -1.18351957],\n",
              "       [ 0.76240994, -1.18351957],\n",
              "       [-1.75315584, -0.57460383],\n",
              "       [-1.17264066,  0.35326779],\n",
              "       [-1.17264066, -1.06753562],\n",
              "       [ 0.27864729, -1.1255276 ],\n",
              "       [-0.49537295,  2.32499496],\n",
              "       [ 0.08514223,  1.89005514],\n",
              "       [-0.88238307, -0.74857975],\n",
              "       [ 0.76240994, -1.32849951],\n",
              "       [ 0.95591499, -1.1255276 ],\n",
              "       [ 0.27864729, -0.48761586],\n",
              "       [-0.30186789, -0.22665197],\n",
              "       [-0.10836283,  0.17929186],\n",
              "       [ 0.95591499,  1.89005514],\n",
              "       [-1.9466609 , -0.02368006],\n",
              "       [ 0.85916247, -0.57460383],\n",
              "       [-0.39862042, -0.74857975],\n",
              "       [-0.10836283, -0.19765598],\n",
              "       [-0.10836283,  0.09230389],\n",
              "       [ 0.85916247, -0.6325958 ],\n",
              "       [ 1.72993523,  1.02017551],\n",
              "       [-0.30186789,  0.5562397 ],\n",
              "       [-0.30186789, -0.28464395],\n",
              "       [-0.49537295,  0.00531593],\n",
              "       [ 0.27864729, -0.51661185],\n",
              "       [-1.17264066, -1.56046741],\n",
              "       [-1.65640331,  0.09230389],\n",
              "       [ 0.18189476, -0.34263592],\n",
              "       [ 0.95591499,  2.00603909],\n",
              "       [ 0.85916247, -1.00954364],\n",
              "       [-1.17264066,  0.3242718 ],\n",
              "       [ 2.11694535,  0.96218353],\n",
              "       [-0.78563054,  1.36812736],\n",
              "       [ 1.34292511,  2.00603909],\n",
              "       [ 0.95591499, -1.03853963],\n",
              "       [-0.10836283,  0.23728383],\n",
              "       [-0.78563054,  1.10716347],\n",
              "       [ 1.92344029, -0.89355969],\n",
              "       [ 0.56890488, -0.8645637 ],\n",
              "       [-1.26939319,  0.61423168],\n",
              "       [-0.30186789,  0.12129988],\n",
              "       [-1.65640331, -0.02368006]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWQK2SG9DGKe"
      },
      "outputs": [],
      "source": [
        "y_pred=predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XzdxphhEWCO",
        "outputId": "b17e5143-1de6-4a94-8185-7f35b8fd3e1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epeGBz2GE8bt",
        "outputId": "4f0df951-3a9a-4ec3-ab91-87db8e963051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual Value\tpredicted values\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n"
          ]
        }
      ],
      "source": [
        "#print actual and predicted values in a table\n",
        "print(\"actual Value\\tpredicted values\")\n",
        "for i in range(len(y_test)):\n",
        "    print(y_test[i],\"\\t\\t\",int(y_pred[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgvGdLAzFegm",
        "outputId": "6e027b99-d550-4b41-8215-1d5dcf074f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86.0\n"
          ]
        }
      ],
      "source": [
        "x=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==y_pred[i]):\n",
        "    x+=1\n",
        "print((x/len(y_test))*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRBcUufAHDoF",
        "outputId": "8ca5fd46-fe8d-4355-e7ed-d2c147be971c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  86.0 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "from sklearn.metrics import  accuracy_score\n",
        "from sklearn.metrics import  precision_score\n",
        "from sklearn.metrics import  recall_score\n",
        "\n",
        "#Fit\n",
        "LR.fit(X_train,y_train)\n",
        "\n",
        "#predicting the test label with LR. Predict always takes X as input\n",
        "y_test_pred = LR.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)*100\n",
        "print(\"Accuracy: \", accuracy,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgWqwoSdJA4f"
      },
      "outputs": [],
      "source": [
        "y_pred1=predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO2YyVQJNE13"
      },
      "outputs": [],
      "source": [
        "print(\"actual Value\\tpredicted values\")\n",
        "for i in range(len(Y)):\n",
        "    print(Y[i],\"\\t\\t\",int(y_pred1[i]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test, y_test_pred)*100\n",
        "print(\"Precision: \", precision,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FdD7OnVCIB4",
        "outputId": "c2e3e373-be56-40a9-89db-362c610ef67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  87.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall = recall_score(y_test, y_test_pred)*100\n",
        "print(\"Recall: \", recall,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBooO3PtC5-M",
        "outputId": "e99e60fd-83f7-4b08-9173-c4a02d21508f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall:  73.68421052631578 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
